{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll implement two classification algorithms which are using all the previous material: probabilities, gradient descent, etc.: \n",
    "\n",
    "Logistic regression                                                                                                     \n",
    "https://ru.wikipedia.org/wiki/%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F                                                                                  \n",
    "https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html                                                     \n",
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([np.random.rand(1) + 2 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "y2 = np.array([np.random.rand(1) + 2.4 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "\n",
    "x1 = np.array(range(len(y1)))\n",
    "x2 = np.array([c+50 for c in range(len(y2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data matrix \n",
    "a1 = np.concatenate((x1.reshape(-1,1),y1,np.array([1 for c in range(len(x1))]).reshape(-1,1)), 1)\n",
    "a2 = np.concatenate((x2.reshape(-1,1),y2,np.array([0 for c in range(len(x2))]).reshape(-1,1)), 1)\n",
    "\n",
    "A = np.concatenate((a1,a2), 0).round(1)\n",
    "np.random.shuffle(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((168, 3), 78, 90)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, y1.shape[0], y2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 58. ,   2.8,   1. ],\n",
       "       [ 48. ,   2.2,   1. ],\n",
       "       [ 79. ,   2.5,   0. ],\n",
       "       [ 36. ,   2.8,   1. ],\n",
       "       [ 70. ,   2.8,   1. ],\n",
       "       [ 87. ,   3.4,   0. ],\n",
       "       [122. ,   3.4,   0. ],\n",
       "       [ 52. ,   2.4,   1. ],\n",
       "       [ 35. ,   2.7,   1. ],\n",
       "       [ 80. ,   2.6,   0. ],\n",
       "       [109. ,   2.7,   0. ],\n",
       "       [119. ,   3.2,   0. ],\n",
       "       [ 55. ,   3.3,   0. ],\n",
       "       [ 72. ,   2.8,   0. ],\n",
       "       [ 82. ,   3.4,   0. ],\n",
       "       [ 43. ,   2.1,   1. ],\n",
       "       [ 22. ,   2.9,   1. ],\n",
       "       [ 66. ,   3.1,   0. ],\n",
       "       [ 52. ,   2.6,   0. ],\n",
       "       [ 34. ,   3. ,   1. ],\n",
       "       [ 61. ,   2.9,   0. ],\n",
       "       [ 20. ,   2.3,   1. ],\n",
       "       [102. ,   3.4,   0. ],\n",
       "       [112. ,   3. ,   0. ],\n",
       "       [136. ,   2.7,   0. ],\n",
       "       [139. ,   2.6,   0. ],\n",
       "       [ 56. ,   2. ,   1. ],\n",
       "       [ 17. ,   2.2,   1. ],\n",
       "       [ 77. ,   2.6,   0. ],\n",
       "       [ 21. ,   2.8,   1. ],\n",
       "       [101. ,   2.7,   0. ],\n",
       "       [ 11. ,   2.9,   1. ],\n",
       "       [ 50. ,   3. ,   0. ],\n",
       "       [107. ,   3.1,   0. ],\n",
       "       [113. ,   3.1,   0. ],\n",
       "       [111. ,   3.3,   0. ],\n",
       "       [  9. ,   2.8,   1. ],\n",
       "       [ 68. ,   3.4,   0. ],\n",
       "       [ 49. ,   2.6,   1. ],\n",
       "       [128. ,   2.5,   0. ],\n",
       "       [ 44. ,   3. ,   1. ],\n",
       "       [135. ,   2.9,   0. ],\n",
       "       [ 96. ,   2.7,   0. ],\n",
       "       [ 60. ,   3.1,   0. ],\n",
       "       [  0. ,   2.7,   1. ],\n",
       "       [124. ,   3.1,   0. ],\n",
       "       [ 56. ,   2.6,   0. ],\n",
       "       [ 59. ,   2.5,   1. ],\n",
       "       [ 37. ,   2.4,   1. ],\n",
       "       [ 26. ,   2.2,   1. ],\n",
       "       [ 72. ,   2.1,   1. ],\n",
       "       [ 18. ,   2.3,   1. ],\n",
       "       [ 40. ,   2.7,   1. ],\n",
       "       [131. ,   2.9,   0. ],\n",
       "       [ 54. ,   2.5,   1. ],\n",
       "       [ 57. ,   2.9,   1. ],\n",
       "       [ 89. ,   2.7,   0. ],\n",
       "       [ 41. ,   2. ,   1. ],\n",
       "       [ 53. ,   3.1,   0. ],\n",
       "       [ 50. ,   2.9,   1. ],\n",
       "       [ 70. ,   2.7,   0. ],\n",
       "       [ 58. ,   3.2,   0. ],\n",
       "       [ 83. ,   2.5,   0. ],\n",
       "       [117. ,   3. ,   0. ],\n",
       "       [ 28. ,   2.7,   1. ],\n",
       "       [ 78. ,   3.2,   0. ],\n",
       "       [ 10. ,   2.6,   1. ],\n",
       "       [106. ,   2.4,   0. ],\n",
       "       [ 64. ,   3. ,   0. ],\n",
       "       [ 94. ,   2.9,   0. ],\n",
       "       [ 71. ,   2. ,   1. ],\n",
       "       [ 66. ,   2.5,   1. ],\n",
       "       [ 69. ,   2.7,   0. ],\n",
       "       [ 42. ,   2.9,   1. ],\n",
       "       [ 16. ,   2. ,   1. ],\n",
       "       [ 51. ,   2.8,   1. ],\n",
       "       [ 24. ,   2.2,   1. ],\n",
       "       [ 88. ,   2.8,   0. ],\n",
       "       [116. ,   2.7,   0. ],\n",
       "       [ 75. ,   3.2,   0. ],\n",
       "       [ 23. ,   2.9,   1. ],\n",
       "       [ 19. ,   2.5,   1. ],\n",
       "       [ 51. ,   3.2,   0. ],\n",
       "       [ 64. ,   2.2,   1. ],\n",
       "       [ 54. ,   2.6,   0. ],\n",
       "       [121. ,   2.5,   0. ],\n",
       "       [103. ,   3.4,   0. ],\n",
       "       [120. ,   2.7,   0. ],\n",
       "       [ 63. ,   2.2,   1. ],\n",
       "       [ 32. ,   2.2,   1. ],\n",
       "       [ 14. ,   2.3,   1. ],\n",
       "       [  8. ,   2.1,   1. ],\n",
       "       [ 69. ,   2.6,   1. ],\n",
       "       [ 33. ,   2.5,   1. ],\n",
       "       [130. ,   2.7,   0. ],\n",
       "       [ 68. ,   2.7,   1. ],\n",
       "       [ 46. ,   2.5,   1. ],\n",
       "       [104. ,   3.1,   0. ],\n",
       "       [ 55. ,   2.7,   1. ],\n",
       "       [132. ,   2.9,   0. ],\n",
       "       [118. ,   2.9,   0. ],\n",
       "       [125. ,   3.2,   0. ],\n",
       "       [126. ,   3.1,   0. ],\n",
       "       [ 65. ,   2.7,   1. ],\n",
       "       [ 90. ,   2.5,   0. ],\n",
       "       [ 45. ,   2.8,   1. ],\n",
       "       [  5. ,   2.1,   1. ],\n",
       "       [  2. ,   2.3,   1. ],\n",
       "       [ 38. ,   2.3,   1. ],\n",
       "       [ 27. ,   2.7,   1. ],\n",
       "       [ 98. ,   2.9,   0. ],\n",
       "       [ 63. ,   3. ,   0. ],\n",
       "       [ 30. ,   2.8,   1. ],\n",
       "       [ 73. ,   2.3,   1. ],\n",
       "       [ 71. ,   3. ,   0. ],\n",
       "       [ 73. ,   2.9,   0. ],\n",
       "       [ 25. ,   2.5,   1. ],\n",
       "       [ 59. ,   2.6,   0. ],\n",
       "       [  7. ,   2.9,   1. ],\n",
       "       [ 31. ,   2.8,   1. ],\n",
       "       [  3. ,   2.1,   1. ],\n",
       "       [ 65. ,   2.5,   0. ],\n",
       "       [115. ,   2.7,   0. ],\n",
       "       [ 13. ,   2.5,   1. ],\n",
       "       [ 86. ,   2.8,   0. ],\n",
       "       [ 47. ,   2.7,   1. ],\n",
       "       [ 39. ,   2.7,   1. ],\n",
       "       [ 62. ,   2.2,   1. ],\n",
       "       [123. ,   2.8,   0. ],\n",
       "       [ 67. ,   3.2,   0. ],\n",
       "       [ 76. ,   2.7,   0. ],\n",
       "       [ 93. ,   2.8,   0. ],\n",
       "       [105. ,   3. ,   0. ],\n",
       "       [ 74. ,   2.4,   0. ],\n",
       "       [ 15. ,   2.4,   1. ],\n",
       "       [127. ,   3.3,   0. ],\n",
       "       [ 61. ,   2.8,   1. ],\n",
       "       [ 97. ,   3.4,   0. ],\n",
       "       [ 95. ,   2.7,   0. ],\n",
       "       [ 74. ,   2.1,   1. ],\n",
       "       [  6. ,   2.9,   1. ],\n",
       "       [114. ,   3.1,   0. ],\n",
       "       [ 76. ,   2.6,   1. ],\n",
       "       [133. ,   2.9,   0. ],\n",
       "       [129. ,   2.5,   0. ],\n",
       "       [137. ,   2.8,   0. ],\n",
       "       [ 99. ,   3.2,   0. ],\n",
       "       [  1. ,   2.8,   1. ],\n",
       "       [ 81. ,   3. ,   0. ],\n",
       "       [134. ,   3.1,   0. ],\n",
       "       [ 92. ,   2.7,   0. ],\n",
       "       [ 60. ,   2.2,   1. ],\n",
       "       [ 67. ,   2.5,   1. ],\n",
       "       [110. ,   2.7,   0. ],\n",
       "       [ 29. ,   2.4,   1. ],\n",
       "       [ 77. ,   2.5,   1. ],\n",
       "       [ 53. ,   2.1,   1. ],\n",
       "       [100. ,   3.4,   0. ],\n",
       "       [ 84. ,   2.4,   0. ],\n",
       "       [ 12. ,   2.7,   1. ],\n",
       "       [  4. ,   2.1,   1. ],\n",
       "       [ 85. ,   2.6,   0. ],\n",
       "       [108. ,   2.6,   0. ],\n",
       "       [ 62. ,   3. ,   0. ],\n",
       "       [ 75. ,   2.5,   1. ],\n",
       "       [ 91. ,   2.6,   0. ],\n",
       "       [138. ,   3.3,   0. ],\n",
       "       [ 57. ,   2.5,   0. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(x1, y1, s=10, c='b', marker=\"o\", label='first')\n",
    "ax1.scatter(x2, y2, s=10, c='g', marker=\"o\", label='second')\n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.ones((A.shape[0], A.shape[1]+1))\n",
    "temp[:,1:] = A.copy()\n",
    "X = np.copy(temp[:,:-1])\n",
    "y = np.copy(temp[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,  58. ,   2.8],\n",
       "       [  1. ,  48. ,   2.2],\n",
       "       [  1. ,  79. ,   2.5],\n",
       "       [  1. ,  36. ,   2.8],\n",
       "       [  1. ,  70. ,   2.8],\n",
       "       [  1. ,  87. ,   3.4],\n",
       "       [  1. , 122. ,   3.4],\n",
       "       [  1. ,  52. ,   2.4],\n",
       "       [  1. ,  35. ,   2.7],\n",
       "       [  1. ,  80. ,   2.6],\n",
       "       [  1. , 109. ,   2.7],\n",
       "       [  1. , 119. ,   3.2],\n",
       "       [  1. ,  55. ,   3.3],\n",
       "       [  1. ,  72. ,   2.8],\n",
       "       [  1. ,  82. ,   3.4],\n",
       "       [  1. ,  43. ,   2.1],\n",
       "       [  1. ,  22. ,   2.9],\n",
       "       [  1. ,  66. ,   3.1],\n",
       "       [  1. ,  52. ,   2.6],\n",
       "       [  1. ,  34. ,   3. ],\n",
       "       [  1. ,  61. ,   2.9],\n",
       "       [  1. ,  20. ,   2.3],\n",
       "       [  1. , 102. ,   3.4],\n",
       "       [  1. , 112. ,   3. ],\n",
       "       [  1. , 136. ,   2.7],\n",
       "       [  1. , 139. ,   2.6],\n",
       "       [  1. ,  56. ,   2. ],\n",
       "       [  1. ,  17. ,   2.2],\n",
       "       [  1. ,  77. ,   2.6],\n",
       "       [  1. ,  21. ,   2.8],\n",
       "       [  1. , 101. ,   2.7],\n",
       "       [  1. ,  11. ,   2.9],\n",
       "       [  1. ,  50. ,   3. ],\n",
       "       [  1. , 107. ,   3.1],\n",
       "       [  1. , 113. ,   3.1],\n",
       "       [  1. , 111. ,   3.3],\n",
       "       [  1. ,   9. ,   2.8],\n",
       "       [  1. ,  68. ,   3.4],\n",
       "       [  1. ,  49. ,   2.6],\n",
       "       [  1. , 128. ,   2.5],\n",
       "       [  1. ,  44. ,   3. ],\n",
       "       [  1. , 135. ,   2.9],\n",
       "       [  1. ,  96. ,   2.7],\n",
       "       [  1. ,  60. ,   3.1],\n",
       "       [  1. ,   0. ,   2.7],\n",
       "       [  1. , 124. ,   3.1],\n",
       "       [  1. ,  56. ,   2.6],\n",
       "       [  1. ,  59. ,   2.5],\n",
       "       [  1. ,  37. ,   2.4],\n",
       "       [  1. ,  26. ,   2.2],\n",
       "       [  1. ,  72. ,   2.1],\n",
       "       [  1. ,  18. ,   2.3],\n",
       "       [  1. ,  40. ,   2.7],\n",
       "       [  1. , 131. ,   2.9],\n",
       "       [  1. ,  54. ,   2.5],\n",
       "       [  1. ,  57. ,   2.9],\n",
       "       [  1. ,  89. ,   2.7],\n",
       "       [  1. ,  41. ,   2. ],\n",
       "       [  1. ,  53. ,   3.1],\n",
       "       [  1. ,  50. ,   2.9],\n",
       "       [  1. ,  70. ,   2.7],\n",
       "       [  1. ,  58. ,   3.2],\n",
       "       [  1. ,  83. ,   2.5],\n",
       "       [  1. , 117. ,   3. ],\n",
       "       [  1. ,  28. ,   2.7],\n",
       "       [  1. ,  78. ,   3.2],\n",
       "       [  1. ,  10. ,   2.6],\n",
       "       [  1. , 106. ,   2.4],\n",
       "       [  1. ,  64. ,   3. ],\n",
       "       [  1. ,  94. ,   2.9],\n",
       "       [  1. ,  71. ,   2. ],\n",
       "       [  1. ,  66. ,   2.5],\n",
       "       [  1. ,  69. ,   2.7],\n",
       "       [  1. ,  42. ,   2.9],\n",
       "       [  1. ,  16. ,   2. ],\n",
       "       [  1. ,  51. ,   2.8],\n",
       "       [  1. ,  24. ,   2.2],\n",
       "       [  1. ,  88. ,   2.8],\n",
       "       [  1. , 116. ,   2.7],\n",
       "       [  1. ,  75. ,   3.2],\n",
       "       [  1. ,  23. ,   2.9],\n",
       "       [  1. ,  19. ,   2.5],\n",
       "       [  1. ,  51. ,   3.2],\n",
       "       [  1. ,  64. ,   2.2],\n",
       "       [  1. ,  54. ,   2.6],\n",
       "       [  1. , 121. ,   2.5],\n",
       "       [  1. , 103. ,   3.4],\n",
       "       [  1. , 120. ,   2.7],\n",
       "       [  1. ,  63. ,   2.2],\n",
       "       [  1. ,  32. ,   2.2],\n",
       "       [  1. ,  14. ,   2.3],\n",
       "       [  1. ,   8. ,   2.1],\n",
       "       [  1. ,  69. ,   2.6],\n",
       "       [  1. ,  33. ,   2.5],\n",
       "       [  1. , 130. ,   2.7],\n",
       "       [  1. ,  68. ,   2.7],\n",
       "       [  1. ,  46. ,   2.5],\n",
       "       [  1. , 104. ,   3.1],\n",
       "       [  1. ,  55. ,   2.7],\n",
       "       [  1. , 132. ,   2.9],\n",
       "       [  1. , 118. ,   2.9],\n",
       "       [  1. , 125. ,   3.2],\n",
       "       [  1. , 126. ,   3.1],\n",
       "       [  1. ,  65. ,   2.7],\n",
       "       [  1. ,  90. ,   2.5],\n",
       "       [  1. ,  45. ,   2.8],\n",
       "       [  1. ,   5. ,   2.1],\n",
       "       [  1. ,   2. ,   2.3],\n",
       "       [  1. ,  38. ,   2.3],\n",
       "       [  1. ,  27. ,   2.7],\n",
       "       [  1. ,  98. ,   2.9],\n",
       "       [  1. ,  63. ,   3. ],\n",
       "       [  1. ,  30. ,   2.8],\n",
       "       [  1. ,  73. ,   2.3],\n",
       "       [  1. ,  71. ,   3. ],\n",
       "       [  1. ,  73. ,   2.9],\n",
       "       [  1. ,  25. ,   2.5],\n",
       "       [  1. ,  59. ,   2.6],\n",
       "       [  1. ,   7. ,   2.9],\n",
       "       [  1. ,  31. ,   2.8],\n",
       "       [  1. ,   3. ,   2.1],\n",
       "       [  1. ,  65. ,   2.5],\n",
       "       [  1. , 115. ,   2.7],\n",
       "       [  1. ,  13. ,   2.5],\n",
       "       [  1. ,  86. ,   2.8],\n",
       "       [  1. ,  47. ,   2.7],\n",
       "       [  1. ,  39. ,   2.7],\n",
       "       [  1. ,  62. ,   2.2],\n",
       "       [  1. , 123. ,   2.8],\n",
       "       [  1. ,  67. ,   3.2],\n",
       "       [  1. ,  76. ,   2.7],\n",
       "       [  1. ,  93. ,   2.8],\n",
       "       [  1. , 105. ,   3. ],\n",
       "       [  1. ,  74. ,   2.4],\n",
       "       [  1. ,  15. ,   2.4],\n",
       "       [  1. , 127. ,   3.3],\n",
       "       [  1. ,  61. ,   2.8],\n",
       "       [  1. ,  97. ,   3.4],\n",
       "       [  1. ,  95. ,   2.7],\n",
       "       [  1. ,  74. ,   2.1],\n",
       "       [  1. ,   6. ,   2.9],\n",
       "       [  1. , 114. ,   3.1],\n",
       "       [  1. ,  76. ,   2.6],\n",
       "       [  1. , 133. ,   2.9],\n",
       "       [  1. , 129. ,   2.5],\n",
       "       [  1. , 137. ,   2.8],\n",
       "       [  1. ,  99. ,   3.2],\n",
       "       [  1. ,   1. ,   2.8],\n",
       "       [  1. ,  81. ,   3. ],\n",
       "       [  1. , 134. ,   3.1],\n",
       "       [  1. ,  92. ,   2.7],\n",
       "       [  1. ,  60. ,   2.2],\n",
       "       [  1. ,  67. ,   2.5],\n",
       "       [  1. , 110. ,   2.7],\n",
       "       [  1. ,  29. ,   2.4],\n",
       "       [  1. ,  77. ,   2.5],\n",
       "       [  1. ,  53. ,   2.1],\n",
       "       [  1. , 100. ,   3.4],\n",
       "       [  1. ,  84. ,   2.4],\n",
       "       [  1. ,  12. ,   2.7],\n",
       "       [  1. ,   4. ,   2.1],\n",
       "       [  1. ,  85. ,   2.6],\n",
       "       [  1. , 108. ,   2.6],\n",
       "       [  1. ,  62. ,   3. ],\n",
       "       [  1. ,  75. ,   2.5],\n",
       "       [  1. ,  91. ,   2.6],\n",
       "       [  1. , 138. ,   3.3],\n",
       "       [  1. ,  57. ,   2.5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigm(x):\n",
    "    return 1/(np.exp(-x)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y, y_pred):\n",
    "    return (y == y_pred).astype(int).sum()/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_, y_, batch_size, epochs, eta):\n",
    "    theta = np.random.rand(X.shape[1])\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        print('accuracy: ', accuracy_score(y_, sigm(theta.T@ X_.T).squeeze()>0.5))\n",
    "        rand_idxs = np.random.randint(X.shape[0], size=batch_size)\n",
    "        X_Batch = X_[rand_idxs]\n",
    "        Y_batch = y_[rand_idxs]\n",
    "        grad = 0\n",
    "        batch_loss = 0\n",
    "        for xx, yy in zip(X_Batch, Y_batch):\n",
    "            grad += xx*(sigm(theta.T@xx)-yy)\n",
    "            batch_loss += (1-yy)*np.log(1-sigm(theta.T@xx) + 1e-6) + yy*np.log(sigm(theta.T@xx)+ 1e-6)\n",
    "        print('batch loss: ', -batch_loss)\n",
    "        theta = theta - (1/X_Batch.shape[0])*eta*grad\n",
    "    \n",
    "    return theta\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.4642857142857143\n",
      "batch loss:  473.5819509014061\n",
      "accuracy:  0.4642857142857143\n",
      "batch loss:  336.20349173853975\n",
      "accuracy:  0.4642857142857143\n",
      "batch loss:  190.28774268755026\n",
      "accuracy:  0.4642857142857143\n",
      "batch loss:  52.75536587661622\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  18.02382890724687\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  33.41694630627851\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.047223899404905\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  28.239783013913353\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  30.657810969445332\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.472386762527027\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.66900033318934\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  29.32738485156059\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.986516485627938\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.12326935166973\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.19849944603073\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.804267563723915\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.68045928494273\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  27.16361012174464\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.97071795061809\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.741381365445104\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.626919126802203\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.402738013065903\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.45258973644402\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.537363965104785\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.525767347646\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.049518019831584\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.67864465436702\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.52209551867162\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.766183046386193\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.601068768958562\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  29.321627068158744\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.757935657858763\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.864516043745173\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.80313299115607\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.558603331702685\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.917401480348033\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  18.28008825922421\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  32.79503244833235\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  21.53957564416054\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.03232619178207\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.089383202782752\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.948292202883607\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  20.788420085020487\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  21.449466806079755\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.543735490228208\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.266836297794843\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.37921673027804\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  32.36698493455527\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  26.2724104296574\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.914165956398275\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.71713547108593\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.53318869966563\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.681657493755306\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  22.51632079011394\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  29.667946281460193\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.425625130476607\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.559416941607815\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.407733250787068\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.703189042032978\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.9970389310507\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.59594511097655\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.82186928682938\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.057829818949582\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.334216423415683\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  36.205547588120744\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.636191609796143\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  30.16093171113903\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  29.79238503767093\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  28.558737119321727\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.195492999620686\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  27.743204090869728\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  29.30670130124468\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.958653446852274\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  27.54171749504663\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.750052172529994\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.46315673961816\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.61778642558159\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.055728338977563\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.284184616321223\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  21.565070111545122\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.646916592875\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  32.24565272675547\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.761005921337848\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  29.169175284247412\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.239125408533937\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.759046246188372\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.307861082452597\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  26.803729637940386\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.331984110333998\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  29.368265788188694\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.158392534987286\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.053806821954186\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.330863970738232\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.38968431435377\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.630980030287734\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.96545463602205\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.101109537389668\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.0291947014796\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.64551509810931\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.770719250715\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  30.665635198569507\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  29.158516170302164\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.727509715287027\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.753830616615517\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  31.945167516724077\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.18864865728619\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.146865475539602\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  20.79008813030988\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  29.201682055729304\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.255277044600124\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  20.70105750027516\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.790853820958954\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.540153992351655\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  32.75002341499119\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  30.176491877373785\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  31.938281249713032\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.445931912069142\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.276194798315117\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.755829357585167\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  20.965885892975226\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  29.67461761244127\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  23.149048319582377\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  23.711272862356363\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.507572670688504\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.505703225195113\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  20.101330793529648\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.832537284289277\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.95016107913966\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  24.683282176759825\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  22.614391064321534\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.375126189041463\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.25818550685951\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.995405595191645\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.82207479238246\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.386815113450368\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.563573282242714\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.60219091433537\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  23.088517302895436\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  22.278496264724577\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  32.20888354527413\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.1396023511527\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.446120026706197\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  21.539444588983184\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  27.18196590462948\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  20.910312036542717\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  24.840234581580418\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.426300152564277\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.36537616328591\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.678355954586095\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.420619185582897\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  30.368991460213092\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  31.93531435305193\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.326243032089575\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.194333846018864\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.046932037672118\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.970868113520112\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.03224287127629\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.403720195683796\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.365687260998342\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.409516008721056\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.31801704342731\n",
      "accuracy:  0.8095238095238095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss:  23.456929192491984\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  22.186914916392446\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.94143848049335\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.531591794721162\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.59357617195502\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.31265133817534\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.706870791861434\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.226525128575062\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.28814043215861\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  20.408982241694147\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.543494124405132\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.856828507250405\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.294734869883243\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.280501667471913\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.23428826027407\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  30.70975754117677\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.66916166304391\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.48165251810924\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.480307087421025\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  35.590456296197445\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  29.918018132854417\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.905087847236036\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.85259961257991\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.198376706290368\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  25.188312880239945\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.031140859884353\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.14320159281713\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  20.77576741463971\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.715499729810062\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  30.911808196722564\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.493418872369542\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.783911759473863\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.670780119349864\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.662639011008146\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.56831977002016\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.9617067739418\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.049302790014856\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.87338681865164\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.406168835569048\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.22289971779524\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  28.909694393146214\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.879043047514386\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.636784470842056\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.932254778664525\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  32.15873414523201\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  30.569909348815944\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  26.32164505701382\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.663247924975227\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  29.472595690161796\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.574118953004085\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.47565586293999\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.363642687199995\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.47484245422646\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  22.63577749869375\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.161339446736665\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.149485736355317\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.415447564692748\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.064112940584828\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.0690569094145\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  33.69882121273717\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  23.667392772395733\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.35353198734628\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  29.104330771094908\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.02204774998434\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.272810561128708\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.930887904079622\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.127080952675442\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.136643369403625\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  32.077325330925106\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.129467040969597\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.887056201162228\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  31.170413067888425\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.931466538366156\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.208888821337684\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.229986182109844\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  28.903088201898196\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.876173131022874\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  30.87761199973298\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.40027729067905\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  27.389677510044486\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.017434795974577\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  24.724695538789206\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.8851486641791\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.34955038259004\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.856708458030006\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.73639113596731\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  28.51554155494859\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  26.99872397439698\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.95106495512385\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.273034210563736\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.537381758755835\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.497182407204086\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.264375334084832\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.639310629525067\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.05542026682762\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.047092778615\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.534430134515603\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  30.62357785567643\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.578256740298695\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.89014418125914\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.405539196278266\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.72590512681169\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.941833322547584\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.829941656684692\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  32.2343655096113\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  31.005867362905043\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.049107214636756\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.653989664742493\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.76859072319472\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.720502967629848\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.27383594971309\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  30.258524391916396\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.845170309494804\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  31.666556954423974\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.981790836080588\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  31.442991446748337\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  21.53885089027993\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.769449916509583\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  24.91890303059582\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.569048953240184\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  31.428198388248333\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  25.972841324046886\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.996843229271065\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  27.336758531641486\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.547405536005567\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.79332346001864\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.758563023352703\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.49997525001833\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.613175416134663\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  29.01604065850112\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.091640857894493\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.002883505804547\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.334988650567023\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.248451069939993\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.38834249409956\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.36377769898966\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.838641616811916\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.282054328616148\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.647147905815988\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  30.756433054871692\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.06256395413652\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  26.545727819224172\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  30.28889657591843\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.802497163319348\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.49588709315662\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.797670441525895\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.02474154001927\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.000080834004258\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.416947386751605\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.63826811945412\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.112392333191337\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  26.37990694311245\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.596125688177214\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.07617684227891\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.72138076967978\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.601314913476383\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.74725726122254\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.271181756281223\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.562464968001233\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.33980475397673\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.08567332502686\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.347423320132567\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.60296778734397\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.01366939807868\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.85109531895997\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.06055321909587\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.007070968724452\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.73022781291674\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.688848954126648\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.32296263887089\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.008777340222544\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  29.12008916029473\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.4665487335538\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  22.99860508529776\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.4989271136022\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  33.99570825577477\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.447595345345643\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.55867858019631\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.499713166485993\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.415964926592068\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.46404279277017\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  28.792194211594712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.56241503975495\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.237496059435873\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.375558982937346\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  22.95930690510571\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.185377373670217\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.84142869675408\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.180192321614854\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.37971230968522\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.114657917233377\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.794309360192763\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.537043637917424\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  34.07993112653851\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  26.29741336527755\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.826640930331337\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.939591186000367\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  29.820042974580208\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.412306248776293\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.132199421276425\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  19.547380913647626\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  35.36254866245627\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  24.245203980199648\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.475673802233416\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.574036101559443\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.50166311865649\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.68236374448393\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  29.122259788288726\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  25.635558414427937\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.840761805810452\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.685278555510763\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.91338237036754\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.032282091808355\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.47668402925745\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  32.27912059057607\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.03341271780324\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.452462904591037\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.093188939727472\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.41796762127897\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.267554082359247\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  31.518089300532022\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  34.30038666978363\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  24.01032844373323\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.721307571102034\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.841704934236162\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.842861588323643\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.361122554915223\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.81426860544937\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  32.117630709139675\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.93376354524005\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  32.06574161819713\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  27.54476977154049\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.328168434349152\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.07217118645676\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.21500183722989\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.79204509385455\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.47433114207153\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  30.94963296979135\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  23.940654438880923\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  22.179464905602096\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.157757495944118\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.143635696549588\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  31.446745862575245\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.33984259511808\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.05198645353426\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.115342756062827\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.42564056611864\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.97032956901101\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  28.641375169413386\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  27.36896155499053\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.990072545346056\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.44246534047399\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.37546785369544\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  20.494624426783606\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  33.296758944693906\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.269547710961405\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.92453068436354\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.744001004467357\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  22.9915437870922\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.250005001526443\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.404717456298904\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.18286094747903\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.29727315808114\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.624429618865634\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.18365343055615\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.046580097983536\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.437869437945597\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.987540726400773\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.477634817928994\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  26.926823970607852\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.416356741122502\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.901927875885058\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.617901339003037\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  32.67482785440847\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.98653442390335\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.793014266366075\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.631861475634484\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.804288923393184\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  21.22235690677963\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.164731462119693\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.667002147363075\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.6259905882724\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  32.03521083037157\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.831199920616964\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.63748622809055\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  25.31989154048395\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.735472539370104\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  21.523724718690783\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  26.369171847975654\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.3751385588271\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  23.00643831476153\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  27.62627596114906\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.98544521544164\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  30.802039192831355\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.593795354768154\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.14927475842835\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  20.196780168703167\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.502492874921007\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.40959360853732\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.84610680700844\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.59838375050105\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.340621255168912\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.488931600656304\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.299262533678334\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.031239494877326\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.043475875442113\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.68159154295703\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.14244122677275\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.06764769703956\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  32.72944862252421\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.330172383623566\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.164025997288306\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.11930429216319\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.92345100943345\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.72671638204428\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.613043834726863\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.198672803662056\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.00718449519295\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.649451462989052\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.15929943020749\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.242955174702818\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.405928006359538\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.513217171656095\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.019927816645612\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.798918071185675\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.492406403374808\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.017370186176166\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.449695559287665\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  22.40195259797755\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.688831531706484\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  30.5801696776229\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  27.58059281773877\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  25.852993452332466\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.355149793491147\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.172013105823055\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  19.71279207721339\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  31.08011186034\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.203234412928254\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.091345271890148\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.974324508942697\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.416850158486163\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.43973888196234\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.28895422650064\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  25.80770738490551\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.468702055656514\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  31.047647228964266\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  30.734085464206213\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.62783264468281\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.921136332528512\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  23.834372526976082\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  29.823227865259714\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.22197353007632\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.57062155785929\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.203627958452877\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.56806252067622\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.921779782146356\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.39864734585359\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.804553702234806\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.984240710147937\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.817246546028528\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.292929937414943\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.110123577828723\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.35046992350562\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.073013758373566\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  27.647753140264776\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  37.86949458366125\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  35.13541982391608\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.611989192370867\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.8366028779251\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  19.22331284298167\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.54263785686178\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  32.26899357526024\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.942466969144636\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  19.622379076262458\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.637353353168088\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.141495693985444\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  21.81855172459249\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.006227592626797\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.93848234643038\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.067120660965475\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.689635029989564\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.830272843540143\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.531015955304493\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.97493871871109\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  22.24244075826828\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.327238368660577\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.572362224595697\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.294533101144005\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.382024184212664\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.543755133865147\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.071204910892355\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  27.975846567986512\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.694048575119638\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.22237841578167\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.372605402027414\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  31.029141140729394\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  30.09803198180374\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.415363487457455\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.779308156519985\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  19.22673179380525\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.554891010599196\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.679863631657636\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.721365114271137\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.01118705969986\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.630133753648337\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.98173095125369\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.57596380496919\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.219045998837355\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  30.588629733219364\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  23.885092768461405\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  23.54818777883722\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  25.32120451833202\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.122512578123505\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.19753038183816\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.790424985258248\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.61083908590328\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  28.098208083705572\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.24596230811908\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.818193657817407\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.954154734701984\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.275845086310248\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.640180102223002\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  21.8841102542345\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.749621211408275\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.205066437402472\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.092466301022476\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.246227681473943\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  18.24824306262518\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  31.04107671796043\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  32.22514905617546\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.75895358376076\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.435190728261496\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.17370983894569\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.644678480197587\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  23.494952149238564\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.244894329784525\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.823681768898737\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  25.296563081148843\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.00736853378038\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.070857758011563\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  25.11078658567605\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.64675500607345\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  32.199264947337156\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.422208711924082\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.763740580518924\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  32.28381711967641\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  21.835570410156155\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.066091946952472\n",
      "accuracy:  0.8095238095238095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss:  29.099738361944762\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.138643602757405\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.243926118233283\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  23.095164388578464\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  32.07015555608267\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.56634008210668\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.770252806774497\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  23.351484716631024\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  30.40453958030008\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  31.055248965881297\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.024956729080074\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.849987707206203\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.70911010243503\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  28.618151277358987\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.970054979545303\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.639820018447185\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.84461563503872\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.07434850197764\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  29.748061508633846\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.846390077978207\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.991215123678572\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.89971665462231\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  21.813547870467442\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.08277473090458\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  38.021147044988254\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  26.940374832623412\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.860554680147022\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  22.357556918490147\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  20.608931375145826\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.01752990696653\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.431119022823086\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.943159023530367\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.435844564857817\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.880610232833465\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.17125811980081\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.61289227086716\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.249808050637707\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.843896423860613\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.642466822112414\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.601169051074503\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.793605581288958\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.834391520779008\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.25658288918604\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.17438910104753\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.99761715728887\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.53785800780283\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.711549397697258\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.379180622492843\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.238710910062437\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.013146960548983\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.48871046622675\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.576312827129005\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  20.210386200812877\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  20.462208939064595\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.845290489421174\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.13170190938851\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  21.869548884389427\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.459763945587202\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.363854301999893\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.89834768725538\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.358972128541563\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.722193535328223\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.106241486757177\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.857631623902282\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.045560800810375\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  31.8324774770459\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  31.624107447895256\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  23.199193692459218\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.744340608858483\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.595645809940137\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.221846238389265\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.116780530489066\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.715070763866763\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.150345809419726\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.77362702619375\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.59070678541286\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  19.514491665195607\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.17979979413838\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.88391713852122\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.785372958562505\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  27.1741659095841\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.896156653046994\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.397800167331614\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  32.9121079651472\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  29.94562657985325\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  30.365737778411155\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.276804330308778\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  21.19728948385045\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.904931939522207\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.721124027268022\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.50685345271453\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  28.182041089957917\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  22.98093665839765\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.323649318623925\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  26.72947957173394\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.107256814222236\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  27.69696374836287\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.685873540018246\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  21.184707660606577\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.81972787527734\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  31.121795440866432\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  23.923788610434787\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.02336407101511\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  26.25404773300746\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  22.503783883322885\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.97913354929035\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  24.930664761556613\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  20.191961082144584\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  32.68499951129812\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  31.788946542623282\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.22585782953033\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.0309663766765\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.750031680752365\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.976424062589306\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  31.561534996464868\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  25.941739320793936\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  26.769382576731573\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.887879906585916\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.327566471422507\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  31.763400593954696\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.1331299386308\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  28.691203903983563\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.991847774384663\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.625669314286608\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.66240958341618\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.10794113206011\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.811740174982447\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.6935484495375\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  29.39916682337126\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.957966999455508\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  19.798521392191226\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  23.37566987664437\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  29.598886528467922\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.292795323607056\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.325499894088683\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  21.600251786912942\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  30.38174447677748\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.4357578299189\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  23.444580235536947\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.711757485460392\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  30.937833178118797\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.93879050656707\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.244710347471766\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.68754411601044\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.21015758302754\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.795236372429386\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.90041529480155\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.53106843028523\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.68114666895126\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  29.859010700535215\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  30.373382701372563\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  28.870795601009416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7857142857142857\n",
      "batch loss:  22.812461687101383\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  33.51627420862182\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  28.17272627287696\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.739587899692953\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  24.92891111905715\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  27.256458541723728\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.564861991489533\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  26.45026897228951\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.49870723181806\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.870753830279906\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.998055939393097\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.26284822029902\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.402999048812624\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.05463840313165\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  22.935855124405673\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.66967890411393\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  21.223936626296027\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  31.01762737113966\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  32.41170467101571\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  27.866265896214273\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.31107898622222\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  27.586649881584716\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.098395942650324\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  21.032503237342763\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.096835800362292\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.84154789396328\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.249298220000625\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  29.654516850241738\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  18.277820945106388\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  35.74213004447937\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  28.776786285152774\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.77215624129886\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.21568922297438\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.389277031796208\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.067824478998237\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  31.331179038705503\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  23.74782544480132\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  25.50392711414439\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.977474831747823\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  27.019071672507238\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  28.9120960493148\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  27.778465981424365\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.880796187987684\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.859780508898368\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.73543675517319\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.145002867027817\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.40847086236163\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.71284132982138\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.46673497102561\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.034947148244044\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.727043688256217\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.668903796230797\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  28.533231116759165\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.20384373678887\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  31.3784318239019\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  22.730918826765045\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.34144912526942\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  26.491055134826205\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.38031743130025\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  38.85646321480557\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  28.331463255779767\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.441454720048416\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.844865169658085\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.68375776864716\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.045009791318716\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  26.75346279496288\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.35204104831752\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.317002584297345\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.170448128906653\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  27.59355669036885\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.97513216439135\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.242043305158646\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.31048381687897\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.29218835968999\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.68284408853814\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.345044270831703\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  22.040046645956895\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  30.387462220266254\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  23.32358722318522\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.458435739607545\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  22.788935586852492\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.107955520611537\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  28.18299745234975\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.986702881744865\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.064017579143083\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.390641401507807\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  29.234860204261224\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  30.2131986070354\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.73173243172844\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.604896204903643\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.86083022784956\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.588766508836844\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  30.919156823127043\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.740638815407372\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.231488612658783\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.921649559612085\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.513547210479643\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.484191805252664\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  32.78802218910876\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  30.00072375685349\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.63734142809158\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.706100148925717\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.839803646825505\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.655679861378157\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.277548955696346\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.622929751545648\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.680209287713513\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.284488410391447\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.901855494080422\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.44673425931614\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.376213598114013\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  25.82797487437347\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.843975705125242\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.25687367719601\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  32.710637565105365\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  25.86366900858755\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.597486370768237\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  32.010758153046794\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  27.547515519608083\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.4640028530086\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.315712240860204\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.74754312516651\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.21292080880572\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.177499901572588\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.556321293842167\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.28158914114772\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.630978549506278\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.652488475024352\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.95846746479344\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  19.12085675853921\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.36900625219953\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.21469354719554\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.91807051955605\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.439047678349336\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.762674495720457\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.87509780066904\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.520035430589452\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.07460725367381\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.714185685261988\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.63573389570562\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  28.45295968621023\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.690459541540097\n",
      "accuracy:  0.8095238095238095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss:  24.469606829842622\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.99980169016631\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.94654421061255\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  21.2787458874654\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.03780344526895\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  28.03059546228348\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.80197495222146\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.65260188442763\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  27.778638098654202\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  20.936652941975616\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.872242072946257\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.795250793293775\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.25906628801427\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.886343247818576\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  25.696391805379225\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.270129697062707\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.68962771310978\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  31.380198516382872\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.0889093890254\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.293321463201664\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.517245913429974\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  31.503147551077166\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  22.78418781094346\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.99577485392402\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.067537453228773\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.478000722282584\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.797467948761557\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  32.05829861504502\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.78638784474398\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.334192511630008\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  31.41521576044325\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  30.230794175224506\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.335035682208655\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.062731522998433\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  25.747253326130217\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.82491904391941\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.583988518648557\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.114176429568236\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  24.08324945179874\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.11252022310812\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.379873774454293\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  26.241947524382688\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  25.193117971224343\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.03045366836234\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  27.032211103430193\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  29.84670106214458\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.922163518287014\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  28.196909581980595\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.518827642041934\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  22.34647321364327\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.028255318356457\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  29.40038581009934\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  26.097590186222536\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.075739801882712\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.06182211074944\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.01801236484111\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  23.069994056983738\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.12288637381733\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  32.21373301553323\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  22.134996443961594\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  27.712862358406635\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  27.40228845057072\n",
      "accuracy:  0.7619047619047619\n",
      "batch loss:  28.732504822315843\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  27.277744388033337\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  19.19707239065959\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.751257786226706\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  26.594364856363576\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  28.309574205665285\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  20.93194363141117\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  24.850134186264825\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.162727722680284\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  21.771604199649165\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  28.601050878380036\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  30.448907192151953\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  23.592466331801546\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  30.7786785035554\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.848239683956006\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  28.115858054364\n",
      "accuracy:  0.7678571428571429\n",
      "batch loss:  30.163833028499702\n",
      "accuracy:  0.8095238095238095\n",
      "batch loss:  24.3405866500759\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  27.084643909103644\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  22.802498519307672\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  24.30521721315646\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  23.750108985302695\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  28.69643966226323\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  27.638975380971683\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  21.574537703772044\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  31.008279334093967\n",
      "accuracy:  0.7857142857142857\n",
      "batch loss:  29.269672605879208\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  24.96010328973452\n",
      "accuracy:  0.7738095238095238\n",
      "batch loss:  28.66146066502469\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  26.14039257931472\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  28.582772570784286\n",
      "accuracy:  0.7797619047619048\n",
      "batch loss:  26.20407173927985\n",
      "accuracy:  0.8035714285714286\n",
      "batch loss:  25.151993276607357\n",
      "accuracy:  0.7916666666666666\n",
      "batch loss:  25.19574003490406\n",
      "accuracy:  0.7976190476190477\n",
      "batch loss:  22.14200628906204\n"
     ]
    }
   ],
   "source": [
    "theta = train(X, y, 64, 1000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "\n",
    "y1_test = np.array([np.random.rand(1) + 2 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "y2_test = np.array([np.random.rand(1) + 2.4 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "\n",
    "x1_test = np.array(range(len(y1_test)))\n",
    "x2_test = np.array([c+50 for c in range(len(y2_test))])\n",
    "\n",
    "a1_test = np.concatenate((x1_test.reshape(-1,1),y1_test,np.array([1 for c in range(len(x1_test))]).reshape(-1,1)), 1)\n",
    "a2_test = np.concatenate((x2_test.reshape(-1,1),y2_test,np.array([0 for c in range(len(x2_test))]).reshape(-1,1)), 1)\n",
    "\n",
    "A_test = np.concatenate((a1_test,a2_test), 0).round(1)\n",
    "np.random.shuffle(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_test = np.ones((A_test.shape[0], A_test.shape[1]+1))\n",
    "# temp_test[:,1:] = A_test\n",
    "# X_test = temp_test[:,:-1]\n",
    "# y_test = temp_test[:,-1]\n",
    "temp_test = np.ones((A_test.shape[0], A_test.shape[1]+1))\n",
    "temp_test[:,1:] = A_test.copy()\n",
    "X_test = np.copy(temp_test[:,:-1])\n",
    "y_test = np.copy(temp_test[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. , 104. ,   2.7],\n",
       "       [  1. ,  48. ,   2.2],\n",
       "       [  1. ,  93. ,   3.3],\n",
       "       [  1. , 118. ,   3. ],\n",
       "       [  1. ,  38. ,   2.7],\n",
       "       [  1. ,  98. ,   2. ],\n",
       "       [  1. ,  79. ,   3.2],\n",
       "       [  1. ,  30. ,   2.4],\n",
       "       [  1. ,  87. ,   2.9],\n",
       "       [  1. , 105. ,   2.6],\n",
       "       [  1. ,  76. ,   3.1],\n",
       "       [  1. ,  55. ,   2.1],\n",
       "       [  1. ,  71. ,   2.5],\n",
       "       [  1. , 103. ,   2.6],\n",
       "       [  1. ,  57. ,   2.5],\n",
       "       [  1. ,  78. ,   3.1],\n",
       "       [  1. , 136. ,   2.8],\n",
       "       [  1. ,  28. ,   2. ],\n",
       "       [  1. , 144. ,   2.5],\n",
       "       [  1. , 120. ,   3.1],\n",
       "       [  1. , 117. ,   2.4],\n",
       "       [  1. ,  62. ,   2.2],\n",
       "       [  1. ,  60. ,   3.2],\n",
       "       [  1. ,  67. ,   2.7],\n",
       "       [  1. ,  71. ,   2.3],\n",
       "       [  1. ,   9. ,   2.8],\n",
       "       [  1. ,  46. ,   2.9],\n",
       "       [  1. , 125. ,   3.3],\n",
       "       [  1. ,  65. ,   3.3],\n",
       "       [  1. ,  84. ,   2.5],\n",
       "       [  1. ,  74. ,   2.9],\n",
       "       [  1. , 126. ,   3.1],\n",
       "       [  1. ,  95. ,   2.7],\n",
       "       [  1. ,  76. ,   2.4],\n",
       "       [  1. ,  10. ,   2.5],\n",
       "       [  1. ,  37. ,   2.2],\n",
       "       [  1. , 122. ,   2.9],\n",
       "       [  1. ,  40. ,   3. ],\n",
       "       [  1. ,  75. ,   2.8],\n",
       "       [  1. , 106. ,   2.9],\n",
       "       [  1. ,  77. ,   2.5],\n",
       "       [  1. ,  80. ,   2.5],\n",
       "       [  1. ,  73. ,   2.6],\n",
       "       [  1. , 132. ,   2.5],\n",
       "       [  1. ,  90. ,   2.7],\n",
       "       [  1. , 142. ,   3.1],\n",
       "       [  1. ,   5. ,   2.4],\n",
       "       [  1. ,  63. ,   2.5],\n",
       "       [  1. ,  69. ,   2.7],\n",
       "       [  1. ,  50. ,   2.5],\n",
       "       [  1. ,  55. ,   3.1],\n",
       "       [  1. , 145. ,   2.5],\n",
       "       [  1. ,  85. ,   2.2],\n",
       "       [  1. ,  12. ,   2. ],\n",
       "       [  1. , 123. ,   3. ],\n",
       "       [  1. ,  90. ,   3.1],\n",
       "       [  1. , 135. ,   2.5],\n",
       "       [  1. ,  93. ,   2.4],\n",
       "       [  1. ,  94. ,   2.2],\n",
       "       [  1. ,  92. ,   2.6],\n",
       "       [  1. ,   0. ,   2. ],\n",
       "       [  1. ,  24. ,   3. ],\n",
       "       [  1. ,  59. ,   2.5],\n",
       "       [  1. ,  82. ,   2.3],\n",
       "       [  1. ,  19. ,   2.6],\n",
       "       [  1. ,  54. ,   2.6],\n",
       "       [  1. ,  98. ,   2.7],\n",
       "       [  1. , 109. ,   3. ],\n",
       "       [  1. ,  57. ,   2.7],\n",
       "       [  1. , 129. ,   3. ],\n",
       "       [  1. , 127. ,   2.8],\n",
       "       [  1. ,  86. ,   3.1],\n",
       "       [  1. ,  23. ,   2.2],\n",
       "       [  1. ,  16. ,   2.2],\n",
       "       [  1. ,  58. ,   3. ],\n",
       "       [  1. , 139. ,   2.9],\n",
       "       [  1. , 112. ,   2.8],\n",
       "       [  1. ,  88. ,   2.7],\n",
       "       [  1. ,  94. ,   2.5],\n",
       "       [  1. ,  50. ,   2.8],\n",
       "       [  1. , 137. ,   2.8],\n",
       "       [  1. ,  72. ,   2. ],\n",
       "       [  1. ,  89. ,   2.8],\n",
       "       [  1. ,  45. ,   2.1],\n",
       "       [  1. ,  70. ,   2.4],\n",
       "       [  1. ,  78. ,   2.7],\n",
       "       [  1. , 138. ,   3.3],\n",
       "       [  1. ,  79. ,   2.8],\n",
       "       [  1. ,  13. ,   2.6],\n",
       "       [  1. ,  74. ,   3. ],\n",
       "       [  1. ,  32. ,   2.3],\n",
       "       [  1. ,  56. ,   3.1],\n",
       "       [  1. ,  53. ,   2.6],\n",
       "       [  1. , 128. ,   2.6],\n",
       "       [  1. ,  27. ,   2.3],\n",
       "       [  1. ,  58. ,   2.2],\n",
       "       [  1. ,  97. ,   2.7],\n",
       "       [  1. ,   3. ,   2.1],\n",
       "       [  1. ,  14. ,   2.4],\n",
       "       [  1. , 141. ,   3.4],\n",
       "       [  1. ,  97. ,   2.4],\n",
       "       [  1. , 101. ,   3.2],\n",
       "       [  1. ,  81. ,   3.2],\n",
       "       [  1. ,  39. ,   2.4],\n",
       "       [  1. ,  95. ,   2.6],\n",
       "       [  1. , 107. ,   2.5],\n",
       "       [  1. ,  66. ,   2.7],\n",
       "       [  1. , 133. ,   3. ],\n",
       "       [  1. ,  52. ,   3.2],\n",
       "       [  1. ,  25. ,   2.7],\n",
       "       [  1. , 124. ,   2.7],\n",
       "       [  1. ,  51. ,   2.1],\n",
       "       [  1. ,  84. ,   3.2],\n",
       "       [  1. ,  61. ,   2.9],\n",
       "       [  1. ,  31. ,   2.1],\n",
       "       [  1. ,  69. ,   3. ],\n",
       "       [  1. ,  61. ,   2.8],\n",
       "       [  1. ,  67. ,   2.5],\n",
       "       [  1. ,  66. ,   2.4],\n",
       "       [  1. , 108. ,   3. ],\n",
       "       [  1. , 140. ,   3.4],\n",
       "       [  1. ,  63. ,   2.5],\n",
       "       [  1. ,  77. ,   2.8],\n",
       "       [  1. , 100. ,   3.4],\n",
       "       [  1. , 143. ,   2.7],\n",
       "       [  1. ,  56. ,   2.4],\n",
       "       [  1. ,  54. ,   2.5],\n",
       "       [  1. ,  18. ,   2. ],\n",
       "       [  1. , 114. ,   3.3],\n",
       "       [  1. ,  92. ,   2.7],\n",
       "       [  1. ,  75. ,   2.7],\n",
       "       [  1. ,  33. ,   2.1],\n",
       "       [  1. ,  15. ,   2.4],\n",
       "       [  1. ,  11. ,   2.1],\n",
       "       [  1. , 130. ,   3.1],\n",
       "       [  1. ,  60. ,   2.3],\n",
       "       [  1. ,  91. ,   2.2],\n",
       "       [  1. ,  47. ,   2.5],\n",
       "       [  1. ,  70. ,   2.9],\n",
       "       [  1. ,  49. ,   2.3],\n",
       "       [  1. ,   8. ,   2.5],\n",
       "       [  1. ,  82. ,   3.1],\n",
       "       [  1. ,  51. ,   2.8],\n",
       "       [  1. ,  53. ,   2.8],\n",
       "       [  1. ,  72. ,   3. ],\n",
       "       [  1. ,  41. ,   2.3],\n",
       "       [  1. ,  35. ,   2.2],\n",
       "       [  1. ,  34. ,   2. ],\n",
       "       [  1. , 115. ,   2.7],\n",
       "       [  1. ,  96. ,   3. ],\n",
       "       [  1. , 102. ,   2.8],\n",
       "       [  1. ,  64. ,   3.1],\n",
       "       [  1. ,  26. ,   2.7],\n",
       "       [  1. , 113. ,   2.5],\n",
       "       [  1. ,  83. ,   2.1],\n",
       "       [  1. ,  68. ,   3.2],\n",
       "       [  1. ,  64. ,   3. ],\n",
       "       [  1. ,  81. ,   2.2],\n",
       "       [  1. ,  89. ,   2.9],\n",
       "       [  1. ,   4. ,   3. ],\n",
       "       [  1. ,  73. ,   2.2],\n",
       "       [  1. ,  91. ,   2.6],\n",
       "       [  1. ,  20. ,   2.7],\n",
       "       [  1. ,   2. ,   2.9],\n",
       "       [  1. ,  83. ,   2.5],\n",
       "       [  1. ,  88. ,   2.6],\n",
       "       [  1. ,  42. ,   2.7],\n",
       "       [  1. ,  99. ,   2.6],\n",
       "       [  1. ,  80. ,   2.1],\n",
       "       [  1. ,  21. ,   2.1],\n",
       "       [  1. , 134. ,   2.6],\n",
       "       [  1. , 121. ,   3. ],\n",
       "       [  1. ,   7. ,   2. ],\n",
       "       [  1. ,  85. ,   3. ],\n",
       "       [  1. ,  87. ,   3.4],\n",
       "       [  1. ,  17. ,   2.9],\n",
       "       [  1. ,  44. ,   2.1],\n",
       "       [  1. ,  22. ,   2.3],\n",
       "       [  1. , 119. ,   3. ],\n",
       "       [  1. ,  43. ,   2.5],\n",
       "       [  1. ,  86. ,   2.6],\n",
       "       [  1. ,  62. ,   3.2],\n",
       "       [  1. , 116. ,   2.6],\n",
       "       [  1. , 111. ,   2.9],\n",
       "       [  1. ,  65. ,   2.6],\n",
       "       [  1. ,  68. ,   3. ],\n",
       "       [  1. ,  36. ,   2.3],\n",
       "       [  1. ,  59. ,   2.6],\n",
       "       [  1. ,  96. ,   3.3],\n",
       "       [  1. , 131. ,   2.9],\n",
       "       [  1. ,   1. ,   2.5],\n",
       "       [  1. ,   6. ,   2. ],\n",
       "       [  1. ,  29. ,   2.5],\n",
       "       [  1. , 110. ,   3.4],\n",
       "       [  1. ,  52. ,   2.2]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_logistic_regr(theta, data):\n",
    "    return (sigm(theta.T@ data.T).squeeze()>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pred_logistic_regr(theta, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717948717948718"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(x1_test, y1_test, s=10, c='b', marker=\"o\", label='first')\n",
    "ax1.scatter(x2_test, y2_test, s=10, c='g', marker=\"o\", label='second')\n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(trues, falses):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    no_of_preds = len(trues) + len(falses)\n",
    "\n",
    "    ax.scatter([i for i in range(len(trues))], trues, s=25, c='b', marker=\"o\", label='Trues')\n",
    "    ax.scatter([i for i in range(len(falses))], falses, s=25, c='r', marker=\"s\", label='Falses')\n",
    "\n",
    "    plt.legend(loc='upper right');\n",
    "    ax.set_title(\"Decision Boundary\")\n",
    "    ax.set_xlabel('N/2')\n",
    "    ax.set_ylabel('Predicted Probability')\n",
    "    plt.axhline(.5, color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for train  data\n",
    "trues = sigm(theta.T@ X.T).squeeze()*((y + sigm(theta.T@ X.T).squeeze() >=0.5) > 0)\n",
    "falses = sigm(theta.T@ X.T).squeeze()*(1-y + (sigm(theta.T@ X.T).squeeze() < 0.5) > 0)\n",
    "plot_decision_boundary(trues[trues != 0], falses[falses != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857142857142857"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train accuracy\n",
    "accuracy_score(y, pred_logistic_regr(theta, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717948717948718"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "accuracy_score(y_test, pred_logistic_regr(theta, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for test  data\n",
    "trues = sigm(theta.T@ X_test.T).squeeze()*((y_test + sigm(theta.T@ X_test.T).squeeze() >=0.5) > 0)\n",
    "falses = sigm(theta.T@ X_test.T).squeeze()*(1-y_test + (sigm(theta.T@ X_test.T).squeeze() < 0.5) > 0)\n",
    "plot_decision_boundary(trues[trues != 0], falses[falses != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_lr = lr.predict(X_test)\n",
    "y_test_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7538461538461538"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717948717948718"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
