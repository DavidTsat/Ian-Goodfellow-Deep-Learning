{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes classifier\n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([np.random.rand(1) + 2 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "y2 = np.array([np.random.rand(1) + 2.4 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "y3 = np.array([np.random.rand(1) + 1.4 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "\n",
    "x1 = np.array(range(len(y1)))\n",
    "x2 = np.array([c+50 for c in range(len(y2))])\n",
    "x3 = np.array([c+80 for c in range(len(y3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data matrix \n",
    "a1 = np.concatenate((x1.reshape(-1,1),y1,np.array([0 for c in range(len(x1))]).reshape(-1,1)), 1)\n",
    "a2 = np.concatenate((x2.reshape(-1,1),y2,np.array([1 for c in range(len(x2))]).reshape(-1,1)), 1)\n",
    "a3 = np.concatenate((x3.reshape(-1,1),y3,np.array([2 for c in range(len(x3))]).reshape(-1,1)), 1)\n",
    "\n",
    "A = np.concatenate((a1,a2,a3), 0).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((231, 3), 90, 68, 73)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, y1.shape[0], y2.shape[0], y3.shape[0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0. ,   2.8,   0. ],\n",
       "       [  1. ,   2.2,   0. ],\n",
       "       [  2. ,   2.3,   0. ],\n",
       "       [  3. ,   2.3,   0. ],\n",
       "       [  4. ,   3. ,   0. ],\n",
       "       [  5. ,   2.2,   0. ],\n",
       "       [  6. ,   2.9,   0. ],\n",
       "       [  7. ,   2.7,   0. ],\n",
       "       [  8. ,   2.9,   0. ],\n",
       "       [  9. ,   2.6,   0. ],\n",
       "       [ 10. ,   2.2,   0. ],\n",
       "       [ 11. ,   2.3,   0. ],\n",
       "       [ 12. ,   2.6,   0. ],\n",
       "       [ 13. ,   2.5,   0. ],\n",
       "       [ 14. ,   2.1,   0. ],\n",
       "       [ 15. ,   2.4,   0. ],\n",
       "       [ 16. ,   2.8,   0. ],\n",
       "       [ 17. ,   3. ,   0. ],\n",
       "       [ 18. ,   2.1,   0. ],\n",
       "       [ 19. ,   2.9,   0. ],\n",
       "       [ 20. ,   2.1,   0. ],\n",
       "       [ 21. ,   3. ,   0. ],\n",
       "       [ 22. ,   2.7,   0. ],\n",
       "       [ 23. ,   2.2,   0. ],\n",
       "       [ 24. ,   2.3,   0. ],\n",
       "       [ 25. ,   2.7,   0. ],\n",
       "       [ 26. ,   2.7,   0. ],\n",
       "       [ 27. ,   2.5,   0. ],\n",
       "       [ 28. ,   2. ,   0. ],\n",
       "       [ 29. ,   2.1,   0. ],\n",
       "       [ 30. ,   2.6,   0. ],\n",
       "       [ 31. ,   2.5,   0. ],\n",
       "       [ 32. ,   2.4,   0. ],\n",
       "       [ 33. ,   2.8,   0. ],\n",
       "       [ 34. ,   2. ,   0. ],\n",
       "       [ 35. ,   2.5,   0. ],\n",
       "       [ 36. ,   2.9,   0. ],\n",
       "       [ 37. ,   2.2,   0. ],\n",
       "       [ 38. ,   2.2,   0. ],\n",
       "       [ 39. ,   2. ,   0. ],\n",
       "       [ 40. ,   2.1,   0. ],\n",
       "       [ 41. ,   2.1,   0. ],\n",
       "       [ 42. ,   2.4,   0. ],\n",
       "       [ 43. ,   2.8,   0. ],\n",
       "       [ 44. ,   2.3,   0. ],\n",
       "       [ 45. ,   2. ,   0. ],\n",
       "       [ 46. ,   2.1,   0. ],\n",
       "       [ 47. ,   2.6,   0. ],\n",
       "       [ 48. ,   2.7,   0. ],\n",
       "       [ 49. ,   2.4,   0. ],\n",
       "       [ 50. ,   2.6,   0. ],\n",
       "       [ 51. ,   2.8,   0. ],\n",
       "       [ 52. ,   2.6,   0. ],\n",
       "       [ 53. ,   2.9,   0. ],\n",
       "       [ 54. ,   2.2,   0. ],\n",
       "       [ 55. ,   2.3,   0. ],\n",
       "       [ 56. ,   2.5,   0. ],\n",
       "       [ 57. ,   2.6,   0. ],\n",
       "       [ 58. ,   3. ,   0. ],\n",
       "       [ 59. ,   2.6,   0. ],\n",
       "       [ 60. ,   2. ,   0. ],\n",
       "       [ 61. ,   2.2,   0. ],\n",
       "       [ 62. ,   2.9,   0. ],\n",
       "       [ 63. ,   2.3,   0. ],\n",
       "       [ 64. ,   2.7,   0. ],\n",
       "       [ 65. ,   2.3,   0. ],\n",
       "       [ 66. ,   2.1,   0. ],\n",
       "       [ 67. ,   2.9,   0. ],\n",
       "       [ 68. ,   2.6,   0. ],\n",
       "       [ 69. ,   2.4,   0. ],\n",
       "       [ 70. ,   2.5,   0. ],\n",
       "       [ 71. ,   2.1,   0. ],\n",
       "       [ 72. ,   2. ,   0. ],\n",
       "       [ 73. ,   2.7,   0. ],\n",
       "       [ 74. ,   2.3,   0. ],\n",
       "       [ 75. ,   2.3,   0. ],\n",
       "       [ 76. ,   2.2,   0. ],\n",
       "       [ 77. ,   2.1,   0. ],\n",
       "       [ 78. ,   2.8,   0. ],\n",
       "       [ 79. ,   2.3,   0. ],\n",
       "       [ 80. ,   2.7,   0. ],\n",
       "       [ 81. ,   2.4,   0. ],\n",
       "       [ 82. ,   3. ,   0. ],\n",
       "       [ 83. ,   2.1,   0. ],\n",
       "       [ 84. ,   2.9,   0. ],\n",
       "       [ 85. ,   2.7,   0. ],\n",
       "       [ 86. ,   2.3,   0. ],\n",
       "       [ 87. ,   2.9,   0. ],\n",
       "       [ 88. ,   2.5,   0. ],\n",
       "       [ 89. ,   2.6,   0. ],\n",
       "       [ 50. ,   3.1,   1. ],\n",
       "       [ 51. ,   3.1,   1. ],\n",
       "       [ 52. ,   3.3,   1. ],\n",
       "       [ 53. ,   2.6,   1. ],\n",
       "       [ 54. ,   2.7,   1. ],\n",
       "       [ 55. ,   2.5,   1. ],\n",
       "       [ 56. ,   2.4,   1. ],\n",
       "       [ 57. ,   3. ,   1. ],\n",
       "       [ 58. ,   2.8,   1. ],\n",
       "       [ 59. ,   2.8,   1. ],\n",
       "       [ 60. ,   2.4,   1. ],\n",
       "       [ 61. ,   2.8,   1. ],\n",
       "       [ 62. ,   2.6,   1. ],\n",
       "       [ 63. ,   3. ,   1. ],\n",
       "       [ 64. ,   3.3,   1. ],\n",
       "       [ 65. ,   2.7,   1. ],\n",
       "       [ 66. ,   3.2,   1. ],\n",
       "       [ 67. ,   2.7,   1. ],\n",
       "       [ 68. ,   3.3,   1. ],\n",
       "       [ 69. ,   2.5,   1. ],\n",
       "       [ 70. ,   3. ,   1. ],\n",
       "       [ 71. ,   2.9,   1. ],\n",
       "       [ 72. ,   2.8,   1. ],\n",
       "       [ 73. ,   2.8,   1. ],\n",
       "       [ 74. ,   3.1,   1. ],\n",
       "       [ 75. ,   3. ,   1. ],\n",
       "       [ 76. ,   2.8,   1. ],\n",
       "       [ 77. ,   2.4,   1. ],\n",
       "       [ 78. ,   3.3,   1. ],\n",
       "       [ 79. ,   2.5,   1. ],\n",
       "       [ 80. ,   3.4,   1. ],\n",
       "       [ 81. ,   2.5,   1. ],\n",
       "       [ 82. ,   3.1,   1. ],\n",
       "       [ 83. ,   3.3,   1. ],\n",
       "       [ 84. ,   3. ,   1. ],\n",
       "       [ 85. ,   2.6,   1. ],\n",
       "       [ 86. ,   2.5,   1. ],\n",
       "       [ 87. ,   2.8,   1. ],\n",
       "       [ 88. ,   2.6,   1. ],\n",
       "       [ 89. ,   2.6,   1. ],\n",
       "       [ 90. ,   2.5,   1. ],\n",
       "       [ 91. ,   2.5,   1. ],\n",
       "       [ 92. ,   2.8,   1. ],\n",
       "       [ 93. ,   2.6,   1. ],\n",
       "       [ 94. ,   3.3,   1. ],\n",
       "       [ 95. ,   2.5,   1. ],\n",
       "       [ 96. ,   3.2,   1. ],\n",
       "       [ 97. ,   3.1,   1. ],\n",
       "       [ 98. ,   2.7,   1. ],\n",
       "       [ 99. ,   3.4,   1. ],\n",
       "       [100. ,   3.4,   1. ],\n",
       "       [101. ,   3. ,   1. ],\n",
       "       [102. ,   3.3,   1. ],\n",
       "       [103. ,   2.8,   1. ],\n",
       "       [104. ,   3.3,   1. ],\n",
       "       [105. ,   2.6,   1. ],\n",
       "       [106. ,   3.1,   1. ],\n",
       "       [107. ,   3.3,   1. ],\n",
       "       [108. ,   2.4,   1. ],\n",
       "       [109. ,   3.3,   1. ],\n",
       "       [110. ,   2.8,   1. ],\n",
       "       [111. ,   2.4,   1. ],\n",
       "       [112. ,   2.5,   1. ],\n",
       "       [113. ,   2.9,   1. ],\n",
       "       [114. ,   3. ,   1. ],\n",
       "       [115. ,   3. ,   1. ],\n",
       "       [116. ,   2.6,   1. ],\n",
       "       [117. ,   3. ,   1. ],\n",
       "       [ 80. ,   1.4,   2. ],\n",
       "       [ 81. ,   1.9,   2. ],\n",
       "       [ 82. ,   1.9,   2. ],\n",
       "       [ 83. ,   1.9,   2. ],\n",
       "       [ 84. ,   1.8,   2. ],\n",
       "       [ 85. ,   1.6,   2. ],\n",
       "       [ 86. ,   1.4,   2. ],\n",
       "       [ 87. ,   1.6,   2. ],\n",
       "       [ 88. ,   2.2,   2. ],\n",
       "       [ 89. ,   1.9,   2. ],\n",
       "       [ 90. ,   2.3,   2. ],\n",
       "       [ 91. ,   1.4,   2. ],\n",
       "       [ 92. ,   2. ,   2. ],\n",
       "       [ 93. ,   1.6,   2. ],\n",
       "       [ 94. ,   2.2,   2. ],\n",
       "       [ 95. ,   2.3,   2. ],\n",
       "       [ 96. ,   1.6,   2. ],\n",
       "       [ 97. ,   2. ,   2. ],\n",
       "       [ 98. ,   1.8,   2. ],\n",
       "       [ 99. ,   2.2,   2. ],\n",
       "       [100. ,   2.3,   2. ],\n",
       "       [101. ,   1.5,   2. ],\n",
       "       [102. ,   2.2,   2. ],\n",
       "       [103. ,   1.5,   2. ],\n",
       "       [104. ,   1.5,   2. ],\n",
       "       [105. ,   1.9,   2. ],\n",
       "       [106. ,   2.1,   2. ],\n",
       "       [107. ,   2.1,   2. ],\n",
       "       [108. ,   2.1,   2. ],\n",
       "       [109. ,   1.5,   2. ],\n",
       "       [110. ,   1.4,   2. ],\n",
       "       [111. ,   1.7,   2. ],\n",
       "       [112. ,   1.7,   2. ],\n",
       "       [113. ,   2.3,   2. ],\n",
       "       [114. ,   2. ,   2. ],\n",
       "       [115. ,   1.4,   2. ],\n",
       "       [116. ,   2.3,   2. ],\n",
       "       [117. ,   1.9,   2. ],\n",
       "       [118. ,   1.6,   2. ],\n",
       "       [119. ,   2.2,   2. ],\n",
       "       [120. ,   1.6,   2. ],\n",
       "       [121. ,   1.9,   2. ],\n",
       "       [122. ,   1.4,   2. ],\n",
       "       [123. ,   2.3,   2. ],\n",
       "       [124. ,   2. ,   2. ],\n",
       "       [125. ,   2.1,   2. ],\n",
       "       [126. ,   2.1,   2. ],\n",
       "       [127. ,   2. ,   2. ],\n",
       "       [128. ,   2.3,   2. ],\n",
       "       [129. ,   1.9,   2. ],\n",
       "       [130. ,   1.9,   2. ],\n",
       "       [131. ,   1.5,   2. ],\n",
       "       [132. ,   1.4,   2. ],\n",
       "       [133. ,   1.5,   2. ],\n",
       "       [134. ,   2. ,   2. ],\n",
       "       [135. ,   2.3,   2. ],\n",
       "       [136. ,   1.6,   2. ],\n",
       "       [137. ,   1.9,   2. ],\n",
       "       [138. ,   2. ,   2. ],\n",
       "       [139. ,   1.6,   2. ],\n",
       "       [140. ,   1.8,   2. ],\n",
       "       [141. ,   1.6,   2. ],\n",
       "       [142. ,   1.5,   2. ],\n",
       "       [143. ,   1.9,   2. ],\n",
       "       [144. ,   1.9,   2. ],\n",
       "       [145. ,   1.5,   2. ],\n",
       "       [146. ,   1.7,   2. ],\n",
       "       [147. ,   2.3,   2. ],\n",
       "       [148. ,   1.4,   2. ],\n",
       "       [149. ,   1.9,   2. ],\n",
       "       [150. ,   1.7,   2. ],\n",
       "       [151. ,   2. ,   2. ],\n",
       "       [152. ,   2.2,   2. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(x1, y1, s=10, c='b', marker=\"o\", label='first')\n",
    "ax1.scatter(x2, y2, s=10, c='g', marker=\"o\", label='second')\n",
    "ax1.scatter(x3, y3, s=10, c='r', marker=\"o\", label='third')\n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClass:\n",
    "    def __init__(self, A):\n",
    "        self.data = A\n",
    "        self.classes = self.data.label.unique()\n",
    "        self.class_data = self.__separate_data_by_classes__()\n",
    "        self.class_probs = self.__get_probs_of_each_class__()\n",
    "        self.class_means = self.__get_mean_of_each_class__()\n",
    "        self.class_vars = self.__get_variances_class__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __separate_data_by_classes__(self):\n",
    "        c_d = {}\n",
    "        for c in self.classes:\n",
    "            c_d[c] = (self.data.loc[self.data['label'] == c]).values[:,:-1]\n",
    "        return c_d\n",
    "    \n",
    "    def __get_probs_of_each_class__(self):\n",
    "        probs = []\n",
    "        for c in self.classes:\n",
    "            probs.append(len(self.class_data[c])/self.data.shape[0])\n",
    "        return np.array(probs)\n",
    "    \n",
    "    def __get_mean_of_each_class__(self):\n",
    "        means = {}\n",
    "        for c in self.classes:\n",
    "            m = []\n",
    "            for i in range(self.data.shape[1] - 1):\n",
    "                m.append(self.class_data[c][:,i].mean())\n",
    "            means[c] = m\n",
    "        return means\n",
    "    \n",
    "    def __get_variances_class__(self):\n",
    "        variances = {}\n",
    "        for c in self.classes:\n",
    "            va = []\n",
    "            for i in range(self.data.shape[1] - 1):\n",
    "                va.append(self.class_data[c][:,i].var()+1e-5) # to avoid division by zero\n",
    "            variances[c] = va\n",
    "        return variances\n",
    "    \n",
    "    def __get_gaussian_prob__(self, x, mean_, var_):\n",
    "        somnojitels = []\n",
    "        for i in range(x.shape[1]):\n",
    "            x_feat = x[:,i]\n",
    "            somnojitels.append((1/np.sqrt(2*np.pi*var_[i])*np.exp(-1/(2*var_[i])*(x_feat-mean_[i])**2)))\n",
    "        return np.array(somnojitels).prod()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        res = []\n",
    "        for row in x:\n",
    "            pr = []\n",
    "            for c in self.classes:\n",
    "                pr.append(self.class_probs[c]*self.__get_gaussian_prob__(row.reshape(1,-1), self.class_means[c], self.class_vars[c]))\n",
    "            res.append(np.argmax(pr))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(A)\n",
    "df.columns = ['x', 'y', 'label']\n",
    "df = df.astype({'x': 'float32', 'y': 'float32', 'label': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x    y  label\n",
       "0  0.0  2.8      0\n",
       "1  1.0  2.2      0\n",
       "2  2.0  2.3      0\n",
       "3  3.0  2.3      0\n",
       "4  4.0  3.0      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayesClass(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38961039, 0.29437229, 0.31601732])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [674.9166766666666, 0.09152112401750806],\n",
       " 1: [385.25001, 0.09508568716178274],\n",
       " 2: [444.00001, 0.08688933347086189]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.class_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [44.5, 2.4733333269755047],\n",
       " 1: [83.5, 2.869117631631739],\n",
       " 2: [116.0, 1.8479451937218234]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.class_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_label = nb.predict(A[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_class_label [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print('predicted_class_label', predicted_class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831168831168831"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predicted_class_label, A[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(A[:,:-1], A[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 2. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "sklearn_predicted = clf.predict(A[:,:-1])\n",
    "print(sklearn_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831168831168831"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sklearn_predicted, A[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "\n",
    "y1_test = np.array([np.random.rand(1) + 2 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "y2_test = np.array([np.random.rand(1) + 2.4 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "y3_test = np.array([np.random.rand(1) + 1.4 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "\n",
    "x1_test = np.array(range(len(y1_test)))\n",
    "x2_test = np.array([c+50 for c in range(len(y2_test))])\n",
    "x3_test = np.array([c+80 for c in range(len(y3_test))])\n",
    "\n",
    "a1_test = np.concatenate((x1_test.reshape(-1,1),y1_test,np.array([0 for c in range(len(x1_test))]).reshape(-1,1)), 1)\n",
    "a2_test = np.concatenate((x2_test.reshape(-1,1),y2_test,np.array([1 for c in range(len(x2_test))]).reshape(-1,1)), 1)\n",
    "a3_test = np.concatenate((x3_test.reshape(-1,1),y3_test,np.array([2 for c in range(len(x3_test))]).reshape(-1,1)), 1)\n",
    "\n",
    "A_test = np.concatenate((a1_test,a2_test,a3_test), 0).round(1)\n",
    "# np.random.shuffle(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0. ,   2.9,   0. ],\n",
       "       [  1. ,   2.4,   0. ],\n",
       "       [  2. ,   3. ,   0. ],\n",
       "       [  3. ,   2.5,   0. ],\n",
       "       [  4. ,   2.4,   0. ],\n",
       "       [  5. ,   2.8,   0. ],\n",
       "       [  6. ,   2. ,   0. ],\n",
       "       [  7. ,   2.5,   0. ],\n",
       "       [  8. ,   2.7,   0. ],\n",
       "       [  9. ,   2.8,   0. ],\n",
       "       [ 10. ,   2.3,   0. ],\n",
       "       [ 11. ,   2.3,   0. ],\n",
       "       [ 12. ,   2.1,   0. ],\n",
       "       [ 13. ,   2. ,   0. ],\n",
       "       [ 14. ,   2.7,   0. ],\n",
       "       [ 15. ,   2.4,   0. ],\n",
       "       [ 16. ,   2.4,   0. ],\n",
       "       [ 17. ,   2.2,   0. ],\n",
       "       [ 18. ,   2.3,   0. ],\n",
       "       [ 19. ,   2.7,   0. ],\n",
       "       [ 20. ,   2.6,   0. ],\n",
       "       [ 21. ,   2.8,   0. ],\n",
       "       [ 22. ,   2.8,   0. ],\n",
       "       [ 23. ,   2.6,   0. ],\n",
       "       [ 24. ,   2.6,   0. ],\n",
       "       [ 25. ,   2.8,   0. ],\n",
       "       [ 26. ,   2.7,   0. ],\n",
       "       [ 27. ,   2.4,   0. ],\n",
       "       [ 28. ,   3. ,   0. ],\n",
       "       [ 29. ,   2.6,   0. ],\n",
       "       [ 30. ,   2.7,   0. ],\n",
       "       [ 31. ,   2.7,   0. ],\n",
       "       [ 32. ,   3. ,   0. ],\n",
       "       [ 33. ,   2.9,   0. ],\n",
       "       [ 34. ,   2.8,   0. ],\n",
       "       [ 35. ,   2.1,   0. ],\n",
       "       [ 36. ,   2.6,   0. ],\n",
       "       [ 37. ,   2.7,   0. ],\n",
       "       [ 38. ,   2.4,   0. ],\n",
       "       [ 39. ,   2.8,   0. ],\n",
       "       [ 40. ,   2.3,   0. ],\n",
       "       [ 41. ,   2.9,   0. ],\n",
       "       [ 42. ,   2.2,   0. ],\n",
       "       [ 43. ,   2.2,   0. ],\n",
       "       [ 44. ,   2.9,   0. ],\n",
       "       [ 45. ,   2. ,   0. ],\n",
       "       [ 46. ,   2.3,   0. ],\n",
       "       [ 47. ,   2.2,   0. ],\n",
       "       [ 48. ,   2.3,   0. ],\n",
       "       [ 49. ,   2.6,   0. ],\n",
       "       [ 50. ,   2.2,   0. ],\n",
       "       [ 51. ,   2.4,   0. ],\n",
       "       [ 52. ,   2.6,   0. ],\n",
       "       [ 53. ,   2.3,   0. ],\n",
       "       [ 54. ,   2.6,   0. ],\n",
       "       [ 55. ,   2.6,   0. ],\n",
       "       [ 56. ,   2.3,   0. ],\n",
       "       [ 57. ,   2.5,   0. ],\n",
       "       [ 58. ,   2.5,   0. ],\n",
       "       [ 59. ,   2.6,   0. ],\n",
       "       [ 60. ,   2.8,   0. ],\n",
       "       [ 61. ,   2.1,   0. ],\n",
       "       [ 62. ,   2.8,   0. ],\n",
       "       [ 63. ,   2.6,   0. ],\n",
       "       [ 50. ,   2.7,   1. ],\n",
       "       [ 51. ,   3.1,   1. ],\n",
       "       [ 52. ,   2.9,   1. ],\n",
       "       [ 53. ,   3.2,   1. ],\n",
       "       [ 54. ,   3. ,   1. ],\n",
       "       [ 55. ,   3.1,   1. ],\n",
       "       [ 56. ,   2.8,   1. ],\n",
       "       [ 57. ,   3.4,   1. ],\n",
       "       [ 58. ,   3.4,   1. ],\n",
       "       [ 59. ,   2.8,   1. ],\n",
       "       [ 60. ,   3. ,   1. ],\n",
       "       [ 61. ,   3.3,   1. ],\n",
       "       [ 62. ,   2.8,   1. ],\n",
       "       [ 63. ,   2.6,   1. ],\n",
       "       [ 64. ,   2.5,   1. ],\n",
       "       [ 65. ,   3.3,   1. ],\n",
       "       [ 66. ,   2.7,   1. ],\n",
       "       [ 67. ,   2.8,   1. ],\n",
       "       [ 68. ,   2.6,   1. ],\n",
       "       [ 69. ,   2.4,   1. ],\n",
       "       [ 70. ,   2.5,   1. ],\n",
       "       [ 71. ,   3.1,   1. ],\n",
       "       [ 72. ,   3.2,   1. ],\n",
       "       [ 73. ,   2.7,   1. ],\n",
       "       [ 74. ,   3.1,   1. ],\n",
       "       [ 75. ,   3.1,   1. ],\n",
       "       [ 76. ,   2.6,   1. ],\n",
       "       [ 77. ,   2.4,   1. ],\n",
       "       [ 78. ,   2.6,   1. ],\n",
       "       [ 79. ,   2.6,   1. ],\n",
       "       [ 80. ,   3.2,   1. ],\n",
       "       [ 81. ,   2.9,   1. ],\n",
       "       [ 82. ,   3.3,   1. ],\n",
       "       [ 83. ,   3.1,   1. ],\n",
       "       [ 84. ,   3.2,   1. ],\n",
       "       [ 85. ,   2.9,   1. ],\n",
       "       [ 86. ,   2.6,   1. ],\n",
       "       [ 87. ,   3.2,   1. ],\n",
       "       [ 88. ,   3.4,   1. ],\n",
       "       [ 89. ,   2.5,   1. ],\n",
       "       [ 90. ,   3.2,   1. ],\n",
       "       [ 91. ,   3. ,   1. ],\n",
       "       [ 92. ,   2.9,   1. ],\n",
       "       [ 93. ,   2.7,   1. ],\n",
       "       [ 94. ,   2.7,   1. ],\n",
       "       [ 95. ,   2.7,   1. ],\n",
       "       [ 96. ,   2.5,   1. ],\n",
       "       [ 97. ,   3.3,   1. ],\n",
       "       [ 98. ,   3.2,   1. ],\n",
       "       [ 99. ,   2.8,   1. ],\n",
       "       [100. ,   3.2,   1. ],\n",
       "       [101. ,   2.7,   1. ],\n",
       "       [102. ,   2.8,   1. ],\n",
       "       [103. ,   2.4,   1. ],\n",
       "       [104. ,   2.7,   1. ],\n",
       "       [105. ,   2.8,   1. ],\n",
       "       [106. ,   2.7,   1. ],\n",
       "       [107. ,   2.9,   1. ],\n",
       "       [108. ,   3.1,   1. ],\n",
       "       [109. ,   3.2,   1. ],\n",
       "       [110. ,   2.6,   1. ],\n",
       "       [111. ,   2.6,   1. ],\n",
       "       [112. ,   2.6,   1. ],\n",
       "       [113. ,   3.4,   1. ],\n",
       "       [114. ,   2.8,   1. ],\n",
       "       [115. ,   2.4,   1. ],\n",
       "       [116. ,   3.3,   1. ],\n",
       "       [117. ,   2.6,   1. ],\n",
       "       [118. ,   2.9,   1. ],\n",
       "       [119. ,   2.6,   1. ],\n",
       "       [120. ,   3.3,   1. ],\n",
       "       [121. ,   3.2,   1. ],\n",
       "       [122. ,   3.2,   1. ],\n",
       "       [123. ,   3.1,   1. ],\n",
       "       [124. ,   2.8,   1. ],\n",
       "       [125. ,   3.2,   1. ],\n",
       "       [126. ,   2.5,   1. ],\n",
       "       [127. ,   2.4,   1. ],\n",
       "       [128. ,   3. ,   1. ],\n",
       "       [129. ,   3.2,   1. ],\n",
       "       [130. ,   3.2,   1. ],\n",
       "       [131. ,   3.2,   1. ],\n",
       "       [132. ,   3.3,   1. ],\n",
       "       [133. ,   2.9,   1. ],\n",
       "       [134. ,   2.7,   1. ],\n",
       "       [135. ,   3.1,   1. ],\n",
       "       [ 80. ,   1.6,   2. ],\n",
       "       [ 81. ,   1.4,   2. ],\n",
       "       [ 82. ,   1.7,   2. ],\n",
       "       [ 83. ,   1.9,   2. ],\n",
       "       [ 84. ,   1.8,   2. ],\n",
       "       [ 85. ,   1.9,   2. ],\n",
       "       [ 86. ,   2. ,   2. ],\n",
       "       [ 87. ,   1.5,   2. ],\n",
       "       [ 88. ,   1.7,   2. ],\n",
       "       [ 89. ,   2.2,   2. ],\n",
       "       [ 90. ,   1.8,   2. ],\n",
       "       [ 91. ,   1.9,   2. ],\n",
       "       [ 92. ,   2.4,   2. ],\n",
       "       [ 93. ,   1.6,   2. ],\n",
       "       [ 94. ,   1.5,   2. ],\n",
       "       [ 95. ,   2.1,   2. ],\n",
       "       [ 96. ,   2. ,   2. ],\n",
       "       [ 97. ,   1.9,   2. ],\n",
       "       [ 98. ,   1.7,   2. ],\n",
       "       [ 99. ,   1.9,   2. ],\n",
       "       [100. ,   2.2,   2. ],\n",
       "       [101. ,   1.7,   2. ],\n",
       "       [102. ,   2.3,   2. ],\n",
       "       [103. ,   1.9,   2. ],\n",
       "       [104. ,   1.6,   2. ],\n",
       "       [105. ,   1.6,   2. ],\n",
       "       [106. ,   1.4,   2. ],\n",
       "       [107. ,   2. ,   2. ],\n",
       "       [108. ,   1.5,   2. ],\n",
       "       [109. ,   1.6,   2. ],\n",
       "       [110. ,   2.1,   2. ],\n",
       "       [111. ,   1.5,   2. ],\n",
       "       [112. ,   1.9,   2. ],\n",
       "       [113. ,   1.7,   2. ],\n",
       "       [114. ,   1.7,   2. ],\n",
       "       [115. ,   2.3,   2. ],\n",
       "       [116. ,   2.2,   2. ],\n",
       "       [117. ,   2.3,   2. ],\n",
       "       [118. ,   2.3,   2. ],\n",
       "       [119. ,   1.4,   2. ],\n",
       "       [120. ,   1.5,   2. ],\n",
       "       [121. ,   2.3,   2. ],\n",
       "       [122. ,   1.6,   2. ],\n",
       "       [123. ,   2.3,   2. ],\n",
       "       [124. ,   1.8,   2. ],\n",
       "       [125. ,   1.9,   2. ],\n",
       "       [126. ,   1.6,   2. ],\n",
       "       [127. ,   2.1,   2. ],\n",
       "       [128. ,   1.8,   2. ],\n",
       "       [129. ,   1.8,   2. ],\n",
       "       [130. ,   1.5,   2. ],\n",
       "       [131. ,   2.1,   2. ],\n",
       "       [132. ,   1.5,   2. ],\n",
       "       [133. ,   2. ,   2. ],\n",
       "       [134. ,   1.8,   2. ],\n",
       "       [135. ,   2.4,   2. ],\n",
       "       [136. ,   1.7,   2. ],\n",
       "       [137. ,   1.5,   2. ],\n",
       "       [138. ,   2.3,   2. ],\n",
       "       [139. ,   2.3,   2. ],\n",
       "       [140. ,   1.8,   2. ],\n",
       "       [141. ,   1.7,   2. ],\n",
       "       [142. ,   2.1,   2. ],\n",
       "       [143. ,   1.7,   2. ],\n",
       "       [144. ,   2.3,   2. ],\n",
       "       [145. ,   2.3,   2. ],\n",
       "       [146. ,   1.8,   2. ],\n",
       "       [147. ,   2.2,   2. ],\n",
       "       [148. ,   1.4,   2. ],\n",
       "       [149. ,   2. ,   2. ],\n",
       "       [150. ,   1.6,   2. ],\n",
       "       [151. ,   2. ,   2. ],\n",
       "       [152. ,   2.2,   2. ],\n",
       "       [153. ,   1.9,   2. ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = A_test[:,:-1]\n",
    "y_test = A_test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "sklearn_predicted_test = clf.predict(X_test)\n",
    "print(sklearn_predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sklearn_predicted_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  2,  0],\n",
       "       [10, 73,  3],\n",
       "       [ 0,  1, 73]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat(y_pred, y_test):\n",
    "    classes = set(map(int, list(y_pred) + list(y_test)))\n",
    "    conf_m = np.zeros((len(classes), len(classes)))\n",
    "    for class_ in classes:\n",
    "        for class2_ in classes:\n",
    "            conf_m[class_, class2_] = ((np.array(y_pred_test) == class_) * (np.array(y_test) == class2_)).sum()\n",
    "    return conf_m.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62, 10,  0],\n",
       "       [ 2, 73,  1],\n",
       "       [ 0,  3, 73]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "recall = np.diag(cm) / np.sum(cm, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96875   , 0.84883721, 0.98648649])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86111111, 0.96052632, 0.96052632])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9310252507966985"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = 2*np.mean(precision) * np.mean(recall)/(np.mean(precision) + np.mean(recall))\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cm = cm[:2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  2],\n",
       "       [10, 73]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = binary_cm[0,0]/binary_cm.sum(axis=1)[0]\n",
    "FPR = binary_cm[1,0]/(binary_cm[1,0] + binary_cm[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96875, 0.12048192771084337)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPR, FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3 - Decision tree                                                                                                    \n",
    "https://en.wikipedia.org/wiki/ID3_algorithm                                                                               \n",
    "https://www.youtube.com/watch?v=0wDu42qH1PY&list=PLJOzdkh8T5krxc4HsHbB8g8f0hu7973fK&index=9                                   \n",
    "https://www.python-course.eu/Decision_Trees.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using the code from the link above, and we'll update it slightly to adapt another impurity function - Gini\n",
    "\n",
    "data = pd.DataFrame({\"toothed\":[\"True\",\"True\",\"True\",\"False\",\"True\",\"True\",\"True\",\"True\",\"True\",\"False\"],\n",
    "                     \"hair\":[\"True\",\"True\",\"False\",\"True\",\"True\",\"True\",\"False\",\"False\",\"True\",\"False\"],\n",
    "                     \"breathes\":[\"True\",\"True\",\"True\",\"True\",\"True\",\"True\",\"False\",\"True\",\"True\",\"True\"],\n",
    "                     \"legs\":[\"True\",\"True\",\"False\",\"True\",\"True\",\"True\",\"False\",\"False\",\"True\",\"True\"],\n",
    "                     \"species\":[\"Mammal\",\"Mammal\",\"Reptile\",\"Mammal\",\"Mammal\",\"Mammal\",\"Reptile\",\"Reptile\",\"Mammal\",\"Reptile\"]}, \n",
    "                    columns=[\"toothed\",\"hair\",\"breathes\",\"legs\",\"species\"])\n",
    "\n",
    "features = data[[\"toothed\",\"hair\",\"breathes\",\"legs\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.species = data.species.map({'Mammal': 0, 'Reptile': 1})\n",
    "target = data[\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toothed</th>\n",
       "      <th>hair</th>\n",
       "      <th>breathes</th>\n",
       "      <th>legs</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  toothed   hair breathes   legs  species\n",
       "0    True   True     True   True        0\n",
       "1    True   True     True   True        0\n",
       "2    True  False     True  False        1\n",
       "3   False   True     True   True        0\n",
       "4    True   True     True   True        0\n",
       "5    True   True     True   True        0\n",
       "6    True  False    False  False        1\n",
       "7    True  False     True  False        1\n",
       "8    True   True     True   True        0\n",
       "9   False  False     True   True        1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "\n",
    "ax.plot(np.linspace(0.01,1),np.log2(np.linspace(0.01,1)))\n",
    "ax.set_xlabel(\"P(x)\")\n",
    "ax.set_ylabel(\"log2(P(x))\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impurity(target_col, type_='Entr'):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a dataset.\n",
    "    The only parameter of this function is the target_col parameter which specifies the target column\n",
    "    \"\"\"\n",
    "    elements, counts = np.unique(target_col,return_counts = True)\n",
    "#     print(elements, counts)\n",
    "    \n",
    "    if type_ == 'Entr':\n",
    "        entropy_ = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "        return entropy_\n",
    "    elif type_ == 'Gini':\n",
    "        gini_ = np.array([2*c/len(target_col)*(1-c/len(target_col)) for c in counts]).sum()\n",
    "        return gini_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impurity(data.toothed, type_='Gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InfoGain(data, split_attribute_name, target_name, type_='Entr'):\n",
    "    \"\"\"\n",
    "    Calculate the information gain of a dataset. This function takes three parameters:\n",
    "    1. data = The dataset for whose feature the IG should be calculated\n",
    "    2. split_attribute_name = the name of the feature for which the information gain should be calculated\n",
    "    3. target_name = the name of the target feature. The default for this example is \"class\"\n",
    "    \"\"\"    \n",
    "    #Calculate the entropy of the total dataset\n",
    "    total_entropy = impurity(data[target_name])\n",
    "#     print(total_entropy)\n",
    "    \n",
    "    #Calculate the values and the corresponding counts for the split attribute \n",
    "    vals,counts = np.unique(data[split_attribute_name],return_counts=True)\n",
    "#     print(vals,counts)\n",
    "    #Calculate the weighted entropy\n",
    "    Weighted_Entropy = np.array([len(data.loc[data[split_attribute_name]==v])/len(data[split_attribute_name])*impurity(data.loc[data[split_attribute_name]==v][target_name].values, type_=type_) for v in vals])\n",
    "#     Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*impurity(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "\n",
    "#     Calculate the information gain\n",
    "    Information_Gain = total_entropy - Weighted_Entropy.sum()\n",
    "    return Information_Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def ID3(data, originaldata, features, imp_type='Entr', target_attribute_name=\"class\", parent_node_class = None):\n",
    "    \"\"\"\n",
    "    ID3 Algorithm: This function takes five paramters:\n",
    "    1. data = the data for which the ID3 algorithm should be run --> In the first run this equals the total dataset\n",
    " \n",
    "    2. originaldata = This is the original dataset needed to calculate the mode target feature value of the original dataset\n",
    "    in the case the dataset delivered by the first parameter is empty\n",
    "\n",
    "    3. features = the feature space of the dataset . This is needed for the recursive call since during the tree growing process\n",
    "    we have to remove features from our dataset --> Splitting at each node\n",
    "\n",
    "    4. target_attribute_name = the name of the target attribute\n",
    "\n",
    "    5. parent_node_class = This is the value or class of the mode target feature value of the parent node for a specific node. This is \n",
    "    also needed for the recursive call since if the splitting leads to a situation that there are no more features left in the feature\n",
    "    space, we want to return the mode target feature value of the direct parent node.\n",
    "    \"\"\"   \n",
    "    #Define the stopping criteria --> If one of this is satisfied, we want to return a leaf node#\n",
    "    \n",
    "    #If all target_values have the same value, return this value\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    #If the dataset is empty, return the mode target feature value in the original dataset\n",
    "    elif len(data)==0:\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    \n",
    "    #If the feature space is empty, return the mode target feature value of the direct parent node --> Note that\n",
    "    #the direct parent node is that node which has called the current run of the ID3 algorithm and hence\n",
    "    #the mode target feature value is stored in the parent_node_class variable.\n",
    "    \n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    #If none of the above holds true, grow the tree!\n",
    "    \n",
    "    else:\n",
    "        #Set the default value for this node --> The mode target feature value of the current node\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "        \n",
    "        #Select the feature which best splits the dataset\n",
    "        item_values = [InfoGain(data,feature,target_attribute_name,type_=imp_type) for feature in features] #Return the information gain values for the features in the dataset\n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "#         print('best_feature', best_feature)\n",
    "        #Create the tree structure. The root gets the name of the feature (best_feature) with the maximum information\n",
    "        #gain in the first run\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        \n",
    "        #Remove the feature with the best inforamtion gain from the feature space\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        #Grow a branch under the root node for each possible value of the root node feature\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            #Split the dataset along the value of the feature with the largest information gain and therwith create sub_datasets\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            #Call the ID3 algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\n",
    "            subtree = ID3(sub_data,originaldata,features,imp_type,target_attribute_name, parent_node_class)\n",
    "            \n",
    "            #Add the sub tree, grown from the sub_dataset to the tree under the root node\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return(tree)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query,tree,default = 1):\n",
    "    \"\"\"\n",
    "    Prediction of a new/unseen query instance. This takes two parameters:\n",
    "    1. The query instance as a dictionary of the shape {\"feature_name\":feature_value,...}\n",
    "\n",
    "    2. The tree \n",
    "\n",
    "\n",
    "    We do this also in a recursive manner. That is, we wander down the tree and check if we have reached a leaf or if we are still in a sub tree. \n",
    "    Since this is a important step to understand, the single steps are extensively commented below.\n",
    "\n",
    "    1.Check for every feature in the query instance if this feature is existing in the tree.keys() for the first call, \n",
    "    tree.keys() only contains the value for the root node \n",
    "    --> if this value is not existing, we can not make a prediction and have to \n",
    "    return the default value which is the majority value of the target feature\n",
    "\n",
    "    2. First of all we have to take care of a important fact: Since we train our model with a database A and then show our model\n",
    "    a unseen query it may happen that the feature values of these query are not existing in our tree model because non of the\n",
    "    training instances has had such a value for this specific feature. \n",
    "    For instance imagine the situation where your model has only seen animals with one to four\n",
    "    legs - The \"legs\" node in your model will only have four outgoing branches (from one to four). If you now show your model\n",
    "    a new instance (animal) which has for the legs feature the vale 5, you have to tell your model what to do in such a \n",
    "    situation because otherwise there is no classification possible because in the classification step you try to \n",
    "    run down the outgoing branch with the value 5 but there is no such a branch. Hence: Error and no Classification!\n",
    "    We can address this issue with a classification value of for instance (999) which tells us that there is no classification\n",
    "    possible or we assign the most frequent target feature value of our dataset used to train the model. Or, in for instance \n",
    "    medical application we can return the most worse case - just to make sure... \n",
    "    We can also return the most frequent value of the direct parent node. To make a long story short, we have to tell the model \n",
    "    what to do in this situation.\n",
    "    In our example, since we are dealing with animal species where a false classification is not that critical, we will assign\n",
    "    the value 1 which is the value for the mammal species (for convenience).\n",
    "\n",
    "    3. Address the key in the tree which fits the value for key --> Note that key == the features in the query. \n",
    "    Because we want the tree to predict the value which is hidden under the key value (imagine you have a drawn tree model on \n",
    "    the table in front of you and you have a query instance for which you want to predict the target feature \n",
    "    - What are you doing? - Correct:\n",
    "    You start at the root node and wander down the tree comparing your query to the node values. Hence you want to have the\n",
    "    value which is hidden under the current node. If this is a leaf, perfect, otherwise you wander the tree deeper until you\n",
    "    get to a leaf node. \n",
    "    Though, you want to have this \"something\" [either leaf or sub_tree] which is hidden under the current node\n",
    "    and hence we must address the node in the tree which == the key value from our query instance. \n",
    "    This is done with tree[keys]. Next you want to run down the branch of this node which is equal to the value given \"behind\"\n",
    "    the key value of your query instance e.g. if you find \"legs\" == to tree.keys() that is, for the first run == the root node.\n",
    "    You want to run deeper and therefore you have to address the branch at your node whose value is == to the value behind key.\n",
    "    This is done with query[key] e.g. query[key] == query['legs'] == 0 --> Therewith we run down the branch of the node with the\n",
    "    value 0. Summarized, in this step we want to address the node which is hidden behind a specific branch of the root node (in the first run)\n",
    "    this is done with: result = [key][query[key]]\n",
    "\n",
    "    4. As said in the 2. step, we run down the tree along nodes and branches until we get to a leaf node.\n",
    "    That is, if result = tree[key][query[key]] returns another tree object (we have represented this by a dict object --> \n",
    "    that is if result is a dict object) we know that we have not arrived at a root node and have to run deeper the tree. \n",
    "    Okay... Look at your drawn tree in front of you... what are you doing?...well, you run down the next branch... \n",
    "    exactly as we have done it above with the slight difference that we already have passed a node and therewith \n",
    "    have to run only a fraction of the tree --> You clever guy! That \"fraction of the tree\" is exactly what we have stored\n",
    "    under 'result'.\n",
    "    So we simply call our predict method using the same query instance (we do not have to drop any features from the query\n",
    "    instance since for instance the feature for the root node will not be available in any of the deeper sub_trees and hence \n",
    "    we will simply not find that feature) as well as the \"reduced / sub_tree\" stored in result.\n",
    "\n",
    "    SUMMARIZED: If we have a query instance consisting of values for features, we take this features and check if the \n",
    "    name of the root node is equal to one of the query features.\n",
    "    If this is true, we run down the root node outgoing branch whose value equals the value of query feature == the root node.\n",
    "    If we find at the end of this branch a leaf node (not a dict object) we return this value (this is our prediction).\n",
    "    If we instead find another node (== sub_tree == dict objct) we search in our query for the feature which equals the value \n",
    "    of that node. Next we look up the value of our query feature and run down the branch whose value is equal to the \n",
    "    query[key] == query feature value. And as you can see this is exactly the recursion we talked about\n",
    "    with the important fact that for each node we run down the tree, we check only the nodes and branches which are \n",
    "    below this node and do not run the whole tree beginning at the root node \n",
    "    --> This is why we re-call the classification function with 'result'\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #1.\n",
    "    for key in list(query.keys()):\n",
    "        if key in list(tree.keys()):\n",
    "            #2.\n",
    "            try:\n",
    "                result = tree[key][query[key]] \n",
    "            except:\n",
    "                return default\n",
    "  \n",
    "            #3.\n",
    "            result = tree[key][query[key]]\n",
    "            #4.\n",
    "            if isinstance(result,dict):\n",
    "                return predict(query,result)\n",
    "\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hair': {'False': 1.0, 'True': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the tree, Print the tree and predict the accuracy\n",
    "\"\"\"\n",
    "tree = ID3(data, data, data.columns[:-1], imp_type='Gini', target_attribute_name='species')\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = data.iloc[:,:-1].to_dict(orient = \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'toothed': 'True', 'hair': 'True', 'breathes': 'True', 'legs': 'True'},\n",
       " {'toothed': 'True', 'hair': 'True', 'breathes': 'True', 'legs': 'True'},\n",
       " {'toothed': 'True', 'hair': 'False', 'breathes': 'True', 'legs': 'False'},\n",
       " {'toothed': 'False', 'hair': 'True', 'breathes': 'True', 'legs': 'True'},\n",
       " {'toothed': 'True', 'hair': 'True', 'breathes': 'True', 'legs': 'True'},\n",
       " {'toothed': 'True', 'hair': 'True', 'breathes': 'True', 'legs': 'True'},\n",
       " {'toothed': 'True', 'hair': 'False', 'breathes': 'False', 'legs': 'False'},\n",
       " {'toothed': 'True', 'hair': 'False', 'breathes': 'True', 'legs': 'False'},\n",
       " {'toothed': 'True', 'hair': 'True', 'breathes': 'True', 'legs': 'True'},\n",
       " {'toothed': 'False', 'hair': 'False', 'breathes': 'True', 'legs': 'True'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the prediction accuracy\n",
    "\n",
    "predicted = pd.DataFrame(columns=[\"predicted\"]) \n",
    "    \n",
    "for i in range(len(data)):\n",
    "    predicted.loc[i,\"predicted\"] = predict(queries[i],tree,1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted\n",
       "0        0.0\n",
       "1        0.0\n",
       "2        1.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "5        0.0\n",
       "6        1.0\n",
       "7        1.0\n",
       "8        0.0\n",
       "9        1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    1\n",
       "7    1\n",
       "8    0\n",
       "9    1\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(target, predicted.predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [*data.columns[:-1], 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(['False', 'True'], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toothed</th>\n",
       "      <th>hair</th>\n",
       "      <th>breathes</th>\n",
       "      <th>legs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toothed  hair  breathes  legs  label\n",
       "0        1     1         1     1      0\n",
       "1        1     1         1     1      0\n",
       "2        1     0         1     0      1\n",
       "3        0     1         1     1      0\n",
       "4        1     1         1     1      0\n",
       "5        1     1         1     1      0\n",
       "6        1     0         0     0      1\n",
       "7        1     0         1     0      1\n",
       "8        1     1         1     1      0\n",
       "9        0     0         1     1      1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayesClass(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 1, 0],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 1, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_nb = nb.predict(data.values[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(target, pr_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(data.values[:,:-1], target)\n",
    "clf.predict(data.values[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on the large random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(A_test)\n",
    "df_test.columns = ['x', 'y', 'label']\n",
    "df_test = df_test.astype({'x': 'float32', 'y': 'float32', 'label': 'int32'}).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x    y  label\n",
       "0  0.0  2.8      0\n",
       "1  1.0  2.2      0\n",
       "2  2.0  2.3      0\n",
       "3  3.0  2.3      0\n",
       "4  4.0  3.0      0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x    y  label\n",
       "0  0.0  2.9      0\n",
       "1  1.0  2.4      0\n",
       "2  2.0  3.0      0\n",
       "3  3.0  2.5      0\n",
       "4  4.0  2.4      0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': {1.4: 2.0,\n",
      "       1.5: 2.0,\n",
      "       1.6: 2.0,\n",
      "       1.7: 2.0,\n",
      "       1.8: 2.0,\n",
      "       1.9: 2.0,\n",
      "       2.0: {'x': {28.0: 0.0,\n",
      "                   34.0: 0.0,\n",
      "                   39.0: 0.0,\n",
      "                   45.0: 0.0,\n",
      "                   60.0: 0.0,\n",
      "                   72.0: 0.0,\n",
      "                   92.0: 2.0,\n",
      "                   97.0: 2.0,\n",
      "                   114.0: 2.0,\n",
      "                   124.0: 2.0,\n",
      "                   127.0: 2.0,\n",
      "                   134.0: 2.0,\n",
      "                   138.0: 2.0,\n",
      "                   151.0: 2.0}},\n",
      "       2.1: {'x': {14.0: 0.0,\n",
      "                   18.0: 0.0,\n",
      "                   20.0: 0.0,\n",
      "                   29.0: 0.0,\n",
      "                   40.0: 0.0,\n",
      "                   41.0: 0.0,\n",
      "                   46.0: 0.0,\n",
      "                   66.0: 0.0,\n",
      "                   71.0: 0.0,\n",
      "                   77.0: 0.0,\n",
      "                   83.0: 0.0,\n",
      "                   106.0: 2.0,\n",
      "                   107.0: 2.0,\n",
      "                   108.0: 2.0,\n",
      "                   125.0: 2.0,\n",
      "                   126.0: 2.0}},\n",
      "       2.2: {'x': {1.0: 0.0,\n",
      "                   5.0: 0.0,\n",
      "                   10.0: 0.0,\n",
      "                   23.0: 0.0,\n",
      "                   37.0: 0.0,\n",
      "                   38.0: 0.0,\n",
      "                   54.0: 0.0,\n",
      "                   61.0: 0.0,\n",
      "                   76.0: 0.0,\n",
      "                   88.0: 2.0,\n",
      "                   94.0: 2.0,\n",
      "                   99.0: 2.0,\n",
      "                   102.0: 2.0,\n",
      "                   119.0: 2.0,\n",
      "                   152.0: 2.0}},\n",
      "       2.3: {'x': {2.0: 0.0,\n",
      "                   3.0: 0.0,\n",
      "                   11.0: 0.0,\n",
      "                   24.0: 0.0,\n",
      "                   44.0: 0.0,\n",
      "                   55.0: 0.0,\n",
      "                   63.0: 0.0,\n",
      "                   65.0: 0.0,\n",
      "                   74.0: 0.0,\n",
      "                   75.0: 0.0,\n",
      "                   79.0: 0.0,\n",
      "                   86.0: 0.0,\n",
      "                   90.0: 2.0,\n",
      "                   95.0: 2.0,\n",
      "                   100.0: 2.0,\n",
      "                   113.0: 2.0,\n",
      "                   116.0: 2.0,\n",
      "                   123.0: 2.0,\n",
      "                   128.0: 2.0,\n",
      "                   135.0: 2.0,\n",
      "                   147.0: 2.0}},\n",
      "       2.4: {'x': {15.0: 0.0,\n",
      "                   32.0: 0.0,\n",
      "                   42.0: 0.0,\n",
      "                   49.0: 0.0,\n",
      "                   56.0: 1.0,\n",
      "                   60.0: 1.0,\n",
      "                   69.0: 0.0,\n",
      "                   77.0: 1.0,\n",
      "                   81.0: 0.0,\n",
      "                   108.0: 1.0,\n",
      "                   111.0: 1.0}},\n",
      "       2.5: {'x': {13.0: 0.0,\n",
      "                   27.0: 0.0,\n",
      "                   31.0: 0.0,\n",
      "                   35.0: 0.0,\n",
      "                   55.0: 1.0,\n",
      "                   56.0: 0.0,\n",
      "                   69.0: 1.0,\n",
      "                   70.0: 0.0,\n",
      "                   79.0: 1.0,\n",
      "                   81.0: 1.0,\n",
      "                   86.0: 1.0,\n",
      "                   88.0: 0.0,\n",
      "                   90.0: 1.0,\n",
      "                   91.0: 1.0,\n",
      "                   95.0: 1.0,\n",
      "                   112.0: 1.0}},\n",
      "       2.6: {'x': {9.0: 0.0,\n",
      "                   12.0: 0.0,\n",
      "                   30.0: 0.0,\n",
      "                   47.0: 0.0,\n",
      "                   50.0: 0.0,\n",
      "                   52.0: 0.0,\n",
      "                   53.0: 1.0,\n",
      "                   57.0: 0.0,\n",
      "                   59.0: 0.0,\n",
      "                   62.0: 1.0,\n",
      "                   68.0: 0.0,\n",
      "                   85.0: 1.0,\n",
      "                   88.0: 1.0,\n",
      "                   89.0: 0.0,\n",
      "                   93.0: 1.0,\n",
      "                   105.0: 1.0,\n",
      "                   116.0: 1.0}},\n",
      "       2.7: {'x': {7.0: 0.0,\n",
      "                   22.0: 0.0,\n",
      "                   25.0: 0.0,\n",
      "                   26.0: 0.0,\n",
      "                   48.0: 0.0,\n",
      "                   54.0: 1.0,\n",
      "                   64.0: 0.0,\n",
      "                   65.0: 1.0,\n",
      "                   67.0: 1.0,\n",
      "                   73.0: 0.0,\n",
      "                   80.0: 0.0,\n",
      "                   85.0: 0.0,\n",
      "                   98.0: 1.0}},\n",
      "       2.8: {'x': {0.0: 0.0,\n",
      "                   16.0: 0.0,\n",
      "                   33.0: 0.0,\n",
      "                   43.0: 0.0,\n",
      "                   51.0: 0.0,\n",
      "                   58.0: 1.0,\n",
      "                   59.0: 1.0,\n",
      "                   61.0: 1.0,\n",
      "                   72.0: 1.0,\n",
      "                   73.0: 1.0,\n",
      "                   76.0: 1.0,\n",
      "                   78.0: 0.0,\n",
      "                   87.0: 1.0,\n",
      "                   92.0: 1.0,\n",
      "                   103.0: 1.0,\n",
      "                   110.0: 1.0}},\n",
      "       2.9: {'x': {6.0: 0.0,\n",
      "                   8.0: 0.0,\n",
      "                   19.0: 0.0,\n",
      "                   36.0: 0.0,\n",
      "                   53.0: 0.0,\n",
      "                   62.0: 0.0,\n",
      "                   67.0: 0.0,\n",
      "                   71.0: 1.0,\n",
      "                   84.0: 0.0,\n",
      "                   87.0: 0.0,\n",
      "                   113.0: 1.0}},\n",
      "       3.0: {'x': {4.0: 0.0,\n",
      "                   17.0: 0.0,\n",
      "                   21.0: 0.0,\n",
      "                   57.0: 1.0,\n",
      "                   58.0: 0.0,\n",
      "                   63.0: 1.0,\n",
      "                   70.0: 1.0,\n",
      "                   75.0: 1.0,\n",
      "                   82.0: 0.0,\n",
      "                   84.0: 1.0,\n",
      "                   101.0: 1.0,\n",
      "                   114.0: 1.0,\n",
      "                   115.0: 1.0,\n",
      "                   117.0: 1.0}},\n",
      "       3.1: 1.0,\n",
      "       3.2: 1.0,\n",
      "       3.3: 1.0,\n",
      "       3.4: 1.0}}\n"
     ]
    }
   ],
   "source": [
    "tree = ID3(df, df, df.columns[:-1], imp_type='Gini', target_attribute_name='label')\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_train = df.iloc[:,:-1].to_dict(orient = \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_test = df_test.iloc[:,:-1].to_dict(orient = \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 0.0, 'y': 2.799999952316284},\n",
       " {'x': 1.0, 'y': 2.200000047683716},\n",
       " {'x': 2.0, 'y': 2.299999952316284},\n",
       " {'x': 3.0, 'y': 2.299999952316284},\n",
       " {'x': 4.0, 'y': 3.0},\n",
       " {'x': 5.0, 'y': 2.200000047683716},\n",
       " {'x': 6.0, 'y': 2.9000000953674316},\n",
       " {'x': 7.0, 'y': 2.700000047683716},\n",
       " {'x': 8.0, 'y': 2.9000000953674316},\n",
       " {'x': 9.0, 'y': 2.5999999046325684},\n",
       " {'x': 10.0, 'y': 2.200000047683716},\n",
       " {'x': 11.0, 'y': 2.299999952316284},\n",
       " {'x': 12.0, 'y': 2.5999999046325684},\n",
       " {'x': 13.0, 'y': 2.5},\n",
       " {'x': 14.0, 'y': 2.0999999046325684},\n",
       " {'x': 15.0, 'y': 2.4000000953674316},\n",
       " {'x': 16.0, 'y': 2.799999952316284},\n",
       " {'x': 17.0, 'y': 3.0},\n",
       " {'x': 18.0, 'y': 2.0999999046325684},\n",
       " {'x': 19.0, 'y': 2.9000000953674316},\n",
       " {'x': 20.0, 'y': 2.0999999046325684},\n",
       " {'x': 21.0, 'y': 3.0},\n",
       " {'x': 22.0, 'y': 2.700000047683716},\n",
       " {'x': 23.0, 'y': 2.200000047683716},\n",
       " {'x': 24.0, 'y': 2.299999952316284},\n",
       " {'x': 25.0, 'y': 2.700000047683716},\n",
       " {'x': 26.0, 'y': 2.700000047683716},\n",
       " {'x': 27.0, 'y': 2.5},\n",
       " {'x': 28.0, 'y': 2.0},\n",
       " {'x': 29.0, 'y': 2.0999999046325684},\n",
       " {'x': 30.0, 'y': 2.5999999046325684},\n",
       " {'x': 31.0, 'y': 2.5},\n",
       " {'x': 32.0, 'y': 2.4000000953674316},\n",
       " {'x': 33.0, 'y': 2.799999952316284},\n",
       " {'x': 34.0, 'y': 2.0},\n",
       " {'x': 35.0, 'y': 2.5},\n",
       " {'x': 36.0, 'y': 2.9000000953674316},\n",
       " {'x': 37.0, 'y': 2.200000047683716},\n",
       " {'x': 38.0, 'y': 2.200000047683716},\n",
       " {'x': 39.0, 'y': 2.0},\n",
       " {'x': 40.0, 'y': 2.0999999046325684},\n",
       " {'x': 41.0, 'y': 2.0999999046325684},\n",
       " {'x': 42.0, 'y': 2.4000000953674316},\n",
       " {'x': 43.0, 'y': 2.799999952316284},\n",
       " {'x': 44.0, 'y': 2.299999952316284},\n",
       " {'x': 45.0, 'y': 2.0},\n",
       " {'x': 46.0, 'y': 2.0999999046325684},\n",
       " {'x': 47.0, 'y': 2.5999999046325684},\n",
       " {'x': 48.0, 'y': 2.700000047683716},\n",
       " {'x': 49.0, 'y': 2.4000000953674316},\n",
       " {'x': 50.0, 'y': 2.5999999046325684},\n",
       " {'x': 51.0, 'y': 2.799999952316284},\n",
       " {'x': 52.0, 'y': 2.5999999046325684},\n",
       " {'x': 53.0, 'y': 2.9000000953674316},\n",
       " {'x': 54.0, 'y': 2.200000047683716},\n",
       " {'x': 55.0, 'y': 2.299999952316284},\n",
       " {'x': 56.0, 'y': 2.5},\n",
       " {'x': 57.0, 'y': 2.5999999046325684},\n",
       " {'x': 58.0, 'y': 3.0},\n",
       " {'x': 59.0, 'y': 2.5999999046325684},\n",
       " {'x': 60.0, 'y': 2.0},\n",
       " {'x': 61.0, 'y': 2.200000047683716},\n",
       " {'x': 62.0, 'y': 2.9000000953674316},\n",
       " {'x': 63.0, 'y': 2.299999952316284},\n",
       " {'x': 64.0, 'y': 2.700000047683716},\n",
       " {'x': 65.0, 'y': 2.299999952316284},\n",
       " {'x': 66.0, 'y': 2.0999999046325684},\n",
       " {'x': 67.0, 'y': 2.9000000953674316},\n",
       " {'x': 68.0, 'y': 2.5999999046325684},\n",
       " {'x': 69.0, 'y': 2.4000000953674316},\n",
       " {'x': 70.0, 'y': 2.5},\n",
       " {'x': 71.0, 'y': 2.0999999046325684},\n",
       " {'x': 72.0, 'y': 2.0},\n",
       " {'x': 73.0, 'y': 2.700000047683716},\n",
       " {'x': 74.0, 'y': 2.299999952316284},\n",
       " {'x': 75.0, 'y': 2.299999952316284},\n",
       " {'x': 76.0, 'y': 2.200000047683716},\n",
       " {'x': 77.0, 'y': 2.0999999046325684},\n",
       " {'x': 78.0, 'y': 2.799999952316284},\n",
       " {'x': 79.0, 'y': 2.299999952316284},\n",
       " {'x': 80.0, 'y': 2.700000047683716},\n",
       " {'x': 81.0, 'y': 2.4000000953674316},\n",
       " {'x': 82.0, 'y': 3.0},\n",
       " {'x': 83.0, 'y': 2.0999999046325684},\n",
       " {'x': 84.0, 'y': 2.9000000953674316},\n",
       " {'x': 85.0, 'y': 2.700000047683716},\n",
       " {'x': 86.0, 'y': 2.299999952316284},\n",
       " {'x': 87.0, 'y': 2.9000000953674316},\n",
       " {'x': 88.0, 'y': 2.5},\n",
       " {'x': 89.0, 'y': 2.5999999046325684},\n",
       " {'x': 50.0, 'y': 3.0999999046325684},\n",
       " {'x': 51.0, 'y': 3.0999999046325684},\n",
       " {'x': 52.0, 'y': 3.299999952316284},\n",
       " {'x': 53.0, 'y': 2.5999999046325684},\n",
       " {'x': 54.0, 'y': 2.700000047683716},\n",
       " {'x': 55.0, 'y': 2.5},\n",
       " {'x': 56.0, 'y': 2.4000000953674316},\n",
       " {'x': 57.0, 'y': 3.0},\n",
       " {'x': 58.0, 'y': 2.799999952316284},\n",
       " {'x': 59.0, 'y': 2.799999952316284},\n",
       " {'x': 60.0, 'y': 2.4000000953674316},\n",
       " {'x': 61.0, 'y': 2.799999952316284},\n",
       " {'x': 62.0, 'y': 2.5999999046325684},\n",
       " {'x': 63.0, 'y': 3.0},\n",
       " {'x': 64.0, 'y': 3.299999952316284},\n",
       " {'x': 65.0, 'y': 2.700000047683716},\n",
       " {'x': 66.0, 'y': 3.200000047683716},\n",
       " {'x': 67.0, 'y': 2.700000047683716},\n",
       " {'x': 68.0, 'y': 3.299999952316284},\n",
       " {'x': 69.0, 'y': 2.5},\n",
       " {'x': 70.0, 'y': 3.0},\n",
       " {'x': 71.0, 'y': 2.9000000953674316},\n",
       " {'x': 72.0, 'y': 2.799999952316284},\n",
       " {'x': 73.0, 'y': 2.799999952316284},\n",
       " {'x': 74.0, 'y': 3.0999999046325684},\n",
       " {'x': 75.0, 'y': 3.0},\n",
       " {'x': 76.0, 'y': 2.799999952316284},\n",
       " {'x': 77.0, 'y': 2.4000000953674316},\n",
       " {'x': 78.0, 'y': 3.299999952316284},\n",
       " {'x': 79.0, 'y': 2.5},\n",
       " {'x': 80.0, 'y': 3.4000000953674316},\n",
       " {'x': 81.0, 'y': 2.5},\n",
       " {'x': 82.0, 'y': 3.0999999046325684},\n",
       " {'x': 83.0, 'y': 3.299999952316284},\n",
       " {'x': 84.0, 'y': 3.0},\n",
       " {'x': 85.0, 'y': 2.5999999046325684},\n",
       " {'x': 86.0, 'y': 2.5},\n",
       " {'x': 87.0, 'y': 2.799999952316284},\n",
       " {'x': 88.0, 'y': 2.5999999046325684},\n",
       " {'x': 89.0, 'y': 2.5999999046325684},\n",
       " {'x': 90.0, 'y': 2.5},\n",
       " {'x': 91.0, 'y': 2.5},\n",
       " {'x': 92.0, 'y': 2.799999952316284},\n",
       " {'x': 93.0, 'y': 2.5999999046325684},\n",
       " {'x': 94.0, 'y': 3.299999952316284},\n",
       " {'x': 95.0, 'y': 2.5},\n",
       " {'x': 96.0, 'y': 3.200000047683716},\n",
       " {'x': 97.0, 'y': 3.0999999046325684},\n",
       " {'x': 98.0, 'y': 2.700000047683716},\n",
       " {'x': 99.0, 'y': 3.4000000953674316},\n",
       " {'x': 100.0, 'y': 3.4000000953674316},\n",
       " {'x': 101.0, 'y': 3.0},\n",
       " {'x': 102.0, 'y': 3.299999952316284},\n",
       " {'x': 103.0, 'y': 2.799999952316284},\n",
       " {'x': 104.0, 'y': 3.299999952316284},\n",
       " {'x': 105.0, 'y': 2.5999999046325684},\n",
       " {'x': 106.0, 'y': 3.0999999046325684},\n",
       " {'x': 107.0, 'y': 3.299999952316284},\n",
       " {'x': 108.0, 'y': 2.4000000953674316},\n",
       " {'x': 109.0, 'y': 3.299999952316284},\n",
       " {'x': 110.0, 'y': 2.799999952316284},\n",
       " {'x': 111.0, 'y': 2.4000000953674316},\n",
       " {'x': 112.0, 'y': 2.5},\n",
       " {'x': 113.0, 'y': 2.9000000953674316},\n",
       " {'x': 114.0, 'y': 3.0},\n",
       " {'x': 115.0, 'y': 3.0},\n",
       " {'x': 116.0, 'y': 2.5999999046325684},\n",
       " {'x': 117.0, 'y': 3.0},\n",
       " {'x': 80.0, 'y': 1.399999976158142},\n",
       " {'x': 81.0, 'y': 1.899999976158142},\n",
       " {'x': 82.0, 'y': 1.899999976158142},\n",
       " {'x': 83.0, 'y': 1.899999976158142},\n",
       " {'x': 84.0, 'y': 1.7999999523162842},\n",
       " {'x': 85.0, 'y': 1.600000023841858},\n",
       " {'x': 86.0, 'y': 1.399999976158142},\n",
       " {'x': 87.0, 'y': 1.600000023841858},\n",
       " {'x': 88.0, 'y': 2.200000047683716},\n",
       " {'x': 89.0, 'y': 1.899999976158142},\n",
       " {'x': 90.0, 'y': 2.299999952316284},\n",
       " {'x': 91.0, 'y': 1.399999976158142},\n",
       " {'x': 92.0, 'y': 2.0},\n",
       " {'x': 93.0, 'y': 1.600000023841858},\n",
       " {'x': 94.0, 'y': 2.200000047683716},\n",
       " {'x': 95.0, 'y': 2.299999952316284},\n",
       " {'x': 96.0, 'y': 1.600000023841858},\n",
       " {'x': 97.0, 'y': 2.0},\n",
       " {'x': 98.0, 'y': 1.7999999523162842},\n",
       " {'x': 99.0, 'y': 2.200000047683716},\n",
       " {'x': 100.0, 'y': 2.299999952316284},\n",
       " {'x': 101.0, 'y': 1.5},\n",
       " {'x': 102.0, 'y': 2.200000047683716},\n",
       " {'x': 103.0, 'y': 1.5},\n",
       " {'x': 104.0, 'y': 1.5},\n",
       " {'x': 105.0, 'y': 1.899999976158142},\n",
       " {'x': 106.0, 'y': 2.0999999046325684},\n",
       " {'x': 107.0, 'y': 2.0999999046325684},\n",
       " {'x': 108.0, 'y': 2.0999999046325684},\n",
       " {'x': 109.0, 'y': 1.5},\n",
       " {'x': 110.0, 'y': 1.399999976158142},\n",
       " {'x': 111.0, 'y': 1.7000000476837158},\n",
       " {'x': 112.0, 'y': 1.7000000476837158},\n",
       " {'x': 113.0, 'y': 2.299999952316284},\n",
       " {'x': 114.0, 'y': 2.0},\n",
       " {'x': 115.0, 'y': 1.399999976158142},\n",
       " {'x': 116.0, 'y': 2.299999952316284},\n",
       " {'x': 117.0, 'y': 1.899999976158142},\n",
       " {'x': 118.0, 'y': 1.600000023841858},\n",
       " {'x': 119.0, 'y': 2.200000047683716},\n",
       " {'x': 120.0, 'y': 1.600000023841858},\n",
       " {'x': 121.0, 'y': 1.899999976158142},\n",
       " {'x': 122.0, 'y': 1.399999976158142},\n",
       " {'x': 123.0, 'y': 2.299999952316284},\n",
       " {'x': 124.0, 'y': 2.0},\n",
       " {'x': 125.0, 'y': 2.0999999046325684},\n",
       " {'x': 126.0, 'y': 2.0999999046325684},\n",
       " {'x': 127.0, 'y': 2.0},\n",
       " {'x': 128.0, 'y': 2.299999952316284},\n",
       " {'x': 129.0, 'y': 1.899999976158142},\n",
       " {'x': 130.0, 'y': 1.899999976158142},\n",
       " {'x': 131.0, 'y': 1.5},\n",
       " {'x': 132.0, 'y': 1.399999976158142},\n",
       " {'x': 133.0, 'y': 1.5},\n",
       " {'x': 134.0, 'y': 2.0},\n",
       " {'x': 135.0, 'y': 2.299999952316284},\n",
       " {'x': 136.0, 'y': 1.600000023841858},\n",
       " {'x': 137.0, 'y': 1.899999976158142},\n",
       " {'x': 138.0, 'y': 2.0},\n",
       " {'x': 139.0, 'y': 1.600000023841858},\n",
       " {'x': 140.0, 'y': 1.7999999523162842},\n",
       " {'x': 141.0, 'y': 1.600000023841858},\n",
       " {'x': 142.0, 'y': 1.5},\n",
       " {'x': 143.0, 'y': 1.899999976158142},\n",
       " {'x': 144.0, 'y': 1.899999976158142},\n",
       " {'x': 145.0, 'y': 1.5},\n",
       " {'x': 146.0, 'y': 1.7000000476837158},\n",
       " {'x': 147.0, 'y': 2.299999952316284},\n",
       " {'x': 148.0, 'y': 1.399999976158142},\n",
       " {'x': 149.0, 'y': 1.899999976158142},\n",
       " {'x': 150.0, 'y': 1.7000000476837158},\n",
       " {'x': 151.0, 'y': 2.0},\n",
       " {'x': 152.0, 'y': 2.200000047683716}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 0.0, 'y': 2.9000000953674316},\n",
       " {'x': 1.0, 'y': 2.4000000953674316},\n",
       " {'x': 2.0, 'y': 3.0},\n",
       " {'x': 3.0, 'y': 2.5},\n",
       " {'x': 4.0, 'y': 2.4000000953674316},\n",
       " {'x': 5.0, 'y': 2.799999952316284},\n",
       " {'x': 6.0, 'y': 2.0},\n",
       " {'x': 7.0, 'y': 2.5},\n",
       " {'x': 8.0, 'y': 2.700000047683716},\n",
       " {'x': 9.0, 'y': 2.799999952316284},\n",
       " {'x': 10.0, 'y': 2.299999952316284},\n",
       " {'x': 11.0, 'y': 2.299999952316284},\n",
       " {'x': 12.0, 'y': 2.0999999046325684},\n",
       " {'x': 13.0, 'y': 2.0},\n",
       " {'x': 14.0, 'y': 2.700000047683716},\n",
       " {'x': 15.0, 'y': 2.4000000953674316},\n",
       " {'x': 16.0, 'y': 2.4000000953674316},\n",
       " {'x': 17.0, 'y': 2.200000047683716},\n",
       " {'x': 18.0, 'y': 2.299999952316284},\n",
       " {'x': 19.0, 'y': 2.700000047683716},\n",
       " {'x': 20.0, 'y': 2.5999999046325684},\n",
       " {'x': 21.0, 'y': 2.799999952316284},\n",
       " {'x': 22.0, 'y': 2.799999952316284},\n",
       " {'x': 23.0, 'y': 2.5999999046325684},\n",
       " {'x': 24.0, 'y': 2.5999999046325684},\n",
       " {'x': 25.0, 'y': 2.799999952316284},\n",
       " {'x': 26.0, 'y': 2.700000047683716},\n",
       " {'x': 27.0, 'y': 2.4000000953674316},\n",
       " {'x': 28.0, 'y': 3.0},\n",
       " {'x': 29.0, 'y': 2.5999999046325684},\n",
       " {'x': 30.0, 'y': 2.700000047683716},\n",
       " {'x': 31.0, 'y': 2.700000047683716},\n",
       " {'x': 32.0, 'y': 3.0},\n",
       " {'x': 33.0, 'y': 2.9000000953674316},\n",
       " {'x': 34.0, 'y': 2.799999952316284},\n",
       " {'x': 35.0, 'y': 2.0999999046325684},\n",
       " {'x': 36.0, 'y': 2.5999999046325684},\n",
       " {'x': 37.0, 'y': 2.700000047683716},\n",
       " {'x': 38.0, 'y': 2.4000000953674316},\n",
       " {'x': 39.0, 'y': 2.799999952316284},\n",
       " {'x': 40.0, 'y': 2.299999952316284},\n",
       " {'x': 41.0, 'y': 2.9000000953674316},\n",
       " {'x': 42.0, 'y': 2.200000047683716},\n",
       " {'x': 43.0, 'y': 2.200000047683716},\n",
       " {'x': 44.0, 'y': 2.9000000953674316},\n",
       " {'x': 45.0, 'y': 2.0},\n",
       " {'x': 46.0, 'y': 2.299999952316284},\n",
       " {'x': 47.0, 'y': 2.200000047683716},\n",
       " {'x': 48.0, 'y': 2.299999952316284},\n",
       " {'x': 49.0, 'y': 2.5999999046325684},\n",
       " {'x': 50.0, 'y': 2.200000047683716},\n",
       " {'x': 51.0, 'y': 2.4000000953674316},\n",
       " {'x': 52.0, 'y': 2.5999999046325684},\n",
       " {'x': 53.0, 'y': 2.299999952316284},\n",
       " {'x': 54.0, 'y': 2.5999999046325684},\n",
       " {'x': 55.0, 'y': 2.5999999046325684},\n",
       " {'x': 56.0, 'y': 2.299999952316284},\n",
       " {'x': 57.0, 'y': 2.5},\n",
       " {'x': 58.0, 'y': 2.5},\n",
       " {'x': 59.0, 'y': 2.5999999046325684},\n",
       " {'x': 60.0, 'y': 2.799999952316284},\n",
       " {'x': 61.0, 'y': 2.0999999046325684},\n",
       " {'x': 62.0, 'y': 2.799999952316284},\n",
       " {'x': 63.0, 'y': 2.5999999046325684},\n",
       " {'x': 50.0, 'y': 2.700000047683716},\n",
       " {'x': 51.0, 'y': 3.0999999046325684},\n",
       " {'x': 52.0, 'y': 2.9000000953674316},\n",
       " {'x': 53.0, 'y': 3.200000047683716},\n",
       " {'x': 54.0, 'y': 3.0},\n",
       " {'x': 55.0, 'y': 3.0999999046325684},\n",
       " {'x': 56.0, 'y': 2.799999952316284},\n",
       " {'x': 57.0, 'y': 3.4000000953674316},\n",
       " {'x': 58.0, 'y': 3.4000000953674316},\n",
       " {'x': 59.0, 'y': 2.799999952316284},\n",
       " {'x': 60.0, 'y': 3.0},\n",
       " {'x': 61.0, 'y': 3.299999952316284},\n",
       " {'x': 62.0, 'y': 2.799999952316284},\n",
       " {'x': 63.0, 'y': 2.5999999046325684},\n",
       " {'x': 64.0, 'y': 2.5},\n",
       " {'x': 65.0, 'y': 3.299999952316284},\n",
       " {'x': 66.0, 'y': 2.700000047683716},\n",
       " {'x': 67.0, 'y': 2.799999952316284},\n",
       " {'x': 68.0, 'y': 2.5999999046325684},\n",
       " {'x': 69.0, 'y': 2.4000000953674316},\n",
       " {'x': 70.0, 'y': 2.5},\n",
       " {'x': 71.0, 'y': 3.0999999046325684},\n",
       " {'x': 72.0, 'y': 3.200000047683716},\n",
       " {'x': 73.0, 'y': 2.700000047683716},\n",
       " {'x': 74.0, 'y': 3.0999999046325684},\n",
       " {'x': 75.0, 'y': 3.0999999046325684},\n",
       " {'x': 76.0, 'y': 2.5999999046325684},\n",
       " {'x': 77.0, 'y': 2.4000000953674316},\n",
       " {'x': 78.0, 'y': 2.5999999046325684},\n",
       " {'x': 79.0, 'y': 2.5999999046325684},\n",
       " {'x': 80.0, 'y': 3.200000047683716},\n",
       " {'x': 81.0, 'y': 2.9000000953674316},\n",
       " {'x': 82.0, 'y': 3.299999952316284},\n",
       " {'x': 83.0, 'y': 3.0999999046325684},\n",
       " {'x': 84.0, 'y': 3.200000047683716},\n",
       " {'x': 85.0, 'y': 2.9000000953674316},\n",
       " {'x': 86.0, 'y': 2.5999999046325684},\n",
       " {'x': 87.0, 'y': 3.200000047683716},\n",
       " {'x': 88.0, 'y': 3.4000000953674316},\n",
       " {'x': 89.0, 'y': 2.5},\n",
       " {'x': 90.0, 'y': 3.200000047683716},\n",
       " {'x': 91.0, 'y': 3.0},\n",
       " {'x': 92.0, 'y': 2.9000000953674316},\n",
       " {'x': 93.0, 'y': 2.700000047683716},\n",
       " {'x': 94.0, 'y': 2.700000047683716},\n",
       " {'x': 95.0, 'y': 2.700000047683716},\n",
       " {'x': 96.0, 'y': 2.5},\n",
       " {'x': 97.0, 'y': 3.299999952316284},\n",
       " {'x': 98.0, 'y': 3.200000047683716},\n",
       " {'x': 99.0, 'y': 2.799999952316284},\n",
       " {'x': 100.0, 'y': 3.200000047683716},\n",
       " {'x': 101.0, 'y': 2.700000047683716},\n",
       " {'x': 102.0, 'y': 2.799999952316284},\n",
       " {'x': 103.0, 'y': 2.4000000953674316},\n",
       " {'x': 104.0, 'y': 2.700000047683716},\n",
       " {'x': 105.0, 'y': 2.799999952316284},\n",
       " {'x': 106.0, 'y': 2.700000047683716},\n",
       " {'x': 107.0, 'y': 2.9000000953674316},\n",
       " {'x': 108.0, 'y': 3.0999999046325684},\n",
       " {'x': 109.0, 'y': 3.200000047683716},\n",
       " {'x': 110.0, 'y': 2.5999999046325684},\n",
       " {'x': 111.0, 'y': 2.5999999046325684},\n",
       " {'x': 112.0, 'y': 2.5999999046325684},\n",
       " {'x': 113.0, 'y': 3.4000000953674316},\n",
       " {'x': 114.0, 'y': 2.799999952316284},\n",
       " {'x': 115.0, 'y': 2.4000000953674316},\n",
       " {'x': 116.0, 'y': 3.299999952316284},\n",
       " {'x': 117.0, 'y': 2.5999999046325684},\n",
       " {'x': 118.0, 'y': 2.9000000953674316},\n",
       " {'x': 119.0, 'y': 2.5999999046325684},\n",
       " {'x': 120.0, 'y': 3.299999952316284},\n",
       " {'x': 121.0, 'y': 3.200000047683716},\n",
       " {'x': 122.0, 'y': 3.200000047683716},\n",
       " {'x': 123.0, 'y': 3.0999999046325684},\n",
       " {'x': 124.0, 'y': 2.799999952316284},\n",
       " {'x': 125.0, 'y': 3.200000047683716},\n",
       " {'x': 126.0, 'y': 2.5},\n",
       " {'x': 127.0, 'y': 2.4000000953674316},\n",
       " {'x': 128.0, 'y': 3.0},\n",
       " {'x': 129.0, 'y': 3.200000047683716},\n",
       " {'x': 130.0, 'y': 3.200000047683716},\n",
       " {'x': 131.0, 'y': 3.200000047683716},\n",
       " {'x': 132.0, 'y': 3.299999952316284},\n",
       " {'x': 133.0, 'y': 2.9000000953674316},\n",
       " {'x': 134.0, 'y': 2.700000047683716},\n",
       " {'x': 135.0, 'y': 3.0999999046325684},\n",
       " {'x': 80.0, 'y': 1.600000023841858},\n",
       " {'x': 81.0, 'y': 1.399999976158142},\n",
       " {'x': 82.0, 'y': 1.7000000476837158},\n",
       " {'x': 83.0, 'y': 1.899999976158142},\n",
       " {'x': 84.0, 'y': 1.7999999523162842},\n",
       " {'x': 85.0, 'y': 1.899999976158142},\n",
       " {'x': 86.0, 'y': 2.0},\n",
       " {'x': 87.0, 'y': 1.5},\n",
       " {'x': 88.0, 'y': 1.7000000476837158},\n",
       " {'x': 89.0, 'y': 2.200000047683716},\n",
       " {'x': 90.0, 'y': 1.7999999523162842},\n",
       " {'x': 91.0, 'y': 1.899999976158142},\n",
       " {'x': 92.0, 'y': 2.4000000953674316},\n",
       " {'x': 93.0, 'y': 1.600000023841858},\n",
       " {'x': 94.0, 'y': 1.5},\n",
       " {'x': 95.0, 'y': 2.0999999046325684},\n",
       " {'x': 96.0, 'y': 2.0},\n",
       " {'x': 97.0, 'y': 1.899999976158142},\n",
       " {'x': 98.0, 'y': 1.7000000476837158},\n",
       " {'x': 99.0, 'y': 1.899999976158142},\n",
       " {'x': 100.0, 'y': 2.200000047683716},\n",
       " {'x': 101.0, 'y': 1.7000000476837158},\n",
       " {'x': 102.0, 'y': 2.299999952316284},\n",
       " {'x': 103.0, 'y': 1.899999976158142},\n",
       " {'x': 104.0, 'y': 1.600000023841858},\n",
       " {'x': 105.0, 'y': 1.600000023841858},\n",
       " {'x': 106.0, 'y': 1.399999976158142},\n",
       " {'x': 107.0, 'y': 2.0},\n",
       " {'x': 108.0, 'y': 1.5},\n",
       " {'x': 109.0, 'y': 1.600000023841858},\n",
       " {'x': 110.0, 'y': 2.0999999046325684},\n",
       " {'x': 111.0, 'y': 1.5},\n",
       " {'x': 112.0, 'y': 1.899999976158142},\n",
       " {'x': 113.0, 'y': 1.7000000476837158},\n",
       " {'x': 114.0, 'y': 1.7000000476837158},\n",
       " {'x': 115.0, 'y': 2.299999952316284},\n",
       " {'x': 116.0, 'y': 2.200000047683716},\n",
       " {'x': 117.0, 'y': 2.299999952316284},\n",
       " {'x': 118.0, 'y': 2.299999952316284},\n",
       " {'x': 119.0, 'y': 1.399999976158142},\n",
       " {'x': 120.0, 'y': 1.5},\n",
       " {'x': 121.0, 'y': 2.299999952316284},\n",
       " {'x': 122.0, 'y': 1.600000023841858},\n",
       " {'x': 123.0, 'y': 2.299999952316284},\n",
       " {'x': 124.0, 'y': 1.7999999523162842},\n",
       " {'x': 125.0, 'y': 1.899999976158142},\n",
       " {'x': 126.0, 'y': 1.600000023841858},\n",
       " {'x': 127.0, 'y': 2.0999999046325684},\n",
       " {'x': 128.0, 'y': 1.7999999523162842},\n",
       " {'x': 129.0, 'y': 1.7999999523162842},\n",
       " {'x': 130.0, 'y': 1.5},\n",
       " {'x': 131.0, 'y': 2.0999999046325684},\n",
       " {'x': 132.0, 'y': 1.5},\n",
       " {'x': 133.0, 'y': 2.0},\n",
       " {'x': 134.0, 'y': 1.7999999523162842},\n",
       " {'x': 135.0, 'y': 2.4000000953674316},\n",
       " {'x': 136.0, 'y': 1.7000000476837158},\n",
       " {'x': 137.0, 'y': 1.5},\n",
       " {'x': 138.0, 'y': 2.299999952316284},\n",
       " {'x': 139.0, 'y': 2.299999952316284},\n",
       " {'x': 140.0, 'y': 1.7999999523162842},\n",
       " {'x': 141.0, 'y': 1.7000000476837158},\n",
       " {'x': 142.0, 'y': 2.0999999046325684},\n",
       " {'x': 143.0, 'y': 1.7000000476837158},\n",
       " {'x': 144.0, 'y': 2.299999952316284},\n",
       " {'x': 145.0, 'y': 2.299999952316284},\n",
       " {'x': 146.0, 'y': 1.7999999523162842},\n",
       " {'x': 147.0, 'y': 2.200000047683716},\n",
       " {'x': 148.0, 'y': 1.399999976158142},\n",
       " {'x': 149.0, 'y': 2.0},\n",
       " {'x': 150.0, 'y': 1.600000023841858},\n",
       " {'x': 151.0, 'y': 2.0},\n",
       " {'x': 152.0, 'y': 2.200000047683716},\n",
       " {'x': 153.0, 'y': 1.899999976158142}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the prediction accuracy\n",
    "\n",
    "predicted_train = pd.DataFrame(columns=[\"predicted\"]) \n",
    "predicted_test = pd.DataFrame(columns=[\"predicted\"])\n",
    "    \n",
    "for i in range(len(df)):\n",
    "    predicted_train.loc[i,\"predicted\"] = predict(queries_train[i],tree,1.0) \n",
    "    \n",
    "    \n",
    "for i in range(len(df_test)):\n",
    "    predicted_test.loc[i,\"predicted\"] = predict(queries_test[i],tree,1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted\n",
       "0        1.0\n",
       "1        1.0\n",
       "2        1.0\n",
       "3        1.0\n",
       "4        1.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9956709956709957"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# worse than bayesian\n",
    "accuracy_score(predicted_train.predicted, A[:,-1]) # overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6116071428571429"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# worse than bayesian\n",
    "accuracy_score(predicted_test.predicted, A_test[:,-1]) # overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf.fit(A[:,:-1], A[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sk_dt_train = clf.predict(A[:,:-1])\n",
    "c_sk_dt_test = clf.predict(A_test[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9956709956709957"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(c_sk_dt_train, A[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9151785714285714"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(c_sk_dt_test, A_test[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
