{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([np.random.rand(1) + 2 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "y2 = np.array([np.random.rand(1) + 2.4 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "y3 = np.array([np.random.rand(1) + 1.4 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "\n",
    "x1 = np.array(range(len(y1)))\n",
    "x2 = np.array([c+50 for c in range(len(y2))])\n",
    "x3 = np.array([c+80 for c in range(len(y3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data matrix \n",
    "a1 = np.concatenate((x1.reshape(-1,1),y1,np.array([0 for c in range(len(x1))]).reshape(-1,1)), 1).round(4)\n",
    "a2 = np.concatenate((x2.reshape(-1,1),y2,np.array([1 for c in range(len(x2))]).reshape(-1,1)), 1).round(4)\n",
    "a3 = np.concatenate((x3.reshape(-1,1),y3,np.array([2 for c in range(len(x3))]).reshape(-1,1)), 1).round(4)\n",
    "\n",
    "A = np.concatenate((a1,a2,a3), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((217, 3), 68, 79, 70)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, y1.shape[0], y2.shape[0], y3.shape[0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.    ,   2.6639,   0.    ],\n",
       "       [  1.    ,   2.2563,   0.    ],\n",
       "       [  2.    ,   2.2536,   0.    ],\n",
       "       [  3.    ,   2.5432,   0.    ],\n",
       "       [  4.    ,   2.0642,   0.    ],\n",
       "       [  5.    ,   2.3037,   0.    ],\n",
       "       [  6.    ,   2.5953,   0.    ],\n",
       "       [  7.    ,   2.2111,   0.    ],\n",
       "       [  8.    ,   2.5765,   0.    ],\n",
       "       [  9.    ,   2.0865,   0.    ],\n",
       "       [ 10.    ,   2.0225,   0.    ],\n",
       "       [ 11.    ,   2.4454,   0.    ],\n",
       "       [ 12.    ,   2.078 ,   0.    ],\n",
       "       [ 13.    ,   2.6751,   0.    ],\n",
       "       [ 14.    ,   2.4526,   0.    ],\n",
       "       [ 15.    ,   2.541 ,   0.    ],\n",
       "       [ 16.    ,   2.3745,   0.    ],\n",
       "       [ 17.    ,   2.6917,   0.    ],\n",
       "       [ 18.    ,   2.4373,   0.    ],\n",
       "       [ 19.    ,   2.6705,   0.    ],\n",
       "       [ 20.    ,   2.655 ,   0.    ],\n",
       "       [ 21.    ,   2.5562,   0.    ],\n",
       "       [ 22.    ,   2.6815,   0.    ],\n",
       "       [ 23.    ,   2.7674,   0.    ],\n",
       "       [ 24.    ,   2.0038,   0.    ],\n",
       "       [ 25.    ,   2.4065,   0.    ],\n",
       "       [ 26.    ,   2.849 ,   0.    ],\n",
       "       [ 27.    ,   2.8443,   0.    ],\n",
       "       [ 28.    ,   2.4421,   0.    ],\n",
       "       [ 29.    ,   2.2101,   0.    ],\n",
       "       [ 30.    ,   2.3506,   0.    ],\n",
       "       [ 31.    ,   2.8048,   0.    ],\n",
       "       [ 32.    ,   2.9773,   0.    ],\n",
       "       [ 33.    ,   2.9818,   0.    ],\n",
       "       [ 34.    ,   2.5918,   0.    ],\n",
       "       [ 35.    ,   2.5418,   0.    ],\n",
       "       [ 36.    ,   2.0814,   0.    ],\n",
       "       [ 37.    ,   2.3536,   0.    ],\n",
       "       [ 38.    ,   2.0974,   0.    ],\n",
       "       [ 39.    ,   2.1812,   0.    ],\n",
       "       [ 40.    ,   2.4175,   0.    ],\n",
       "       [ 41.    ,   2.2038,   0.    ],\n",
       "       [ 42.    ,   2.8296,   0.    ],\n",
       "       [ 43.    ,   2.953 ,   0.    ],\n",
       "       [ 44.    ,   2.2964,   0.    ],\n",
       "       [ 45.    ,   2.2207,   0.    ],\n",
       "       [ 46.    ,   2.8271,   0.    ],\n",
       "       [ 47.    ,   2.8948,   0.    ],\n",
       "       [ 48.    ,   2.7188,   0.    ],\n",
       "       [ 49.    ,   2.7222,   0.    ],\n",
       "       [ 50.    ,   2.4659,   0.    ],\n",
       "       [ 51.    ,   2.5503,   0.    ],\n",
       "       [ 52.    ,   2.5916,   0.    ],\n",
       "       [ 53.    ,   2.1332,   0.    ],\n",
       "       [ 54.    ,   2.1035,   0.    ],\n",
       "       [ 55.    ,   2.794 ,   0.    ],\n",
       "       [ 56.    ,   2.4306,   0.    ],\n",
       "       [ 57.    ,   2.3658,   0.    ],\n",
       "       [ 58.    ,   2.4123,   0.    ],\n",
       "       [ 59.    ,   2.2913,   0.    ],\n",
       "       [ 60.    ,   2.7422,   0.    ],\n",
       "       [ 61.    ,   2.2997,   0.    ],\n",
       "       [ 62.    ,   2.5078,   0.    ],\n",
       "       [ 63.    ,   2.7299,   0.    ],\n",
       "       [ 64.    ,   2.9013,   0.    ],\n",
       "       [ 65.    ,   2.8064,   0.    ],\n",
       "       [ 66.    ,   2.237 ,   0.    ],\n",
       "       [ 67.    ,   2.8758,   0.    ],\n",
       "       [ 50.    ,   3.0745,   1.    ],\n",
       "       [ 51.    ,   3.1921,   1.    ],\n",
       "       [ 52.    ,   2.9268,   1.    ],\n",
       "       [ 53.    ,   3.3082,   1.    ],\n",
       "       [ 54.    ,   2.9887,   1.    ],\n",
       "       [ 55.    ,   2.4833,   1.    ],\n",
       "       [ 56.    ,   3.138 ,   1.    ],\n",
       "       [ 57.    ,   3.0637,   1.    ],\n",
       "       [ 58.    ,   2.9968,   1.    ],\n",
       "       [ 59.    ,   2.8199,   1.    ],\n",
       "       [ 60.    ,   2.7463,   1.    ],\n",
       "       [ 61.    ,   2.6004,   1.    ],\n",
       "       [ 62.    ,   2.9986,   1.    ],\n",
       "       [ 63.    ,   2.8928,   1.    ],\n",
       "       [ 64.    ,   3.3508,   1.    ],\n",
       "       [ 65.    ,   2.5203,   1.    ],\n",
       "       [ 66.    ,   2.4064,   1.    ],\n",
       "       [ 67.    ,   3.207 ,   1.    ],\n",
       "       [ 68.    ,   3.3531,   1.    ],\n",
       "       [ 69.    ,   2.6179,   1.    ],\n",
       "       [ 70.    ,   2.4375,   1.    ],\n",
       "       [ 71.    ,   2.5689,   1.    ],\n",
       "       [ 72.    ,   3.3405,   1.    ],\n",
       "       [ 73.    ,   3.0374,   1.    ],\n",
       "       [ 74.    ,   2.9805,   1.    ],\n",
       "       [ 75.    ,   2.9988,   1.    ],\n",
       "       [ 76.    ,   3.0202,   1.    ],\n",
       "       [ 77.    ,   2.4595,   1.    ],\n",
       "       [ 78.    ,   2.8545,   1.    ],\n",
       "       [ 79.    ,   2.8067,   1.    ],\n",
       "       [ 80.    ,   3.3924,   1.    ],\n",
       "       [ 81.    ,   2.4266,   1.    ],\n",
       "       [ 82.    ,   2.5722,   1.    ],\n",
       "       [ 83.    ,   2.9695,   1.    ],\n",
       "       [ 84.    ,   2.671 ,   1.    ],\n",
       "       [ 85.    ,   2.7907,   1.    ],\n",
       "       [ 86.    ,   3.0363,   1.    ],\n",
       "       [ 87.    ,   2.7749,   1.    ],\n",
       "       [ 88.    ,   2.8544,   1.    ],\n",
       "       [ 89.    ,   2.5083,   1.    ],\n",
       "       [ 90.    ,   3.3503,   1.    ],\n",
       "       [ 91.    ,   3.2097,   1.    ],\n",
       "       [ 92.    ,   2.548 ,   1.    ],\n",
       "       [ 93.    ,   3.1086,   1.    ],\n",
       "       [ 94.    ,   2.6336,   1.    ],\n",
       "       [ 95.    ,   3.2374,   1.    ],\n",
       "       [ 96.    ,   3.338 ,   1.    ],\n",
       "       [ 97.    ,   3.2077,   1.    ],\n",
       "       [ 98.    ,   2.5882,   1.    ],\n",
       "       [ 99.    ,   2.8839,   1.    ],\n",
       "       [100.    ,   2.8124,   1.    ],\n",
       "       [101.    ,   3.1594,   1.    ],\n",
       "       [102.    ,   3.2473,   1.    ],\n",
       "       [103.    ,   2.9317,   1.    ],\n",
       "       [104.    ,   2.6164,   1.    ],\n",
       "       [105.    ,   3.1108,   1.    ],\n",
       "       [106.    ,   3.316 ,   1.    ],\n",
       "       [107.    ,   2.885 ,   1.    ],\n",
       "       [108.    ,   3.2212,   1.    ],\n",
       "       [109.    ,   3.0127,   1.    ],\n",
       "       [110.    ,   3.0813,   1.    ],\n",
       "       [111.    ,   2.6471,   1.    ],\n",
       "       [112.    ,   3.2985,   1.    ],\n",
       "       [113.    ,   2.726 ,   1.    ],\n",
       "       [114.    ,   3.3637,   1.    ],\n",
       "       [115.    ,   2.5872,   1.    ],\n",
       "       [116.    ,   2.7157,   1.    ],\n",
       "       [117.    ,   3.389 ,   1.    ],\n",
       "       [118.    ,   2.6061,   1.    ],\n",
       "       [119.    ,   3.3677,   1.    ],\n",
       "       [120.    ,   2.8627,   1.    ],\n",
       "       [121.    ,   2.9943,   1.    ],\n",
       "       [122.    ,   2.933 ,   1.    ],\n",
       "       [123.    ,   3.386 ,   1.    ],\n",
       "       [124.    ,   2.8281,   1.    ],\n",
       "       [125.    ,   3.1232,   1.    ],\n",
       "       [126.    ,   3.3717,   1.    ],\n",
       "       [127.    ,   2.8462,   1.    ],\n",
       "       [128.    ,   2.4707,   1.    ],\n",
       "       [ 80.    ,   2.3652,   2.    ],\n",
       "       [ 81.    ,   2.0774,   2.    ],\n",
       "       [ 82.    ,   2.1401,   2.    ],\n",
       "       [ 83.    ,   1.588 ,   2.    ],\n",
       "       [ 84.    ,   1.9318,   2.    ],\n",
       "       [ 85.    ,   1.9318,   2.    ],\n",
       "       [ 86.    ,   1.5176,   2.    ],\n",
       "       [ 87.    ,   1.6284,   2.    ],\n",
       "       [ 88.    ,   2.0739,   2.    ],\n",
       "       [ 89.    ,   1.918 ,   2.    ],\n",
       "       [ 90.    ,   1.9153,   2.    ],\n",
       "       [ 91.    ,   1.9693,   2.    ],\n",
       "       [ 92.    ,   2.2559,   2.    ],\n",
       "       [ 93.    ,   1.7574,   2.    ],\n",
       "       [ 94.    ,   1.8891,   2.    ],\n",
       "       [ 95.    ,   2.2574,   2.    ],\n",
       "       [ 96.    ,   1.6497,   2.    ],\n",
       "       [ 97.    ,   2.1424,   2.    ],\n",
       "       [ 98.    ,   1.592 ,   2.    ],\n",
       "       [ 99.    ,   1.7069,   2.    ],\n",
       "       [100.    ,   1.4785,   2.    ],\n",
       "       [101.    ,   1.6266,   2.    ],\n",
       "       [102.    ,   1.8771,   2.    ],\n",
       "       [103.    ,   1.4585,   2.    ],\n",
       "       [104.    ,   1.8253,   2.    ],\n",
       "       [105.    ,   2.0232,   2.    ],\n",
       "       [106.    ,   2.1728,   2.    ],\n",
       "       [107.    ,   1.5374,   2.    ],\n",
       "       [108.    ,   1.6985,   2.    ],\n",
       "       [109.    ,   2.2466,   2.    ],\n",
       "       [110.    ,   1.6256,   2.    ],\n",
       "       [111.    ,   1.752 ,   2.    ],\n",
       "       [112.    ,   1.9448,   2.    ],\n",
       "       [113.    ,   2.289 ,   2.    ],\n",
       "       [114.    ,   2.0134,   2.    ],\n",
       "       [115.    ,   1.7943,   2.    ],\n",
       "       [116.    ,   2.172 ,   2.    ],\n",
       "       [117.    ,   1.5887,   2.    ],\n",
       "       [118.    ,   2.2423,   2.    ],\n",
       "       [119.    ,   1.5612,   2.    ],\n",
       "       [120.    ,   1.4522,   2.    ],\n",
       "       [121.    ,   2.3292,   2.    ],\n",
       "       [122.    ,   2.2957,   2.    ],\n",
       "       [123.    ,   1.7256,   2.    ],\n",
       "       [124.    ,   1.7093,   2.    ],\n",
       "       [125.    ,   1.7583,   2.    ],\n",
       "       [126.    ,   1.8353,   2.    ],\n",
       "       [127.    ,   1.4415,   2.    ],\n",
       "       [128.    ,   1.5016,   2.    ],\n",
       "       [129.    ,   1.6081,   2.    ],\n",
       "       [130.    ,   1.7127,   2.    ],\n",
       "       [131.    ,   1.8497,   2.    ],\n",
       "       [132.    ,   1.9834,   2.    ],\n",
       "       [133.    ,   2.2231,   2.    ],\n",
       "       [134.    ,   1.8192,   2.    ],\n",
       "       [135.    ,   1.5845,   2.    ],\n",
       "       [136.    ,   1.8754,   2.    ],\n",
       "       [137.    ,   1.8011,   2.    ],\n",
       "       [138.    ,   2.2478,   2.    ],\n",
       "       [139.    ,   2.3734,   2.    ],\n",
       "       [140.    ,   1.9906,   2.    ],\n",
       "       [141.    ,   1.5213,   2.    ],\n",
       "       [142.    ,   1.7171,   2.    ],\n",
       "       [143.    ,   2.1972,   2.    ],\n",
       "       [144.    ,   1.5557,   2.    ],\n",
       "       [145.    ,   1.8111,   2.    ],\n",
       "       [146.    ,   1.5234,   2.    ],\n",
       "       [147.    ,   1.5095,   2.    ],\n",
       "       [148.    ,   2.2749,   2.    ],\n",
       "       [149.    ,   2.1021,   2.    ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(x1, y1, s=10, c='b', marker=\"o\", label='first')\n",
    "ax1.scatter(x2, y2, s=10, c='g', marker=\"o\", label='second')\n",
    "ax1.scatter(x3, y3, s=10, c='r', marker=\"o\", label='third')\n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClass:\n",
    "    def __init__(self, A):\n",
    "        self.data = A\n",
    "        self.classes = self.data.label.unique()\n",
    "        self.class_data = self.__separate_data_by_classes__()\n",
    "        self.class_probs = self.__get_probs_of_each_class__()\n",
    "        self.class_means = self.__get_mean_of_each_class__()\n",
    "        self.class_vars = self.__get_variances_class__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __separate_data_by_classes__(self):\n",
    "        c_d = {}\n",
    "        for c in self.classes:\n",
    "            c_d[c] = (self.data.loc[self.data['label'] == c]).values[:,:-1]\n",
    "        return c_d\n",
    "    \n",
    "    def __get_probs_of_each_class__(self):\n",
    "        probs = []\n",
    "        for c in self.classes:\n",
    "            probs.append(len(self.class_data[c])/self.data.shape[0])\n",
    "        return np.array(probs)\n",
    "    \n",
    "    def __get_mean_of_each_class__(self):\n",
    "        means = {}\n",
    "        for c in self.classes:\n",
    "            m = []\n",
    "            for i in range(self.data.shape[1] - 1):\n",
    "                m.append(self.class_data[c][:,i].mean())\n",
    "            means[c] = m\n",
    "        return means\n",
    "    \n",
    "    def __get_variances_class__(self):\n",
    "        variances = {}\n",
    "        for c in self.classes:\n",
    "            va = []\n",
    "            for i in range(self.data.shape[1] - 1):\n",
    "                va.append(self.class_data[c][:,i].var())\n",
    "            variances[c] = va\n",
    "        return variances\n",
    "    \n",
    "    def __get_gaussian_prob__(self, x, mean_, var_):\n",
    "        somnojitels = []\n",
    "        for i in range(x.shape[1]):\n",
    "            x_feat = x[:,i]\n",
    "            somnojitels.append((1/np.sqrt(2*np.pi*var_[i])*np.exp(-1/(2*var_[i])*(x_feat-mean_[i])**2)))\n",
    "        return np.array(somnojitels).prod()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        res = []\n",
    "        for row in x:\n",
    "            pr = []\n",
    "            for c in self.classes:\n",
    "                pr.append(self.class_probs[c]*self.__get_gaussian_prob__(row.reshape(1,-1), self.class_means[c], self.class_vars[c]))\n",
    "            res.append(np.argmax(pr))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(A)\n",
    "df.columns = ['x', 'y', 'label']\n",
    "df = df.astype({'x': 'float32', 'y': 'float32', 'label': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x       y  label\n",
       "0  0.0  2.6639      0\n",
       "1  1.0  2.2563      0\n",
       "2  2.0  2.2536      0\n",
       "3  3.0  2.5432      0\n",
       "4  4.0  2.0642      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayesClass(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31336406, 0.3640553 , 0.32258065])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [385.25, 0.07210756806734175],\n",
       " 1: [520.0, 0.08449327606225562],\n",
       " 2: [408.25, 0.07413494713545374]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.class_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [33.5, 2.4947499878266277],\n",
       " 1: [89.0, 2.93927722037593],\n",
       " 2: [114.5, 1.8652200034686497]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.class_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_label = nb.predict(A[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_class_label [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print('predicted_class_label', predicted_class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9447004608294931"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predicted_class_label, A[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(A[:,:-1], A[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2.]\n"
     ]
    }
   ],
   "source": [
    "sklearn_predicted = clf.predict(A[:,:-1])\n",
    "print(sklearn_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9447004608294931"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sklearn_predicted, A[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "\n",
    "y1_test = np.array([np.random.rand(1) + 2 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "y2_test = np.array([np.random.rand(1) + 2.4 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "y3_test = np.array([np.random.rand(1) + 1.4 for c in (range(np.random.choice([c+60 for c in range(40)])))])\n",
    "\n",
    "x1_test = np.array(range(len(y1_test)))\n",
    "x2_test = np.array([c+50 for c in range(len(y2_test))])\n",
    "x3_test = np.array([c+80 for c in range(len(y3_test))])\n",
    "\n",
    "a1_test = np.concatenate((x1_test.reshape(-1,1),y1_test,np.array([0 for c in range(len(x1_test))]).reshape(-1,1)), 1).round(1)\n",
    "a2_test = np.concatenate((x2_test.reshape(-1,1),y2_test,np.array([1 for c in range(len(x2_test))]).reshape(-1,1)), 1).round(1)\n",
    "a3_test = np.concatenate((x3_test.reshape(-1,1),y3_test,np.array([2 for c in range(len(x3_test))]).reshape(-1,1)), 1).round(1)\n",
    "\n",
    "A_test = np.concatenate((a1_test,a2_test,a3_test), 0)\n",
    "np.random.shuffle(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 75. ,   2.9,   0. ],\n",
       "       [139. ,   1.4,   2. ],\n",
       "       [109. ,   2.9,   1. ],\n",
       "       [ 76. ,   3.3,   1. ],\n",
       "       [103. ,   2.2,   2. ],\n",
       "       [120. ,   2.3,   2. ],\n",
       "       [  7. ,   2.2,   0. ],\n",
       "       [ 20. ,   2.2,   0. ],\n",
       "       [ 58. ,   3.3,   1. ],\n",
       "       [ 22. ,   2.3,   0. ],\n",
       "       [ 66. ,   3.2,   1. ],\n",
       "       [149. ,   1.8,   2. ],\n",
       "       [ 75. ,   3. ,   1. ],\n",
       "       [ 89. ,   3.3,   1. ],\n",
       "       [ 70. ,   3. ,   1. ],\n",
       "       [113. ,   2.2,   2. ],\n",
       "       [135. ,   3.2,   1. ],\n",
       "       [108. ,   2.4,   1. ],\n",
       "       [ 42. ,   2.9,   0. ],\n",
       "       [ 95. ,   2.2,   0. ],\n",
       "       [  9. ,   3. ,   0. ],\n",
       "       [129. ,   3.1,   1. ],\n",
       "       [ 71. ,   3.3,   1. ],\n",
       "       [101. ,   1.7,   2. ],\n",
       "       [ 61. ,   2.9,   0. ],\n",
       "       [106. ,   1.5,   2. ],\n",
       "       [142. ,   1.5,   2. ],\n",
       "       [123. ,   3. ,   1. ],\n",
       "       [131. ,   3.2,   1. ],\n",
       "       [ 88. ,   1.5,   2. ],\n",
       "       [120. ,   2.9,   1. ],\n",
       "       [136. ,   2.4,   1. ],\n",
       "       [154. ,   2.1,   2. ],\n",
       "       [163. ,   1.7,   2. ],\n",
       "       [ 16. ,   2. ,   0. ],\n",
       "       [105. ,   1.5,   2. ],\n",
       "       [ 35. ,   2.5,   0. ],\n",
       "       [ 59. ,   2.9,   0. ],\n",
       "       [119. ,   2.7,   1. ],\n",
       "       [ 90. ,   2.1,   0. ],\n",
       "       [ 81. ,   3.1,   1. ],\n",
       "       [ 11. ,   2. ,   0. ],\n",
       "       [ 33. ,   2.5,   0. ],\n",
       "       [134. ,   3.2,   1. ],\n",
       "       [158. ,   2. ,   2. ],\n",
       "       [110. ,   2.9,   1. ],\n",
       "       [ 39. ,   2.2,   0. ],\n",
       "       [ 23. ,   2.1,   0. ],\n",
       "       [ 13. ,   2.9,   0. ],\n",
       "       [131. ,   1.9,   2. ],\n",
       "       [ 78. ,   2.5,   0. ],\n",
       "       [145. ,   2.1,   2. ],\n",
       "       [148. ,   2.4,   2. ],\n",
       "       [114. ,   2.8,   1. ],\n",
       "       [ 52. ,   2.6,   0. ],\n",
       "       [ 74. ,   2.5,   1. ],\n",
       "       [  5. ,   2.7,   0. ],\n",
       "       [ 64. ,   2.7,   0. ],\n",
       "       [100. ,   2.3,   2. ],\n",
       "       [ 26. ,   2.2,   0. ],\n",
       "       [ 54. ,   3.3,   1. ],\n",
       "       [ 52. ,   2.9,   1. ],\n",
       "       [130. ,   2.2,   2. ],\n",
       "       [130. ,   2.6,   1. ],\n",
       "       [ 89. ,   2.2,   2. ],\n",
       "       [129. ,   1.8,   2. ],\n",
       "       [116. ,   1.9,   2. ],\n",
       "       [  0. ,   2. ,   0. ],\n",
       "       [132. ,   2.4,   1. ],\n",
       "       [ 51. ,   2.6,   0. ],\n",
       "       [119. ,   1.9,   2. ],\n",
       "       [106. ,   2.6,   1. ],\n",
       "       [ 56. ,   2.7,   1. ],\n",
       "       [ 72. ,   3.3,   1. ],\n",
       "       [ 60. ,   2.5,   1. ],\n",
       "       [ 82. ,   2.9,   0. ],\n",
       "       [ 10. ,   2.7,   0. ],\n",
       "       [  1. ,   2.5,   0. ],\n",
       "       [ 92. ,   3.1,   1. ],\n",
       "       [143. ,   2. ,   2. ],\n",
       "       [ 93. ,   3. ,   0. ],\n",
       "       [166. ,   2. ,   2. ],\n",
       "       [ 80. ,   2.9,   1. ],\n",
       "       [ 53. ,   2.2,   0. ],\n",
       "       [  8. ,   2.9,   0. ],\n",
       "       [ 68. ,   2.9,   1. ],\n",
       "       [ 55. ,   2.7,   0. ],\n",
       "       [157. ,   2.3,   2. ],\n",
       "       [159. ,   2. ,   2. ],\n",
       "       [ 12. ,   2.6,   0. ],\n",
       "       [ 28. ,   2.9,   0. ],\n",
       "       [ 79. ,   2.3,   0. ],\n",
       "       [133. ,   3.2,   1. ],\n",
       "       [ 50. ,   2.3,   0. ],\n",
       "       [ 85. ,   2.1,   2. ],\n",
       "       [121. ,   2.3,   2. ],\n",
       "       [134. ,   1.7,   2. ],\n",
       "       [ 84. ,   1.7,   2. ],\n",
       "       [ 85. ,   2.7,   0. ],\n",
       "       [118. ,   1.9,   2. ],\n",
       "       [144. ,   1.7,   2. ],\n",
       "       [ 86. ,   1.4,   2. ],\n",
       "       [100. ,   2.9,   1. ],\n",
       "       [153. ,   2. ,   2. ],\n",
       "       [ 87. ,   2.2,   0. ],\n",
       "       [115. ,   1.7,   2. ],\n",
       "       [ 99. ,   2.2,   2. ],\n",
       "       [103. ,   2.4,   1. ],\n",
       "       [162. ,   1.7,   2. ],\n",
       "       [ 79. ,   2.4,   1. ],\n",
       "       [116. ,   3. ,   1. ],\n",
       "       [102. ,   1.5,   2. ],\n",
       "       [ 70. ,   2.1,   0. ],\n",
       "       [ 50. ,   3.1,   1. ],\n",
       "       [ 34. ,   2.6,   0. ],\n",
       "       [ 94. ,   2. ,   2. ],\n",
       "       [ 67. ,   2.4,   0. ],\n",
       "       [ 73. ,   2.8,   0. ],\n",
       "       [ 25. ,   2.4,   0. ],\n",
       "       [128. ,   2.5,   1. ],\n",
       "       [ 96. ,   2.7,   1. ],\n",
       "       [ 84. ,   3.1,   1. ],\n",
       "       [161. ,   1.7,   2. ],\n",
       "       [109. ,   2.3,   2. ],\n",
       "       [105. ,   3. ,   1. ],\n",
       "       [ 58. ,   2.4,   0. ],\n",
       "       [ 69. ,   2.6,   0. ],\n",
       "       [ 69. ,   2.9,   1. ],\n",
       "       [ 44. ,   2.8,   0. ],\n",
       "       [ 96. ,   1.6,   2. ],\n",
       "       [ 93. ,   1.7,   2. ],\n",
       "       [127. ,   2.1,   2. ],\n",
       "       [ 72. ,   2.8,   0. ],\n",
       "       [125. ,   3.2,   1. ],\n",
       "       [ 83. ,   2.3,   2. ],\n",
       "       [ 81. ,   2.6,   0. ],\n",
       "       [ 32. ,   2.3,   0. ],\n",
       "       [141. ,   1.9,   2. ],\n",
       "       [164. ,   1.8,   2. ],\n",
       "       [ 67. ,   2.5,   1. ],\n",
       "       [ 90. ,   2. ,   2. ],\n",
       "       [ 78. ,   3.3,   1. ],\n",
       "       [ 17. ,   2.5,   0. ],\n",
       "       [ 86. ,   3.2,   1. ],\n",
       "       [ 98. ,   2.6,   1. ],\n",
       "       [ 92. ,   1.7,   2. ],\n",
       "       [117. ,   2.4,   1. ],\n",
       "       [150. ,   2.1,   2. ],\n",
       "       [ 56. ,   2.5,   0. ],\n",
       "       [ 61. ,   2.5,   1. ],\n",
       "       [ 46. ,   2. ,   0. ],\n",
       "       [104. ,   3.1,   1. ],\n",
       "       [160. ,   1.7,   2. ],\n",
       "       [112. ,   1.5,   2. ],\n",
       "       [127. ,   2.6,   1. ],\n",
       "       [  4. ,   2.9,   0. ],\n",
       "       [114. ,   2. ,   2. ],\n",
       "       [152. ,   2.4,   2. ],\n",
       "       [  6. ,   2.8,   0. ],\n",
       "       [ 94. ,   2.7,   1. ],\n",
       "       [ 73. ,   3.3,   1. ],\n",
       "       [107. ,   2.9,   1. ],\n",
       "       [ 57. ,   2.4,   0. ],\n",
       "       [ 38. ,   2.3,   0. ],\n",
       "       [ 86. ,   2.2,   0. ],\n",
       "       [128. ,   1.9,   2. ],\n",
       "       [ 92. ,   2.3,   0. ],\n",
       "       [ 18. ,   2.3,   0. ],\n",
       "       [ 88. ,   2.5,   1. ],\n",
       "       [126. ,   3.3,   1. ],\n",
       "       [123. ,   2.3,   2. ],\n",
       "       [ 51. ,   3.1,   1. ],\n",
       "       [111. ,   2.8,   1. ],\n",
       "       [ 40. ,   3. ,   0. ],\n",
       "       [ 64. ,   2.6,   1. ],\n",
       "       [ 14. ,   2.9,   0. ],\n",
       "       [ 80. ,   2.3,   2. ],\n",
       "       [ 29. ,   2.1,   0. ],\n",
       "       [ 81. ,   2.2,   2. ],\n",
       "       [ 82. ,   1.8,   2. ],\n",
       "       [124. ,   1.8,   2. ],\n",
       "       [ 83. ,   3. ,   1. ],\n",
       "       [133. ,   1.5,   2. ],\n",
       "       [ 89. ,   2.6,   0. ],\n",
       "       [ 65. ,   3. ,   1. ],\n",
       "       [ 27. ,   2.1,   0. ],\n",
       "       [126. ,   2.2,   2. ],\n",
       "       [117. ,   1.4,   2. ],\n",
       "       [ 47. ,   2.1,   0. ],\n",
       "       [ 95. ,   3. ,   1. ],\n",
       "       [ 94. ,   2.7,   0. ],\n",
       "       [ 82. ,   3.2,   1. ],\n",
       "       [  3. ,   2.5,   0. ],\n",
       "       [ 88. ,   2.8,   0. ],\n",
       "       [155. ,   1.5,   2. ],\n",
       "       [146. ,   2.4,   2. ],\n",
       "       [ 71. ,   2.4,   0. ],\n",
       "       [ 87. ,   3.2,   1. ],\n",
       "       [135. ,   1.5,   2. ],\n",
       "       [ 90. ,   2.8,   1. ],\n",
       "       [ 15. ,   2.6,   0. ],\n",
       "       [ 19. ,   2.4,   0. ],\n",
       "       [ 83. ,   2.5,   0. ],\n",
       "       [ 63. ,   3.3,   1. ],\n",
       "       [ 74. ,   2.1,   0. ],\n",
       "       [ 31. ,   2.9,   0. ],\n",
       "       [124. ,   2.5,   1. ],\n",
       "       [ 87. ,   1.8,   2. ],\n",
       "       [125. ,   2.3,   2. ],\n",
       "       [ 80. ,   2.6,   0. ],\n",
       "       [132. ,   1.5,   2. ],\n",
       "       [107. ,   1.6,   2. ],\n",
       "       [ 99. ,   3.1,   1. ],\n",
       "       [ 62. ,   2.5,   1. ],\n",
       "       [ 77. ,   2.5,   0. ],\n",
       "       [102. ,   3.1,   1. ],\n",
       "       [ 55. ,   2.7,   1. ],\n",
       "       [151. ,   2.1,   2. ],\n",
       "       [ 65. ,   2.9,   0. ],\n",
       "       [118. ,   2.6,   1. ],\n",
       "       [ 93. ,   3.2,   1. ],\n",
       "       [ 76. ,   2.6,   0. ],\n",
       "       [ 30. ,   2.3,   0. ],\n",
       "       [ 97. ,   2.3,   2. ],\n",
       "       [ 97. ,   3.1,   1. ],\n",
       "       [101. ,   2.4,   1. ],\n",
       "       [137. ,   2.4,   2. ],\n",
       "       [ 98. ,   1.8,   2. ],\n",
       "       [ 21. ,   2.4,   0. ],\n",
       "       [ 53. ,   2.6,   1. ],\n",
       "       [137. ,   2.9,   1. ],\n",
       "       [ 77. ,   3.1,   1. ],\n",
       "       [ 68. ,   2.2,   0. ],\n",
       "       [ 84. ,   2. ,   0. ],\n",
       "       [ 66. ,   2.3,   0. ],\n",
       "       [ 91. ,   1.7,   2. ],\n",
       "       [138. ,   2. ,   2. ],\n",
       "       [ 43. ,   2.6,   0. ],\n",
       "       [156. ,   1.7,   2. ],\n",
       "       [122. ,   3.3,   1. ],\n",
       "       [ 60. ,   2.3,   0. ],\n",
       "       [ 95. ,   1.8,   2. ],\n",
       "       [ 57. ,   2.4,   1. ],\n",
       "       [ 49. ,   2.5,   0. ],\n",
       "       [111. ,   1.9,   2. ],\n",
       "       [110. ,   1.9,   2. ],\n",
       "       [ 41. ,   2.9,   0. ],\n",
       "       [165. ,   2.4,   2. ],\n",
       "       [ 36. ,   2.4,   0. ],\n",
       "       [ 37. ,   2.3,   0. ],\n",
       "       [ 59. ,   2.6,   1. ],\n",
       "       [136. ,   2.1,   2. ],\n",
       "       [ 54. ,   2.2,   0. ],\n",
       "       [ 91. ,   2.1,   0. ],\n",
       "       [108. ,   2.1,   2. ],\n",
       "       [104. ,   1.5,   2. ],\n",
       "       [ 24. ,   2.6,   0. ],\n",
       "       [112. ,   3. ,   1. ],\n",
       "       [ 45. ,   3. ,   0. ],\n",
       "       [ 48. ,   2.6,   0. ],\n",
       "       [ 63. ,   2.1,   0. ],\n",
       "       [  2. ,   2.7,   0. ],\n",
       "       [ 91. ,   2.9,   1. ],\n",
       "       [ 85. ,   2.7,   1. ],\n",
       "       [ 62. ,   2.2,   0. ],\n",
       "       [122. ,   1.5,   2. ],\n",
       "       [140. ,   2.1,   2. ],\n",
       "       [113. ,   2.8,   1. ],\n",
       "       [115. ,   3.2,   1. ],\n",
       "       [147. ,   1.9,   2. ],\n",
       "       [121. ,   2.5,   1. ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = A_test[:,:-1]\n",
    "y_test = A_test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8376383763837638"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 1. 1. 2. 2. 0. 0. 1. 0. 1. 2. 1. 1. 1. 2. 1. 2. 0. 2. 0. 1. 1. 2.\n",
      " 1. 2. 2. 1. 1. 2. 1. 2. 2. 2. 0. 2. 0. 1. 1. 2. 1. 0. 0. 1. 2. 1. 0. 0.\n",
      " 0. 2. 1. 2. 2. 1. 0. 1. 0. 1. 2. 0. 1. 1. 2. 1. 2. 2. 2. 0. 2. 0. 2. 1.\n",
      " 0. 1. 0. 1. 0. 0. 1. 2. 1. 2. 1. 0. 0. 1. 0. 2. 2. 0. 0. 1. 1. 0. 2. 2.\n",
      " 2. 2. 1. 2. 2. 2. 1. 2. 2. 2. 2. 1. 2. 1. 1. 2. 0. 1. 0. 2. 0. 1. 0. 1.\n",
      " 1. 1. 2. 2. 1. 0. 1. 1. 0. 2. 2. 2. 1. 1. 2. 1. 0. 2. 2. 0. 2. 1. 0. 1.\n",
      " 1. 2. 2. 2. 0. 0. 0. 1. 2. 2. 1. 0. 2. 2. 0. 1. 1. 1. 0. 0. 2. 2. 2. 0.\n",
      " 1. 1. 2. 1. 1. 0. 0. 0. 1. 0. 2. 2. 2. 1. 2. 1. 1. 0. 2. 2. 0. 1. 1. 1.\n",
      " 0. 1. 2. 2. 0. 1. 2. 1. 0. 0. 1. 1. 2. 0. 1. 2. 2. 1. 2. 2. 1. 0. 1. 1.\n",
      " 0. 2. 1. 1. 1. 1. 0. 2. 1. 1. 2. 2. 0. 0. 1. 1. 0. 2. 0. 2. 2. 0. 2. 1.\n",
      " 0. 2. 0. 0. 2. 2. 0. 2. 0. 0. 0. 2. 0. 2. 2. 2. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 2. 2. 1. 1. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "sklearn_predicted_test = clf.predict(X_test)\n",
    "print(sklearn_predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8376383763837638"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(sklearn_predicted_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
