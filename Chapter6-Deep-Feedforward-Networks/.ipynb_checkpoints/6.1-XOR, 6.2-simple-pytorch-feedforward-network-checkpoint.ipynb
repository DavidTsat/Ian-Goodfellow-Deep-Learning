{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pytorch/examples/blob/master/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.autograd.Variable(torch.FloatTensor(np.array([[0,0],[0,1],[1,0],[1,1]])),requires_grad=False).to(device)\n",
    "y = torch.autograd.Variable(torch.FloatTensor(np.array([[0,1,1,0]]).T),requires_grad=False).to(device)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_xor = nn.Sequential(nn.Linear(2, 2),nn.ReLU(),nn.Linear(2,1)).to(device)\n",
    "net_xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 1)\n",
    "\n",
    "weights_init(net_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_net_xor = optim.SGD(net_xor.parameters(), lr=0.002, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6372,  0.4172, -0.8506, -0.0898], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.6102,  0.4296, -0.8115, -0.0761], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.5723,  0.4472, -0.7565, -0.0567], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.5250,  0.4692, -0.6879, -0.0324], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.4701,  0.4948, -0.6081, -0.0040], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([-0.4091,  0.5235, -0.5192,  0.0277], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([-0.3435,  0.5545, -0.4235,  0.0620], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([-0.2748,  0.5871, -0.3230,  0.0982], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([-0.2042,  0.6208, -0.2193,  0.1356], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([-0.1330,  0.6548, -0.1143,  0.1735], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([-0.0623,  0.6887, -0.0101,  0.2112], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0039, 0.7219, 0.0237, 0.2483], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0655, 0.7541, 0.0567, 0.2844], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1225, 0.7848, 0.0886, 0.3191], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1747, 0.8140, 0.1192, 0.3522], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.2223, 0.8412, 0.1482, 0.3834], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.2652, 0.8664, 0.1755, 0.4126], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3035, 0.8893, 0.2010, 0.4395], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3372, 0.9099, 0.2246, 0.4640], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3666, 0.9280, 0.2462, 0.4861], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.3916, 0.9437, 0.2657, 0.5057], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4125, 0.9570, 0.2832, 0.5229], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4295, 0.9678, 0.2987, 0.5375], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4427, 0.9763, 0.3122, 0.5498], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4523, 0.9825, 0.3238, 0.5597], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4587, 0.9865, 0.3335, 0.5674], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4620, 0.9885, 0.3416, 0.5730], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4625, 0.9887, 0.3480, 0.5767], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4605, 0.9871, 0.3530, 0.5787], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4561, 0.9841, 0.3566, 0.5790], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4497, 0.9797, 0.3591, 0.5779], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4415, 0.9741, 0.3604, 0.5756], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4318, 0.9675, 0.3609, 0.5722], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4208, 0.9601, 0.3605, 0.5679], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.4087, 0.9520, 0.3596, 0.5629], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3957, 0.9435, 0.3581, 0.5573], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3821, 0.9346, 0.3562, 0.5513], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3680, 0.9255, 0.3540, 0.5450], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3535, 0.9163, 0.3517, 0.5385], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3390, 0.9071, 0.3492, 0.5320], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3244, 0.8981, 0.3468, 0.5255], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.3099, 0.8893, 0.3445, 0.5192], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.2957, 0.8808, 0.3422, 0.5131], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.2817, 0.8726, 0.3402, 0.5073], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.2682, 0.8649, 0.3384, 0.5019], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.2552, 0.8576, 0.3369, 0.4968], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.2427, 0.8508, 0.3358, 0.4922], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.2307, 0.8446, 0.3349, 0.4880], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.2194, 0.8388, 0.3344, 0.4843], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1986, 0.8290, 0.3346, 0.4782], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1893, 0.8249, 0.3352, 0.4759], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1805, 0.8213, 0.3361, 0.4741], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1724, 0.8182, 0.3375, 0.4727], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1650, 0.8156, 0.3392, 0.4717], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1582, 0.8135, 0.3412, 0.4712], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1520, 0.8119, 0.3435, 0.4710], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1463, 0.8106, 0.3461, 0.4712], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1412, 0.8098, 0.3490, 0.4718], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1366, 0.8093, 0.3521, 0.4726], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1325, 0.8091, 0.3554, 0.4737], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1289, 0.8093, 0.3590, 0.4751], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1256, 0.8097, 0.3627, 0.4767], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1227, 0.8103, 0.3666, 0.4784], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1202, 0.8111, 0.3706, 0.4804], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1180, 0.8121, 0.3747, 0.4824], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1161, 0.8133, 0.3789, 0.4846], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1144, 0.8146, 0.3832, 0.4868], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1130, 0.8159, 0.3874, 0.4891], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1117, 0.8173, 0.3918, 0.4914], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1106, 0.8188, 0.3961, 0.4937], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1096, 0.8203, 0.4004, 0.4960], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1087, 0.8218, 0.4046, 0.4983], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.1079, 0.8233, 0.4089, 0.5005], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1071, 0.8247, 0.4130, 0.5026], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1065, 0.8261, 0.4171, 0.5046], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1058, 0.8275, 0.4211, 0.5066], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1052, 0.8287, 0.4251, 0.5084], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1045, 0.8299, 0.4289, 0.5102], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1039, 0.8310, 0.4326, 0.5118], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1032, 0.8320, 0.4363, 0.5133], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1025, 0.8330, 0.4398, 0.5147], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1018, 0.8338, 0.4432, 0.5159], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1010, 0.8345, 0.4465, 0.5170], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.1002, 0.8351, 0.4497, 0.5180], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0994, 0.8356, 0.4528, 0.5188], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0985, 0.8361, 0.4558, 0.5196], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0976, 0.8364, 0.4587, 0.5202], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0967, 0.8367, 0.4614, 0.5206], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0957, 0.8368, 0.4641, 0.5210], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0947, 0.8369, 0.4667, 0.5213], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0936, 0.8369, 0.4692, 0.5214], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0926, 0.8368, 0.4716, 0.5215], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0915, 0.8367, 0.4739, 0.5214], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0904, 0.8365, 0.4762, 0.5213], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0892, 0.8362, 0.4784, 0.5211], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0881, 0.8359, 0.4805, 0.5208], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0870, 0.8355, 0.4825, 0.5205], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0859, 0.8351, 0.4846, 0.5201], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0837, 0.8343, 0.4884, 0.5191], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0826, 0.8338, 0.4903, 0.5185], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0815, 0.8333, 0.4922, 0.5180], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0805, 0.8328, 0.4940, 0.5173], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0795, 0.8323, 0.4958, 0.5167], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0785, 0.8317, 0.4975, 0.5160], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0775, 0.8312, 0.4993, 0.5153], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.5\n",
      "tensor([0.0766, 0.8307, 0.5010, 0.5146], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0757, 0.8302, 0.5027, 0.5138], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0749, 0.8297, 0.5044, 0.5131], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0741, 0.8291, 0.5061, 0.5123], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0733, 0.8287, 0.5078, 0.5116], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0726, 0.8282, 0.5095, 0.5108], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0719, 0.8277, 0.5112, 0.5100], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0713, 0.8272, 0.5128, 0.5093], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0707, 0.8268, 0.5145, 0.5085], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0701, 0.8264, 0.5162, 0.5077], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0696, 0.8259, 0.5178, 0.5069], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0692, 0.8256, 0.5195, 0.5062], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0687, 0.8252, 0.5212, 0.5054], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0683, 0.8248, 0.5229, 0.5046], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0679, 0.8244, 0.5245, 0.5039], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0676, 0.8241, 0.5262, 0.5031], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0673, 0.8238, 0.5279, 0.5023], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0670, 0.8235, 0.5295, 0.5016], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0668, 0.8232, 0.5312, 0.5008], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0666, 0.8229, 0.5329, 0.5000], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  0.75\n",
      "tensor([0.0664, 0.8226, 0.5345, 0.4992], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0662, 0.8223, 0.5362, 0.4985], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0661, 0.8221, 0.5379, 0.4977], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0659, 0.8218, 0.5395, 0.4969], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0658, 0.8216, 0.5412, 0.4961], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0657, 0.8213, 0.5428, 0.4953], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0657, 0.8211, 0.5444, 0.4945], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0656, 0.8209, 0.5461, 0.4937], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0655, 0.8206, 0.5477, 0.4929], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0655, 0.8204, 0.5493, 0.4921], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0655, 0.8202, 0.5509, 0.4912], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0655, 0.8200, 0.5525, 0.4904], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0654, 0.8198, 0.5541, 0.4895], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0654, 0.8196, 0.5557, 0.4887], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0654, 0.8193, 0.5573, 0.4878], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0654, 0.8191, 0.5569, 0.4869], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0668, 0.8189, 0.5592, 0.4861], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0695, 0.8187, 0.5620, 0.4852], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0718, 0.8185, 0.5635, 0.4843], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0739, 0.8183, 0.5650, 0.4833], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0758, 0.8180, 0.5665, 0.4824], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0774, 0.8177, 0.5680, 0.4814], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0799, 0.8171, 0.5708, 0.4793], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0809, 0.8168, 0.5722, 0.4783], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0816, 0.8164, 0.5735, 0.4772], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0822, 0.8160, 0.5748, 0.4760], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0827, 0.8156, 0.5761, 0.4749], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0830, 0.8152, 0.5774, 0.4737], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0832, 0.8148, 0.5786, 0.4725], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0833, 0.8144, 0.5799, 0.4713], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0833, 0.8139, 0.5811, 0.4701], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0832, 0.8135, 0.5823, 0.4689], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0830, 0.8130, 0.5835, 0.4677], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0828, 0.8125, 0.5847, 0.4665], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0824, 0.8121, 0.5859, 0.4652], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0821, 0.8117, 0.5860, 0.4640], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0830, 0.8112, 0.5880, 0.4628], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0851, 0.8108, 0.5894, 0.4616], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0868, 0.8104, 0.5906, 0.4603], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0883, 0.8100, 0.5918, 0.4591], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0895, 0.8096, 0.5930, 0.4579], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0905, 0.8092, 0.5942, 0.4567], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0913, 0.8088, 0.5953, 0.4554], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0919, 0.8083, 0.5965, 0.4542], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0923, 0.8079, 0.5976, 0.4530], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0925, 0.8075, 0.5988, 0.4517], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0926, 0.8071, 0.5999, 0.4505], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0926, 0.8067, 0.6010, 0.4493], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0925, 0.8063, 0.6022, 0.4480], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0922, 0.8059, 0.6033, 0.4468], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0919, 0.8055, 0.6044, 0.4456], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0915, 0.8052, 0.6056, 0.4444], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0910, 0.8048, 0.6067, 0.4432], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0905, 0.8045, 0.6079, 0.4420], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0899, 0.8042, 0.6071, 0.4408], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0905, 0.8039, 0.6088, 0.4397], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0923, 0.8036, 0.6114, 0.4385], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0937, 0.8033, 0.6126, 0.4374], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0949, 0.8031, 0.6138, 0.4363], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0959, 0.8028, 0.6150, 0.4352], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0966, 0.8026, 0.6162, 0.4340], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0972, 0.8023, 0.6174, 0.4329], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0975, 0.8021, 0.6186, 0.4318], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0977, 0.8019, 0.6198, 0.4307], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0978, 0.8016, 0.6209, 0.4296], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0977, 0.8014, 0.6221, 0.4285], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0974, 0.8012, 0.6233, 0.4273], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0971, 0.8009, 0.6245, 0.4262], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0967, 0.8007, 0.6256, 0.4251], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0962, 0.8005, 0.6266, 0.4240], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0968, 0.8003, 0.6280, 0.4229], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0975, 0.8000, 0.6304, 0.4208], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0976, 0.7998, 0.6315, 0.4197], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0976, 0.7996, 0.6322, 0.4186], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0987, 0.7995, 0.6339, 0.4175], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0995, 0.7993, 0.6351, 0.4165], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1000, 0.7992, 0.6363, 0.4154], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1004, 0.7991, 0.6374, 0.4143], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1006, 0.7989, 0.6386, 0.4133], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1007, 0.7988, 0.6398, 0.4122], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1006, 0.7986, 0.6409, 0.4111], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1003, 0.7985, 0.6421, 0.4100], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1000, 0.7984, 0.6423, 0.4090], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1007, 0.7983, 0.6444, 0.4079], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1023, 0.7981, 0.6456, 0.4068], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1036, 0.7980, 0.6467, 0.4058], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1046, 0.7979, 0.6479, 0.4047], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1054, 0.7978, 0.6490, 0.4036], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1059, 0.7976, 0.6501, 0.4025], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1062, 0.7975, 0.6512, 0.4014], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1063, 0.7974, 0.6523, 0.4003], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1062, 0.7972, 0.6534, 0.3992], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1059, 0.7971, 0.6545, 0.3981], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1055, 0.7969, 0.6556, 0.3970], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1049, 0.7968, 0.6566, 0.3959], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1043, 0.7967, 0.6577, 0.3948], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1035, 0.7965, 0.6588, 0.3937], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1027, 0.7964, 0.6598, 0.3926], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1017, 0.7963, 0.6590, 0.3915], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1019, 0.7962, 0.6601, 0.3905], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1030, 0.7962, 0.6631, 0.3894], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1039, 0.7961, 0.6642, 0.3884], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1045, 0.7960, 0.6653, 0.3873], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1048, 0.7960, 0.6664, 0.3863], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1050, 0.7960, 0.6675, 0.3852], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1050, 0.7959, 0.6686, 0.3842], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1048, 0.7959, 0.6697, 0.3832], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1045, 0.7958, 0.6708, 0.3821], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1041, 0.7958, 0.6719, 0.3811], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1035, 0.7958, 0.6721, 0.3801], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1039, 0.7958, 0.6738, 0.3791], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1052, 0.7958, 0.6752, 0.3780], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1062, 0.7958, 0.6763, 0.3770], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1069, 0.7958, 0.6774, 0.3760], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1073, 0.7958, 0.6785, 0.3750], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1076, 0.7958, 0.6795, 0.3740], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1076, 0.7958, 0.6806, 0.3729], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1074, 0.7958, 0.6816, 0.3719], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1071, 0.7957, 0.6827, 0.3709], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1066, 0.7957, 0.6837, 0.3698], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1052, 0.7957, 0.6858, 0.3678], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1044, 0.7957, 0.6866, 0.3667], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1045, 0.7958, 0.6878, 0.3657], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1055, 0.7958, 0.6889, 0.3647], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1062, 0.7958, 0.6900, 0.3637], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1067, 0.7959, 0.6910, 0.3627], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1069, 0.7959, 0.6921, 0.3617], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1069, 0.7959, 0.6931, 0.3607], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1068, 0.7960, 0.6941, 0.3597], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1064, 0.7960, 0.6951, 0.3587], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1060, 0.7961, 0.6962, 0.3576], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1053, 0.7961, 0.6972, 0.3566], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1046, 0.7962, 0.6982, 0.3556], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1038, 0.7962, 0.6977, 0.3546], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1039, 0.7963, 0.6990, 0.3537], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1048, 0.7964, 0.7013, 0.3527], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1055, 0.7965, 0.7023, 0.3517], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1059, 0.7966, 0.7033, 0.3508], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1061, 0.7967, 0.7044, 0.3498], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1061, 0.7968, 0.7054, 0.3488], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1059, 0.7969, 0.7064, 0.3478], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1055, 0.7970, 0.7074, 0.3469], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1050, 0.7971, 0.7084, 0.3459], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1044, 0.7972, 0.7093, 0.3449], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1046, 0.7973, 0.7104, 0.3440], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1046, 0.7975, 0.7114, 0.3430], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1045, 0.7976, 0.7124, 0.3420], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1041, 0.7977, 0.7131, 0.3411], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1046, 0.7978, 0.7144, 0.3401], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1049, 0.7980, 0.7154, 0.3391], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1050, 0.7981, 0.7164, 0.3382], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1048, 0.7982, 0.7174, 0.3372], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1045, 0.7984, 0.7183, 0.3363], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1041, 0.7985, 0.7193, 0.3353], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1044, 0.7987, 0.7203, 0.3344], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1045, 0.7988, 0.7213, 0.3334], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1045, 0.7990, 0.7222, 0.3324], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1042, 0.7975, 0.7232, 0.3315], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1045, 0.7969, 0.7241, 0.3305], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1053, 0.7974, 0.7251, 0.3296], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1064, 0.7989, 0.7261, 0.3287], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1080, 0.7998, 0.7270, 0.3277], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1092, 0.8000, 0.7279, 0.3268], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1100, 0.8001, 0.7289, 0.3258], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1105, 0.8003, 0.7298, 0.3248], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1108, 0.8004, 0.7306, 0.3239], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1108, 0.8005, 0.7315, 0.3229], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1105, 0.8006, 0.7321, 0.3219], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1109, 0.8007, 0.7332, 0.3208], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1119, 0.8009, 0.7348, 0.3188], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1124, 0.8010, 0.7356, 0.3178], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1126, 0.8010, 0.7364, 0.3168], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1125, 0.8011, 0.7372, 0.3157], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1122, 0.8012, 0.7380, 0.3147], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1117, 0.8010, 0.7388, 0.3136], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1117, 0.8007, 0.7395, 0.3126], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1121, 0.8013, 0.7403, 0.3116], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1122, 0.8014, 0.7410, 0.3106], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1120, 0.8015, 0.7412, 0.3096], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1126, 0.8016, 0.7425, 0.3085], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1128, 0.8017, 0.7433, 0.3075], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1127, 0.8017, 0.7440, 0.3065], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1131, 0.8018, 0.7448, 0.3056], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1132, 0.8019, 0.7455, 0.3046], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1130, 0.8020, 0.7457, 0.3036], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1135, 0.8021, 0.7470, 0.3026], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1137, 0.8022, 0.7478, 0.3016], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1136, 0.8022, 0.7485, 0.3007], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1139, 0.8025, 0.7493, 0.2997], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1139, 0.8026, 0.7500, 0.2988], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1137, 0.8027, 0.7506, 0.2979], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1141, 0.8029, 0.7515, 0.2969], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1142, 0.8029, 0.7523, 0.2960], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1147, 0.8031, 0.7530, 0.2951], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1149, 0.8033, 0.7537, 0.2942], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1148, 0.8034, 0.7545, 0.2933], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1145, 0.8036, 0.7552, 0.2924], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1139, 0.8030, 0.7557, 0.2915], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1146, 0.8039, 0.7567, 0.2906], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1150, 0.8041, 0.7574, 0.2897], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1151, 0.8042, 0.7581, 0.2888], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1149, 0.8044, 0.7589, 0.2880], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1145, 0.8044, 0.7596, 0.2871], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1145, 0.8048, 0.7603, 0.2863], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1142, 0.8050, 0.7607, 0.2854], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1146, 0.8052, 0.7618, 0.2846], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1146, 0.8054, 0.7625, 0.2837], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1143, 0.8054, 0.7632, 0.2829], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1145, 0.8058, 0.7640, 0.2821], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1144, 0.8060, 0.7647, 0.2813], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1140, 0.8062, 0.7647, 0.2804], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1142, 0.8064, 0.7661, 0.2796], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1150, 0.8066, 0.7669, 0.2788], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1154, 0.8068, 0.7676, 0.2780], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1154, 0.8071, 0.7683, 0.2772], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1152, 0.8071, 0.7690, 0.2764], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1154, 0.8075, 0.7697, 0.2756], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1152, 0.8077, 0.7704, 0.2748], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1155, 0.8082, 0.7718, 0.2733], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1152, 0.8084, 0.7725, 0.2725], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1146, 0.8086, 0.7731, 0.2717], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1137, 0.8086, 0.7738, 0.2709], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1134, 0.8090, 0.7745, 0.2701], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1135, 0.8093, 0.7752, 0.2693], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1133, 0.8095, 0.7756, 0.2686], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1136, 0.8098, 0.7765, 0.2678], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1137, 0.8100, 0.7772, 0.2671], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1134, 0.8103, 0.7777, 0.2663], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1136, 0.8105, 0.7786, 0.2656], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1136, 0.8108, 0.7792, 0.2648], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1132, 0.8111, 0.7799, 0.2641], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1126, 0.8113, 0.7806, 0.2633], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1118, 0.8116, 0.7808, 0.2626], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1116, 0.8118, 0.7818, 0.2619], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1119, 0.8121, 0.7826, 0.2611], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1119, 0.8119, 0.7832, 0.2604], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1122, 0.8126, 0.7839, 0.2597], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1130, 0.8130, 0.7846, 0.2590], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1133, 0.8132, 0.7852, 0.2583], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1133, 0.8135, 0.7859, 0.2576], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1131, 0.8138, 0.7865, 0.2569], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1125, 0.8141, 0.7872, 0.2561], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1117, 0.8144, 0.7878, 0.2554], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1107, 0.8143, 0.7884, 0.2547], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1102, 0.8144, 0.7891, 0.2540], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1101, 0.8152, 0.7897, 0.2533], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1097, 0.8155, 0.7903, 0.2526], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1091, 0.8158, 0.7909, 0.2519], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1091, 0.8161, 0.7916, 0.2512], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1087, 0.8164, 0.7920, 0.2506], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1089, 0.8167, 0.7929, 0.2499], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1088, 0.8170, 0.7935, 0.2492], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1084, 0.8174, 0.7942, 0.2485], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1078, 0.8170, 0.7948, 0.2479], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1076, 0.8174, 0.7955, 0.2472], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1078, 0.8183, 0.7961, 0.2466], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1077, 0.8187, 0.7968, 0.2459], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1074, 0.8190, 0.7969, 0.2453], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1075, 0.8194, 0.7980, 0.2446], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1074, 0.8197, 0.7987, 0.2440], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1070, 0.8200, 0.7991, 0.2433], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1070, 0.8204, 0.7999, 0.2427], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1068, 0.8207, 0.8005, 0.2420], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1064, 0.8210, 0.8012, 0.2414], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1057, 0.8204, 0.8018, 0.2407], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1054, 0.8207, 0.8024, 0.2401], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1056, 0.8220, 0.8030, 0.2394], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1063, 0.8228, 0.8042, 0.2381], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1061, 0.8231, 0.8048, 0.2375], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1057, 0.8234, 0.8048, 0.2368], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1058, 0.8238, 0.8058, 0.2362], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1063, 0.8241, 0.8066, 0.2355], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1065, 0.8244, 0.8072, 0.2349], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1063, 0.8248, 0.8078, 0.2342], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1059, 0.8251, 0.8083, 0.2336], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1052, 0.8254, 0.8089, 0.2329], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1043, 0.8257, 0.8094, 0.2322], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1032, 0.8260, 0.8098, 0.2316], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1026, 0.8263, 0.8104, 0.2309], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1025, 0.8265, 0.8111, 0.2303], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1028, 0.8270, 0.8116, 0.2296], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1028, 0.8273, 0.8122, 0.2290], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1025, 0.8276, 0.8127, 0.2283], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1026, 0.8280, 0.8133, 0.2277], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1025, 0.8283, 0.8138, 0.2270], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1020, 0.8287, 0.8144, 0.2264], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1013, 0.8287, 0.8149, 0.2258], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1011, 0.8293, 0.8155, 0.2251], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1006, 0.8297, 0.8160, 0.2245], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1005, 0.8300, 0.8166, 0.2239], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.1002, 0.8304, 0.8171, 0.2233], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0996, 0.8308, 0.8172, 0.2227], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0995, 0.8311, 0.8179, 0.2220], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0998, 0.8315, 0.8188, 0.2214], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0998, 0.8318, 0.8194, 0.2208], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0996, 0.8322, 0.8199, 0.2202], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0991, 0.8326, 0.8205, 0.2196], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0983, 0.8329, 0.8210, 0.2190], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0974, 0.8324, 0.8213, 0.2184], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0976, 0.8333, 0.8221, 0.2178], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0982, 0.8341, 0.8227, 0.2172], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0984, 0.8344, 0.8232, 0.2167], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0984, 0.8348, 0.8238, 0.2161], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0980, 0.8352, 0.8243, 0.2155], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0975, 0.8356, 0.8248, 0.2149], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0967, 0.8359, 0.8254, 0.2143], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0957, 0.8363, 0.8250, 0.2137], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0959, 0.8367, 0.8260, 0.2131], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0964, 0.8370, 0.8270, 0.2125], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0966, 0.8374, 0.8275, 0.2119], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0965, 0.8378, 0.8280, 0.2114], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0962, 0.8382, 0.8285, 0.2108], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0956, 0.8385, 0.8291, 0.2102], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0948, 0.8387, 0.8296, 0.2096], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0945, 0.8390, 0.8301, 0.2090], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0945, 0.8396, 0.8306, 0.2084], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0938, 0.8404, 0.8314, 0.2072], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0937, 0.8407, 0.8321, 0.2066], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0934, 0.8411, 0.8326, 0.2061], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0935, 0.8415, 0.8331, 0.2055], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0934, 0.8419, 0.8336, 0.2052], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0933, 0.8428, 0.8347, 0.2055], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0932, 0.8441, 0.8363, 0.2062], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0934, 0.8455, 0.8378, 0.2071], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0939, 0.8468, 0.8391, 0.2078], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0941, 0.8479, 0.8403, 0.2083], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0939, 0.8488, 0.8413, 0.2086], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0934, 0.8496, 0.8414, 0.2088], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0933, 0.8503, 0.8423, 0.2088], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0935, 0.8509, 0.8438, 0.2087], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0933, 0.8514, 0.8444, 0.2084], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0928, 0.8518, 0.8450, 0.2080], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0920, 0.8519, 0.8454, 0.2078], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0918, 0.8528, 0.8463, 0.2079], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0922, 0.8543, 0.8477, 0.2087], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0922, 0.8554, 0.8489, 0.2094], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0918, 0.8563, 0.8497, 0.2099], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0918, 0.8571, 0.8508, 0.2100], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0913, 0.8576, 0.8515, 0.2100], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0905, 0.8581, 0.8516, 0.2098], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0901, 0.8584, 0.8524, 0.2093], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0893, 0.8584, 0.8527, 0.2088], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0888, 0.8586, 0.8529, 0.2084], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0883, 0.8592, 0.8535, 0.2084], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0883, 0.8602, 0.8547, 0.2087], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0880, 0.8611, 0.8556, 0.2092], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0879, 0.8617, 0.8564, 0.2093], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0875, 0.8622, 0.8569, 0.2092], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0868, 0.8625, 0.8573, 0.2089], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0857, 0.8627, 0.8575, 0.2084], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0850, 0.8627, 0.8577, 0.2081], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0843, 0.8628, 0.8583, 0.2080], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0841, 0.8640, 0.8594, 0.2084], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0842, 0.8651, 0.8603, 0.2088], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0839, 0.8657, 0.8610, 0.2089], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0833, 0.8661, 0.8614, 0.2087], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0824, 0.8663, 0.8614, 0.2083], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0817, 0.8664, 0.8617, 0.2077], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0814, 0.8663, 0.8619, 0.2072], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0810, 0.8668, 0.8625, 0.2071], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0806, 0.8677, 0.8634, 0.2074], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0799, 0.8683, 0.8642, 0.2077], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0795, 0.8689, 0.8647, 0.2076], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0788, 0.8690, 0.8651, 0.2073], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n",
      "tensor([0.0783, 0.8693, 0.8653, 0.2068], grad_fn=<SqueezeBackward0>)\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "net_xor.train()\n",
    "for i in range(500):\n",
    "    optimizer_net_xor.zero_grad()\n",
    "    output = net_xor(X)\n",
    "    if i%50:\n",
    "        print(output.squeeze())\n",
    "        print('Accuracy: ', ((output.squeeze()>0.5)==y.squeeze().byte()).sum().item()/4)\n",
    "    loss = F.mse_loss(output, y)\n",
    "    loss.backward()\n",
    "    optimizer_net_xor.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0775],\n",
       "        [0.8693],\n",
       "        [0.8654],\n",
       "        [0.2061]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_xor.eval()\n",
    "output = net_xor(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[-0.5448, -0.5416],\n",
      "        [-0.7307, -0.7307]])\n",
      "0.bias tensor([1.0863, 0.7304])\n",
      "2.weight tensor([[ 1.2175, -1.9867]])\n",
      "2.bias tensor([0.2061])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net_xor.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_random_images(loader):\n",
    "    rand_idxs = [np.random.randint(0, batch_size-1) for i in range (4)]\n",
    "    for t in loader:\n",
    "        X = t[0][rand_idxs]\n",
    "        y = t[1][rand_idxs]\n",
    "\n",
    "        print(X.shape, y.shape)\n",
    "\n",
    "        f, axarr = plt.subplots(2,2)\n",
    "\n",
    "        axarr[0,0].imshow(X[0].squeeze())\n",
    "        axarr[0,0].set_title(str(y[0].item()))\n",
    "\n",
    "        axarr[0,1].imshow(X[1].squeeze())\n",
    "        axarr[0,1].set_title(str(y[1].item()))\n",
    "\n",
    "        axarr[1,0].imshow(X[2].squeeze())\n",
    "        axarr[1,0].set_title(str(y[2].item()))\n",
    "\n",
    "        axarr[1,1].imshow(X[3].squeeze())\n",
    "        axarr[1,1].set_title(str(y[3].item()))\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = draw_random_images(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDenseNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleDenseNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc_output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        return F.log_softmax(self.fc_output(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleDenseNet(\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc_output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SimpleDenseNet(28*28).to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Batch Accuracy: ', (torch.argmax(output,1) == target).sum().item()/batch_size)\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Accuracy:  0.1875\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 2.282829\n",
      "Batch Accuracy:  0.25\n",
      "Train Epoch: 50 [1600/60000 (3%)]\tLoss: 2.288347\n",
      "Batch Accuracy:  0.3125\n",
      "Train Epoch: 50 [3200/60000 (5%)]\tLoss: 2.258720\n",
      "Batch Accuracy:  0.3125\n",
      "Train Epoch: 50 [4800/60000 (8%)]\tLoss: 2.256721\n",
      "Batch Accuracy:  0.3125\n",
      "Train Epoch: 50 [6400/60000 (11%)]\tLoss: 2.259532\n",
      "Batch Accuracy:  0.40625\n",
      "Train Epoch: 50 [8000/60000 (13%)]\tLoss: 2.243279\n",
      "Batch Accuracy:  0.375\n",
      "Train Epoch: 50 [9600/60000 (16%)]\tLoss: 2.223096\n",
      "Batch Accuracy:  0.5625\n",
      "Train Epoch: 50 [11200/60000 (19%)]\tLoss: 2.186799\n",
      "Batch Accuracy:  0.6875\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 2.170178\n",
      "Batch Accuracy:  0.28125\n",
      "Train Epoch: 50 [14400/60000 (24%)]\tLoss: 2.214509\n",
      "Batch Accuracy:  0.5625\n",
      "Train Epoch: 50 [16000/60000 (27%)]\tLoss: 2.144142\n",
      "Batch Accuracy:  0.71875\n",
      "Train Epoch: 50 [17600/60000 (29%)]\tLoss: 2.110268\n",
      "Batch Accuracy:  0.6875\n",
      "Train Epoch: 50 [19200/60000 (32%)]\tLoss: 2.082780\n",
      "Batch Accuracy:  0.71875\n",
      "Train Epoch: 50 [20800/60000 (35%)]\tLoss: 2.037919\n",
      "Batch Accuracy:  0.625\n",
      "Train Epoch: 50 [22400/60000 (37%)]\tLoss: 2.047807\n",
      "Batch Accuracy:  0.71875\n",
      "Train Epoch: 50 [24000/60000 (40%)]\tLoss: 1.966989\n",
      "Batch Accuracy:  0.53125\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 2.037505\n",
      "Batch Accuracy:  0.78125\n",
      "Train Epoch: 50 [27200/60000 (45%)]\tLoss: 1.913128\n",
      "Batch Accuracy:  0.59375\n",
      "Train Epoch: 50 [28800/60000 (48%)]\tLoss: 1.943752\n",
      "Batch Accuracy:  0.84375\n",
      "Train Epoch: 50 [30400/60000 (51%)]\tLoss: 1.934482\n",
      "Batch Accuracy:  0.75\n",
      "Train Epoch: 50 [32000/60000 (53%)]\tLoss: 1.813523\n",
      "Batch Accuracy:  0.71875\n",
      "Train Epoch: 50 [33600/60000 (56%)]\tLoss: 1.799944\n",
      "Batch Accuracy:  0.78125\n",
      "Train Epoch: 50 [35200/60000 (59%)]\tLoss: 1.703726\n",
      "Batch Accuracy:  0.71875\n",
      "Train Epoch: 50 [36800/60000 (61%)]\tLoss: 1.651631\n",
      "Batch Accuracy:  0.65625\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 1.733657\n",
      "Batch Accuracy:  0.625\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 1.680285\n",
      "Batch Accuracy:  0.625\n",
      "Train Epoch: 50 [41600/60000 (69%)]\tLoss: 1.593141\n",
      "Batch Accuracy:  0.65625\n",
      "Train Epoch: 50 [43200/60000 (72%)]\tLoss: 1.622838\n",
      "Batch Accuracy:  0.65625\n",
      "Train Epoch: 50 [44800/60000 (75%)]\tLoss: 1.563663\n",
      "Batch Accuracy:  0.75\n",
      "Train Epoch: 50 [46400/60000 (77%)]\tLoss: 1.506642\n",
      "Batch Accuracy:  0.875\n",
      "Train Epoch: 50 [48000/60000 (80%)]\tLoss: 1.249548\n",
      "Batch Accuracy:  0.78125\n",
      "Train Epoch: 50 [49600/60000 (83%)]\tLoss: 1.317898\n",
      "Batch Accuracy:  0.65625\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 1.457309\n",
      "Batch Accuracy:  0.90625\n",
      "Train Epoch: 50 [52800/60000 (88%)]\tLoss: 1.126583\n",
      "Batch Accuracy:  0.8125\n",
      "Train Epoch: 50 [54400/60000 (91%)]\tLoss: 1.200321\n",
      "Batch Accuracy:  0.90625\n",
      "Train Epoch: 50 [56000/60000 (93%)]\tLoss: 1.081586\n",
      "Batch Accuracy:  0.71875\n",
      "Train Epoch: 50 [57600/60000 (96%)]\tLoss: 1.245010\n",
      "Batch Accuracy:  0.84375\n",
      "Train Epoch: 50 [59200/60000 (99%)]\tLoss: 1.144194\n"
     ]
    }
   ],
   "source": [
    "train(net, train_loader, optimizer, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0818, Accuracy: 8037/10000 (80%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = draw_random_images(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "predicted_y = net(X).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 3, 3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 3, 5, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
