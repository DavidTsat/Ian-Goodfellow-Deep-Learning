{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this chapter we'll be participating in a real kaggle competition and evaluate each of the regularization techniques of the chapter 7                                                                                                               \n",
    "https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection/overview                                                       \n",
    "dataset from                                                                                                                  \n",
    "https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection/discussion/182930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'D:\\\\lungs\\\\train-jpegs'\n",
    "csv_path = 'E:\\\\Download\\\\new_downloads\\\\train.csv'\n",
    "# sample_subm_csv_path = 'E:Download\\\\new_downloads\\\\sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1790594, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>qa_motion</th>\n",
       "      <th>qa_contrast</th>\n",
       "      <th>flow_artifact</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>true_filling_defect_not_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>c0f3cb036d06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>f57ffd3883b6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>41220fda34a3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>13b685b4b14f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>be0b7524ffb4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StudyInstanceUID SeriesInstanceUID SOPInstanceUID  pe_present_on_image  \\\n",
       "0     6897fa9de148      2bfbb7fd2e8b   c0f3cb036d06                    0   \n",
       "1     6897fa9de148      2bfbb7fd2e8b   f57ffd3883b6                    0   \n",
       "2     6897fa9de148      2bfbb7fd2e8b   41220fda34a3                    0   \n",
       "3     6897fa9de148      2bfbb7fd2e8b   13b685b4b14f                    0   \n",
       "4     6897fa9de148      2bfbb7fd2e8b   be0b7524ffb4                    0   \n",
       "\n",
       "   negative_exam_for_pe  qa_motion  qa_contrast  flow_artifact  \\\n",
       "0                     0          0            0              0   \n",
       "1                     0          0            0              0   \n",
       "2                     0          0            0              0   \n",
       "3                     0          0            0              0   \n",
       "4                     0          0            0              0   \n",
       "\n",
       "   rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  leftsided_pe  chronic_pe  \\\n",
       "0                  0                 1             1           0   \n",
       "1                  0                 1             1           0   \n",
       "2                  0                 1             1           0   \n",
       "3                  0                 1             1           0   \n",
       "4                  0                 1             1           0   \n",
       "\n",
       "   true_filling_defect_not_pe  rightsided_pe  acute_and_chronic_pe  \\\n",
       "0                           0              1                     0   \n",
       "1                           0              1                     0   \n",
       "2                           0              1                     0   \n",
       "3                           0              1                     0   \n",
       "4                           0              1                     0   \n",
       "\n",
       "   central_pe  indeterminate  \n",
       "0           0              0  \n",
       "1           0              0  \n",
       "2           0              0  \n",
       "3           0              0  \n",
       "4           0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>qa_motion</th>\n",
       "      <th>qa_contrast</th>\n",
       "      <th>flow_artifact</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>true_filling_defect_not_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1790589</th>\n",
       "      <td>4833c9b6a5d0</td>\n",
       "      <td>57e3e3c5f910</td>\n",
       "      <td>da0ecef50cf5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790590</th>\n",
       "      <td>4833c9b6a5d0</td>\n",
       "      <td>57e3e3c5f910</td>\n",
       "      <td>d74b46c2f2c4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790591</th>\n",
       "      <td>4833c9b6a5d0</td>\n",
       "      <td>57e3e3c5f910</td>\n",
       "      <td>ba71189191ad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790592</th>\n",
       "      <td>4833c9b6a5d0</td>\n",
       "      <td>57e3e3c5f910</td>\n",
       "      <td>f4fdc88f2ace</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790593</th>\n",
       "      <td>4833c9b6a5d0</td>\n",
       "      <td>57e3e3c5f910</td>\n",
       "      <td>f890efd48940</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        StudyInstanceUID SeriesInstanceUID SOPInstanceUID  \\\n",
       "1790589     4833c9b6a5d0      57e3e3c5f910   da0ecef50cf5   \n",
       "1790590     4833c9b6a5d0      57e3e3c5f910   d74b46c2f2c4   \n",
       "1790591     4833c9b6a5d0      57e3e3c5f910   ba71189191ad   \n",
       "1790592     4833c9b6a5d0      57e3e3c5f910   f4fdc88f2ace   \n",
       "1790593     4833c9b6a5d0      57e3e3c5f910   f890efd48940   \n",
       "\n",
       "         pe_present_on_image  negative_exam_for_pe  qa_motion  qa_contrast  \\\n",
       "1790589                    0                     0          0            0   \n",
       "1790590                    0                     0          0            0   \n",
       "1790591                    0                     0          0            0   \n",
       "1790592                    0                     0          0            0   \n",
       "1790593                    1                     0          0            0   \n",
       "\n",
       "         flow_artifact  rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  leftsided_pe  \\\n",
       "1790589              0                  0                 1             1   \n",
       "1790590              0                  0                 1             1   \n",
       "1790591              0                  0                 1             1   \n",
       "1790592              0                  0                 1             1   \n",
       "1790593              0                  0                 1             1   \n",
       "\n",
       "         chronic_pe  true_filling_defect_not_pe  rightsided_pe  \\\n",
       "1790589           1                           0              0   \n",
       "1790590           1                           0              0   \n",
       "1790591           1                           0              0   \n",
       "1790592           1                           0              0   \n",
       "1790593           1                           0              0   \n",
       "\n",
       "         acute_and_chronic_pe  central_pe  indeterminate  \n",
       "1790589                     0           0              0  \n",
       "1790590                     0           0              0  \n",
       "1790591                     0           0              0  \n",
       "1790592                     0           0              0  \n",
       "1790593                     0           0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_level_features = ['pe_present_on_image']\n",
    "# exam_level_features = ['negative_exam_for_pe', \n",
    "exam_level_features = ['indeterminate', 'chronic_pe', 'acute_and_chronic_pe', 'central_pe', 'leftsided_pe', 'rightsided_pe', 'rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1',]\n",
    "informational_features = ['qa_motion', 'qa_contrast', 'true_filling_defect_not_pe', 'flow_artifact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['pe_present_on_image'] == 0, exam_level_features] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.pe_present_on_image == 1].append(df_train[df_train.pe_present_on_image == 0].sample(df_train[df_train.pe_present_on_image == 1].shape[0]), ignore_index=True).sample(frac=1)\n",
    "df_train = df_train[df_train.pe_present_on_image == 1].append(df_train[df_train.pe_present_on_image == 0].sample(df_train[df_train.pe_present_on_image == 1].shape[0]), ignore_index=True)\n",
    "\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>qa_motion</th>\n",
       "      <th>qa_contrast</th>\n",
       "      <th>flow_artifact</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>true_filling_defect_not_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ddcd4deceb98</td>\n",
       "      <td>62929b5bf178</td>\n",
       "      <td>82ddcf09683f</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84e494d67539</td>\n",
       "      <td>5f10c2bb4bf2</td>\n",
       "      <td>de2f7f8f4c38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b414e0ac7cec</td>\n",
       "      <td>d9b33900f2b4</td>\n",
       "      <td>1d959d9dd76f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9f03e1e55791</td>\n",
       "      <td>76ed03625431</td>\n",
       "      <td>b854d125dd76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4b897f593782</td>\n",
       "      <td>d4dbb09b2897</td>\n",
       "      <td>d84d63a50be0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StudyInstanceUID SeriesInstanceUID SOPInstanceUID  pe_present_on_image  \\\n",
       "0     ddcd4deceb98      62929b5bf178   82ddcf09683f                    0   \n",
       "1     84e494d67539      5f10c2bb4bf2   de2f7f8f4c38                    1   \n",
       "2     b414e0ac7cec      d9b33900f2b4   1d959d9dd76f                    0   \n",
       "3     9f03e1e55791      76ed03625431   b854d125dd76                    1   \n",
       "4     4b897f593782      d4dbb09b2897   d84d63a50be0                    1   \n",
       "\n",
       "   negative_exam_for_pe  qa_motion  qa_contrast  flow_artifact  \\\n",
       "0                     1          0            0              0   \n",
       "1                     0          0            0              0   \n",
       "2                     0          0            0              0   \n",
       "3                     0          0            0              0   \n",
       "4                     0          0            0              0   \n",
       "\n",
       "   rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  leftsided_pe  chronic_pe  \\\n",
       "0                  0                 0             0           0   \n",
       "1                  0                 1             1           1   \n",
       "2                  0                 0             0           0   \n",
       "3                  1                 0             1           0   \n",
       "4                  1                 0             1           0   \n",
       "\n",
       "   true_filling_defect_not_pe  rightsided_pe  acute_and_chronic_pe  \\\n",
       "0                           0              0                     0   \n",
       "1                           0              0                     0   \n",
       "2                           0              0                     0   \n",
       "3                           0              1                     0   \n",
       "4                           0              1                     0   \n",
       "\n",
       "   central_pe  indeterminate  \n",
       "0           0              0  \n",
       "1           0              0  \n",
       "2           0              0  \n",
       "3           1              0  \n",
       "4           0              0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ims__ = []\n",
    "# for i, c in enumerate(df_train.StudyInstanceUID.unique()):\n",
    "#     print(i)\n",
    "#     ims__.append(len(df_train[df_train.StudyInstanceUID == c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(ims__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_csv_df = pd.read_csv(sample_subm_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_an_image(df, idx=0):\n",
    "    row = df.iloc[idx]\n",
    "#     print('Reading image ', glob.glob(f\"{train_path}/{row[0]}/{row[1]}/*{row[2]}.jpg\"))\n",
    "    print('Reading image ', glob.glob(f\"{train_path}/{row[0]}/{row[1]}/*{row[2]}.jpg\")[0])\n",
    "    img = Image.open(glob.glob(f\"{train_path}/{row[0]}/{row[1]}/*{row[2]}.jpg\")[0])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_an_image(df, idx=0):\n",
    "#     row = df.iloc[idx]\n",
    "# #     print('Reading image ', glob.glob(f\"{train_path}/{row[0]}/{row[1]}/*{row[2]}.jpg\"))\n",
    "#     print('Reading image ', glob.glob(f\"{train_path}/{row[0]}/{row[1]}/*{row[2]}.jpg\")[0])\n",
    "#     img = Image.open(glob.glob(f\"{train_path}/{row[0]}/{row[1]}/*{row[2]}.jpg\")[0])\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_an_image(df_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    plt.figure(figsize=[12,6])\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img[:,:,0],cmap='gray')\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(img[:,:,1],cmap='gray')\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(img[:,:,2],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_instances =  pd.read_csv(csv_path).StudyInstanceUID.unique()\n",
    "# len(study_instances)\n",
    "\n",
    "# len(pd.read_csv(csv_path).StudyInstanceUID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train.loc[df_train.StudyInstanceUID == study_instances[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.StudyInstanceUID == study_instances[0]].sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_level_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "#         self.sample_size = 32 # min unique\n",
    "#         self.sample_size = 1\n",
    "        self.csv_file = csv_file\n",
    "#         self.study_instances = self.csv_file.StudyInstanceUID.unique()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         sub_df = self.csv_file.loc[self.csv_file.StudyInstanceUID == self.study_instances[idx]].sample(self.sample_size)\n",
    "#         imgs = []\n",
    "# #         print(sub_df)\n",
    "#         for i in range(len(sub_df)):\n",
    "#             print(i)\n",
    "# #             print(sub_df)\n",
    "#             img_ = get_an_image(sub_df, i)\n",
    "#             if self.transform:\n",
    "#                 img_ = self.transform(img_).to(device)\n",
    "#                 imgs.append(img_)\n",
    "            \n",
    "#         targets = torch.FloatTensor(sub_df.loc[sub_df.StudyInstanceUID == self.study_instances[idx]][image_level_features+exam_level_features+informational_features].values).to(device)\n",
    "#         targets = torch.autograd.Variable((sub_df[image_level_features+exam_level_features + informational_features].values)).to(device)\n",
    "#         print(targets.shape, imgs[0].shape, len(imgs))\n",
    "        row = self.csv_file.iloc[idx]\n",
    "        img = Image.open(glob.glob(f\"{train_path}/{row[0]}/{row[1]}/*{row[2]}.jpg\")[0])\n",
    "        img = self.transform(img).to(device)\n",
    "        targets = torch.tensor(row[image_level_features+exam_level_features + informational_features].values.astype(np.float16)).float().to(device)\n",
    "#         print(targets.shape)\n",
    "        return torch.autograd.Variable(img), targets\n",
    "#         return torch.autograd.Variable(torch.stack(imgs)), targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "# normalize = transforms.Normalize(\n",
    "#     mean=[0.5, 0.5, 0.5],\n",
    "#     std=[0.5, 0.5, 0.5]\n",
    "# )\n",
    "\n",
    "ds_trans = transforms.Compose([\n",
    "                                transforms.Grayscale(num_output_channels=3),\n",
    "                                transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                \n",
    "#                                 transforms.CenterCrop(224),\n",
    "                                normalize\n",
    "])\n",
    "\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LungsDataset(df_train, transform=ds_trans)\n",
    "\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = 0\n",
    "# yy = 0\n",
    "# for i, x in enumerate(train_dataloader):\n",
    "# #     print('AAAAAAAAA', x[0].shape, x[1].shape)\n",
    "# #     print(x[0])\n",
    "    \n",
    "#     print('---'*40)\n",
    "#     if i == 0:\n",
    "#         xx = x[0]\n",
    "#     if i == 1:\n",
    "#         yy = x[1]\n",
    "#         break\n",
    "# #     print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx.shape, yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_image(xx[0].cpu().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yy[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_image(xx[3].cpu().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101 = models.resnet50()\n",
    "fc_feat_size = resnet101.fc.in_features\n",
    "resnet101.fc.in_features, resnet101.fc.out_features\n",
    "# fc_feat_size = 2048\n",
    "# resnet50.fc = nn.Linear(resnet50.fc.in_features, fc_feat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "    def __forward__(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "    \n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101.avgpool = Identity()\n",
    "resnet101.fc = Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_level_features+exam_level_features+informational_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_feat_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc_feat_size = 1024\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    for l in m.modules():\n",
    "        if isinstance(l, nn.Conv2d):\n",
    "            torch.nn.init.uniform_(l.weight)\n",
    "        elif isinstance(l, nn.BatchNorm2d):\n",
    "            torch.nn.init.uniform_(l.weight)\n",
    "        elif isinstance(l, nn.Linear):\n",
    "            torch.nn.init.xavier_normal_(l.weight)\n",
    "        \n",
    "class MultiTaskHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskHead, self).__init__()\n",
    "        self.m = nn.Sequential(\n",
    "                nn.Conv2d(2048, 512, kernel_size=(1,1), stride=(1,1), bias=False), \n",
    "                nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "                nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "                nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.AdaptiveAvgPool2d(output_size=(1,1)),\n",
    "        )\n",
    "        self.l = nn.Sequential(\n",
    "                nn.Linear(fc_feat_size, 1, bias=True), \n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(512, 1), \n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 2048, int(np.sqrt(x.shape[1]/2048)), int(np.sqrt(x.shape[1]/2048)))\n",
    "        x = self.m(x)\n",
    "        x = self.l(x.squeeze())\n",
    "        return x\n",
    "\n",
    "class WrapperModel(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(WrapperModel, self).__init__()\n",
    "        self.stage = 'train'\n",
    "        \n",
    "        self.backbone = pretrained_model\n",
    "        '''\n",
    "        image-level feature\n",
    "        '''\n",
    "        self.linear_pe_present_on_image = MultiTaskHead()\n",
    "        weights_init(self.linear_pe_present_on_image)\n",
    "        '''\n",
    "        exam-level features\n",
    "        '''\n",
    "        self.linear_negative_exam_for_pe = MultiTaskHead()\n",
    "        weights_init(self.linear_negative_exam_for_pe)\n",
    "        \n",
    "        self.linear_indeterminate = MultiTaskHead()\n",
    "        weights_init(self.linear_indeterminate)\n",
    "        \n",
    "        self.linear_chronic_pe = MultiTaskHead()\n",
    "        weights_init(self.linear_chronic_pe)\n",
    "        \n",
    "        self.linear_acute_and_chronic_pe = MultiTaskHead()\n",
    "        weights_init(self.linear_acute_and_chronic_pe)\n",
    "        \n",
    "        self.linear_central_pe = MultiTaskHead()\n",
    "        weights_init(self.linear_central_pe)\n",
    "        \n",
    "        self.linear_leftsided_pe = MultiTaskHead()\n",
    "        weights_init(self.linear_leftsided_pe)\n",
    "        \n",
    "        self.linear_rightsided_pe = MultiTaskHead()\n",
    "        weights_init(self.linear_rightsided_pe)\n",
    "        \n",
    "        self.linear_rv_lv_ratio_gte_1 = MultiTaskHead()\n",
    "        weights_init(self.linear_rv_lv_ratio_gte_1)\n",
    "        \n",
    "        self.linear_rv_lv_ratio_lt_1 = MultiTaskHead()\n",
    "        weights_init(self.linear_rv_lv_ratio_lt_1)\n",
    "        \n",
    "        '''\n",
    "        informational features\n",
    "        '''\n",
    "        self.linear_qa_motion = MultiTaskHead()\n",
    "        weights_init(self.linear_qa_motion)\n",
    "        \n",
    "        self.linear_qa_contrast = MultiTaskHead()\n",
    "        weights_init(self.linear_qa_contrast)\n",
    "                \n",
    "        self.linear_true_filling_defect_not_pe = MultiTaskHead()\n",
    "        weights_init(self.linear_true_filling_defect_not_pe)\n",
    "        \n",
    "        self.linear_flow_artifact = MultiTaskHead()\n",
    "        weights_init(self.linear_flow_artifact)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         if self.stage == 'train':\n",
    "#             x, _ = self.backbone(x)\n",
    "#         else: \n",
    "        x = self.backbone(x)\n",
    "        \n",
    "#         print('x1 .shape', x1.shape)\n",
    "        x_pe_present_on_image = self.linear_pe_present_on_image(x)\n",
    "        \n",
    "        x_negative_exam_for_pe = self.linear_negative_exam_for_pe(x)\n",
    "        x_indeterminate = self.linear_indeterminate(x)\n",
    "        x_chronic_pe = self.linear_chronic_pe(x)\n",
    "        x_acute_and_chronic_pe = self.linear_acute_and_chronic_pe(x)\n",
    "        x_central_pe = self.linear_central_pe(x)\n",
    "        x_leftsided_pe = self.linear_leftsided_pe(x)\n",
    "        x_rightsided_pe = self.linear_rightsided_pe(x)\n",
    "        x_rv_lv_ratio_gte_1 = self.linear_rv_lv_ratio_gte_1(x)\n",
    "        x_rv_lv_ratio_lt_1 = self.linear_rv_lv_ratio_lt_1(x)\n",
    "        \n",
    "        x_qa_motion = self.linear_qa_motion(x)\n",
    "        x_qa_contrast = self.linear_qa_contrast(x)\n",
    "        x_true_filling_defect_not_pe = self.linear_true_filling_defect_not_pe(x)\n",
    "        x_flow_artifact = self.linear_flow_artifact(x)\n",
    "        \n",
    "#         ys = []\n",
    "#         for y_pred in [ x_pe_present_on_image, x_negative_exam_for_pe, x_indeterminate, x_chronic_pe, x_acute_and_chronic_pe, x_central_pe, x_leftsided_pe, x_rightsided_pe, x_rv_lv_ratio_gte_1, x_rv_lv_ratio_lt_1, x_qa_motion, x_qa_contrast, x_true_filling_defect_not_pe, x_flow_artifact]:\n",
    "#             ys.append(y_pred)\n",
    "        ys = []\n",
    "        for y_pred in [ x_pe_present_on_image, x_indeterminate, x_chronic_pe, x_acute_and_chronic_pe, x_central_pe, x_leftsided_pe, x_rightsided_pe, x_rv_lv_ratio_gte_1, x_rv_lv_ratio_lt_1, x_qa_motion, x_qa_contrast, x_true_filling_defect_not_pe, x_flow_artifact]:\n",
    "            ys.append(y_pred)\n",
    "        return torch.cat(ys, 1)\n",
    "                      \n",
    "\n",
    "model = WrapperModel(resnet101).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fc_feat_size = 1024\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     for l in m.modules():\n",
    "#         if isinstance(l, nn.Conv2d):\n",
    "#             torch.nn.init.uniform_(l.weight)\n",
    "#         elif isinstance(l, nn.BatchNorm2d):\n",
    "#             torch.nn.init.uniform_(l.weight)\n",
    "#         elif isinstance(l, nn.Linear):\n",
    "#             torch.nn.init.xavier_normal_(l.weight)\n",
    "        \n",
    "# class MultiTaskHead(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(MultiTaskHead, self).__init__()\n",
    "#         self.m = nn.Sequential(\n",
    "#                 nn.Conv2d(2048, 512, kernel_size=(1,1), stride=(1,1), bias=False), \n",
    "#                 nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "#                 nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "#                 nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "#                 nn.Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "#                 nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "#                 nn.AdaptiveMaxPool2d(output_size=(1,1)),\n",
    "#         )\n",
    "#         self.l = nn.Sequential(\n",
    "#                 nn.Linear(fc_feat_size, 1), \n",
    "# #                 nn.ReLU(),\n",
    "# #                 nn.Linear(512, 1), \n",
    "#                 nn.Sigmoid()\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = x.view(x.shape[0], 2048, int(np.sqrt(x.shape[1]/2048)), int(np.sqrt(x.shape[1]/2048)))\n",
    "#         x = self.m(x)\n",
    "#         x = self.l(x.squeeze())\n",
    "#         return x\n",
    "\n",
    "# class WrapperModel(nn.Module):\n",
    "#     def __init__(self, pretrained_model):\n",
    "#         super(WrapperModel, self).__init__()\n",
    "        \n",
    "#         self.backbone = pretrained_model\n",
    "#         '''\n",
    "#         image-level feature\n",
    "#         '''\n",
    "#         self.linear_pe_present_on_image = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_pe_present_on_image)\n",
    "#         '''\n",
    "#         exam-level features\n",
    "#         '''\n",
    "#         self.linear_negative_exam_for_pe = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_negative_exam_for_pe)\n",
    "        \n",
    "#         self.linear_indeterminate = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_indeterminate)\n",
    "        \n",
    "#         self.linear_chronic_pe = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_chronic_pe)\n",
    "        \n",
    "#         self.linear_acute_and_chronic_pe = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_acute_and_chronic_pe)\n",
    "        \n",
    "#         self.linear_central_pe = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_central_pe)\n",
    "        \n",
    "#         self.linear_leftsided_pe = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_leftsided_pe)\n",
    "        \n",
    "#         self.linear_rightsided_pe = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_rightsided_pe)\n",
    "        \n",
    "#         self.linear_rv_lv_ratio_gte_1 = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_rv_lv_ratio_gte_1)\n",
    "        \n",
    "#         self.linear_rv_lv_ratio_lt_1 = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_rv_lv_ratio_lt_1)\n",
    "        \n",
    "#         '''\n",
    "#         informational features\n",
    "#         '''\n",
    "#         self.linear_qa_motion = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_qa_motion)\n",
    "        \n",
    "#         self.linear_qa_contrast = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_qa_contrast)\n",
    "                \n",
    "#         self.linear_true_filling_defect_not_pe = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_true_filling_defect_not_pe)\n",
    "        \n",
    "#         self.linear_flow_artifact = nn.Sequential(nn.Linear(2048,1), nn.Sigmoid())\n",
    "#         weights_init(self.linear_flow_artifact)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.backbone(x)\n",
    "        \n",
    "# #         print('x1 .shape', x.shape)\n",
    "\n",
    "#         x_pe_present_on_image = self.linear_pe_present_on_image(x)\n",
    "        \n",
    "#         x_negative_exam_for_pe = self.linear_negative_exam_for_pe(x)\n",
    "#         x_indeterminate = self.linear_indeterminate(x)\n",
    "#         x_chronic_pe = self.linear_chronic_pe(x)\n",
    "#         x_acute_and_chronic_pe = self.linear_acute_and_chronic_pe(x)\n",
    "#         x_central_pe = self.linear_central_pe(x)\n",
    "#         x_leftsided_pe = self.linear_leftsided_pe(x)\n",
    "#         x_rightsided_pe = self.linear_rightsided_pe(x)\n",
    "#         x_rv_lv_ratio_gte_1 = self.linear_rv_lv_ratio_gte_1(x)\n",
    "#         x_rv_lv_ratio_lt_1 = self.linear_rv_lv_ratio_lt_1(x)\n",
    "        \n",
    "#         x_qa_motion = self.linear_qa_motion(x)\n",
    "#         x_qa_contrast = self.linear_qa_contrast(x)\n",
    "#         x_true_filling_defect_not_pe = self.linear_true_filling_defect_not_pe(x)\n",
    "#         x_flow_artifact = self.linear_flow_artifact(x)\n",
    "        \n",
    "#         ys = []\n",
    "#         for y_pred in [ x_pe_present_on_image, x_negative_exam_for_pe, x_indeterminate, x_chronic_pe, x_acute_and_chronic_pe, x_central_pe, x_leftsided_pe, x_rightsided_pe, x_rv_lv_ratio_gte_1, x_rv_lv_ratio_lt_1, x_qa_motion, x_qa_contrast, x_true_filling_defect_not_pe, x_flow_artifact]:\n",
    "#             ys.append(y_pred)\n",
    "#         return torch.cat(ys, 1)\n",
    "                      \n",
    "\n",
    "# model = WrapperModel(resnet101).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.loc[0][image_level_features+exam_level_features+informational_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "#     if not (name.startswith('backbone.layer3') or name.startswith('backbone.layer4') or name.startswith('backbone.Mixed_') or name.startswith('linear')):\n",
    "    if not (name.startswith('backbone.layer4') or name.startswith('linear')):\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.negative_exam_for_pe == 1]['pe_present_on_image'].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.indeterminate == 1][['qa_motion', 'qa_contrast']].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Weights\n",
    "'''\n",
    "image_level_weights = [0.07361963]\n",
    "exam_level_weights = [0.0736196319, 0.09202453988, 0.1042944785, 0.1042944785, 0.1877300613, 0.06257668712, 0.06257668712, 0.2346625767, 0.0782208589]\n",
    "\n",
    "# Negative for PE\t0.0736196319\n",
    "# Indeterminate\t0.09202453988\n",
    "# Chronic\t0.1042944785\n",
    "# Acute & Chronic\t0.1042944785\n",
    "# Central PE\t0.1877300613\n",
    "# Left PE\t0.06257668712\n",
    "# Right PE\t0.06257668712\n",
    "# RV/LV Ratio >= 1\t0.2346625767\n",
    "# RV/LV Ratio < 1\t0.0782208589\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image level log loss (for one exam/study)\n",
    "def image_level_loss(y_pred, y_real):\n",
    "#     q_i = (y_preds[0].squeeze() > 0.5).sum().item()/y_real.shape[0]\n",
    "#     return image_level_weights[0]*q_i*F.binary_cross_entropy(y_preds[0].squeeze(), y_real[:,0])\n",
    "#     print(y_pred[0].squeeze())\n",
    "#     print(y_real[:,0])\n",
    "    return criterion(y_pred[0].squeeze(), y_real[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exam_level_loss(y_pred, y_real):\n",
    "    total_loss = 0\n",
    "#     for y_p, y_r, w in zip(y_preds[1:-4], y_real[:,1:-4].T, exam_level_weights):\n",
    "#         loss = w*F.binary_cross_entropy(y_p.squeeze(), y_r)\n",
    "#         total_loss += loss\n",
    "    for y_p, y_r in zip(y_pred[1:-4], y_real[:,1:-4].T):\n",
    "        loss = criterion(y_p.squeeze(), y_r)\n",
    "        total_loss += loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y_pred, y_real):\n",
    "    im_loss = image_level_loss(y_pred, y_real)\n",
    "    ex_loss = exam_level_loss(y_pred, y_real)\n",
    "    return im_loss+ex_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_sample(num_of_exams=8):\n",
    "    losses = []\n",
    "    for i in range(num_of_exams):\n",
    "        rand_idx = np.random.randint(len(study_instances))\n",
    "        X_eval, Y_eval = train_dataset[rand_idx]\n",
    "        y_pred_eval = model(X_eval)\n",
    "        loss_eval = compute_loss(y_pred_eval, Y_eval)\n",
    "        losses.append(loss_eval)\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = eval_on_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('./saved_resnet50'))\n",
    "# # model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_level_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "steps_per_epoch = 1000\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):  \n",
    "    print('Epoch Number:', epoch)\n",
    "#     running_loss = 0.0\n",
    "    for i, (x,y) in enumerate(train_dataloader):\n",
    "    \n",
    "#         try:\n",
    "#         rand_idx = np.random.randint(len(study_instances))\n",
    "#         X, Y = train_dataset[rand_idx]\n",
    "#         print(X.shape)\n",
    "#         optimizer.zero_grad()\n",
    "#         y_pe_present_on_image, y_negative_exam_for_pe, y_indeterminate, y_chronic_pe, y_acute_and_chronic_pe, y_central_pe, y_leftsided_pe, y_rightsided_pe, y_rv_lv_ratio_gte_1, y_rv_lv_ratio_lt_1, y_qa_motion, y_qa_contrast, y_true_filling_defect_not_pe, y_flow_artifact = model(X)\n",
    "        \n",
    "#         image_level_loss = criterion(y_pe_present_on_image.squeeze(), Y[:,0])\n",
    "        \n",
    "#         exam_level_loss_1 = criterion(y_negative_exam_for_pe.squeeze(), Y[:,1])\n",
    "#         exam_level_loss_2 = criterion(y_indeterminate.squeeze(), Y[:,2])\n",
    "#         exam_level_loss_3 = criterion(y_chronic_pe.squeeze(), Y[:,3])\n",
    "#         exam_level_loss_4 = criterion(y_acute_and_chronic_pe.squeeze(), Y[:,4])\n",
    "#         exam_level_loss_5 = criterion(y_central_pe.squeeze(), Y[:,5])\n",
    "#         exam_level_loss_6 = criterion(y_leftsided_pe.squeeze(), Y[:,6])\n",
    "#         exam_level_loss_7 = criterion(y_rightsided_pe.squeeze(), Y[:,7])\n",
    "#         exam_level_loss_8 = criterion(y_rv_lv_ratio_gte_1.squeeze(), Y[:,8])\n",
    "#         exam_level_loss_9 = criterion(y_rv_lv_ratio_lt_1.squeeze(), Y[:,9])\n",
    "        \n",
    "#         total_loss = 2*image_level_loss + exam_level_loss_1 + exam_level_loss_2 + exam_level_loss_3 + exam_level_loss_4 + exam_level_loss_5 + exam_level_loss_6 + exam_level_loss_7 + exam_level_loss_8 + exam_level_loss_9\n",
    "#         print(x[0].shape,x[1].shape, x[0].squeeze().shape, x[1].squeeze().shape)\n",
    "#         print(x[0].shape, x[1].shape, 'BBBBB')\n",
    "#         y = x[1].view(x[1].shape[0]*8,14)\n",
    "#         x = x[0].view(x[1].shape[0]*8,3,224,224)\n",
    "#         print(x[0].shape, x[1].shape, 'BBBBB')\n",
    "#         y = x[1].view(-1, x[1].shape[2])\n",
    "#         x = x[0].view(-1, x[0].shape[2], x[0].shape[3], x[0].shape[4])\n",
    "#         print(y.shape, x.shape)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        total_loss = 0\n",
    "#         print(y_pred, y)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "        for i in range(y.shape[1]):\n",
    "# #             print(y_pred[:,i])\n",
    "# #             print()\n",
    "# #             total_loss += criterion(y_pred[:,i], y[:,i])\n",
    "# #             print(y_pred[:,i].shape, y[:,i].shape)\n",
    "# #             print(y[:,i])\n",
    "# #             loss_i = torch.autograd.Variable(criterion(y_pred[:,i], y[:,i]))\n",
    "            loss_i = criterion(y_pred[:,i], y[:,i])\n",
    "#             loss_i.backward(retain_graph=True)\n",
    "            total_loss += loss_i\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "#             total_loss = loss_i\n",
    "#             print(i)\n",
    "#         print(y_pred.shape, y.shape)\n",
    "#         loss_i = criterion(y_pred, y)\n",
    "#         loss_i.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        #         print('AAAAAA', x.shape, y.shape)\n",
    "#         print(y_pred[0].shape)\n",
    "#         print(y_pred.shape)\n",
    "#         total_loss = compute_loss(y_pred, y)\n",
    "#         print(total_loss.requires_grad)\n",
    "#         total_loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        print('Loss:', total_loss.item())\n",
    "# # #         print(y_preds[0].shape, Y.shape)\n",
    "# #         loss = compute_loss(y_preds, Y)\n",
    "#         print('Loss:', loss.item())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, './saved_resnet50')\n",
    "torch.save(model.state_dict(), './saved_resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# # del X\n",
    "# del Y\n",
    "# del y_preds\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = eval_on_sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reshape_pred(pred_y):\n",
    "#     ys = []\n",
    "#     for y in pred_y:\n",
    "#         ys.append(y)\n",
    "#     return torch.cat(ys, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stage = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_idx = np.random.randint(len(study_instances))\n",
    "for X, Y in train_dataloader:\n",
    "    y_pred_eval = model(X)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = reshape_pred(y_pred_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred_eval >= 0.5).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred >= 0.5).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred >= 0.5).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
